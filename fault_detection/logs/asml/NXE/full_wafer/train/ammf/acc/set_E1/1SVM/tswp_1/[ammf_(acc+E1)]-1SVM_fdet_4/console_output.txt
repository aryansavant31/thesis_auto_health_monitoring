=== SCRIPT EXECUTION LOG ===
Script: fault_detection.train.py
Base Name: [ammf_(acc+E1)]-1SVM_fdet_4
Start Time: 2025-09-02 07:17:22
End Time: 2025-09-02 07:19:19

CPU: Intel64 Family 6 Model 79 Stepping 1, GenuineIntel (Cores: 12), Max Frequency: 2594.00 MHz
GPU: None detected
OS: Windows 10 (10.0.19045)

Python Version: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 12:58:53) [MSC v.1929 64 bit (AMD64)]
========================================================================================================================


Starting fault detection model training...

'Train' type dataset selected:


Dataset selections:
---------------------------------------------
*_(<ds_subtype_num>) <ds_subtype> : [<augments>]_*

- **Healthy configs**
  (1) E1_set01_M=mAI26    : [OG]
  (2) E1_set01_M=mAQ10    : [OG]
  (3) E1_set01_M=mAQ87    : [OG]
  (4) E1_set01_M=mAS23    : [OG]
  (5) E1_set01_M=mAU64    : [OG]
  (6) E1_set01_M=mBF18    : [OG]
  (7) E1_set01_M=mBF38    : [OG]
  (8) E1_set01_M=mBF92    : [OG]
  (9) E1_set01_M=mBH22    : [OG]
  (10) E1_set01_M=mBI93    : [OG]
  (11) E1_set01_M=mBJ96    : [OG]
  (12) E1_set01_M=mBK70    : [OG]
  (13) E1_set01_M=mBN34    : [OG]
  (14) E1_set01_M=mBP09    : [OG]
  (15) E1_set01_M=mBP98    : [OG]
  (16) E1_set01_M=mBS36    : [OG]
  (17) E1_set01_M=mBS45    : [OG]
  (18) E1_set01_M=mBU17    : [OG]
  (19) E1_set01_M=mBW64    : [OG]
  (20) E1_set01_M=mBY13    : [OG]
  (21) E1_set01_M=mBY93    : [OG]
  (22) E1_set01_M=mCD86    : [OG]
  (23) E1_set01_M=mCF56    : [OG]
  (24) E1_set01_M=mCF78    : [OG]
  (25) E1_set01_M=mCF96    : [OG]
  (26) E1_set01_M=mCG89    : [OG]
  (27) E1_set01_M=mCO66    : [OG]
  (28) E1_set01_M=mCQ94    : [OG]
  (29) E1_set01_M=mCX30    : [OG]
  (30) E1_set01_M=mCZ47    : [OG]
  (31) E1_set01_M=mDD00    : [OG]
  (32) E1_set01_M=mDH60    : [OG]
  (33) E1_set01_M=mDI25    : [OG]
  (34) E1_set01_M=mDI82    : [OG]
  (35) E1_set01_M=mDJ62    : [OG]
  (36) E1_set01_M=mDK28    : [OG]
  (37) E1_set01_M=mDK50    : [OG]
  (38) E1_set01_M=mDL40    : [OG]
  (39) E1_set01_M=mDM53    : [OG]
  (40) E1_set01_M=mDN98    : [OG]
  (41) E1_set01_M=mDP98    : [OG]
  (42) E1_set01_M=mDR32    : [OG]
  (43) E1_set01_M=mDS38    : [OG]
  (44) E1_set01_M=mDT50    : [OG]
  (45) E1_set01_M=mDT62    : [OG]
  (46) E1_set01_M=mDT74    : [OG]
  (47) E1_set01_M=mED29    : [OG]
  (48) E1_set01_M=mED66    : [OG]
  (49) E1_set01_M=mEE75    : [OG]
  (50) E1_set01_M=mEK25    : [OG]

- **Unhealthy configs**

- **Unknown configs**


Node and signal types:
---------------------------------------------
*_(<node_num>) <node_type> : [<signal_types>]_*

  (1) ammf   : [acc_rx, acc_ry, acc_rz, acc_x, acc_y, acc_z]

Node group name: ammf
Signal group name: acc



For ds_type 'OK' and others....

Maximum timesteps across all node types: 4,098

No data interpolation applied.

'fs' is updated in data_config as given in loaded healthy (or unknown) data.
New fs:
[[2500.0002, 2500.0002, 2500.0002, 2500.0002, 2500.0002, 2500.0002]]

Exclusive rep numbers found in keys of hdf5 file. Hence, using them as rep numbers.


[1 sample = (n_nodes, n_timesteps (window_length), n_dims)]
---------------------------------------------
Total samples: 2396 
Train: 1900/1916 [OK=1900, NOK=0, UK=0], Test: 450/479 [OK=450, NOK=0, UK=0], Val: 0/0 [OK=0, NOK=0, UK=0],
Remainder: 1 [OK=1, NOK=0, UK=0]

train_data_loader statistics:
Number of batches: 38
torch.Size([50, 1, 1000, 6])  => (batch_size, n_nodes, n_timesteps, n_dims)

test_data_loader statistics:
Number of batches: 9
torch.Size([50, 1, 1000, 6]) 

---------------------------------------------------------------------------

Anomaly Detector Model Initialized with the following configurations:
Model type: OneClassSVM
Kernel: rbf
Gamma: scale
Nu: 0.001

---------------------------------------------------------------------------
Model parameters saved to C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4.

Training environment set. Training will be logged at: C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4

---------------------------------------------------------------------------

Initializing input processors for anomaly detection model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> No raw data normalization is applied

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

No seperate features extracted, so using components as features: [comp0_dim0, comp0_dim1, comp0_dim2, comp0_dim3...comp999_dim2, comp999_dim3, comp999_dim4, comp999_dim5]

Fitting anomaly detection model...

Model fitted successfully in 14.89 seconds

Training inference completed in 35.66 seconds

Dataframe is as follows:
      comp0_dim0  comp0_dim1  comp0_dim2  ...    rep_num    scores  pred_label
0      -0.000115   -0.000453    0.000026  ...   6015.001  0.041872           0
1       0.000081    0.000102    0.000061  ...  11002.001  0.032953           0
2       0.000004   -0.000268   -0.000066  ...   1038.003  0.025264           0
3      -0.000060   -0.000229    0.000331  ...  12020.001  0.007993           0
4      -0.000141   -0.000344    0.000201  ...  12038.002  0.017727           0
...          ...         ...         ...  ...        ...       ...         ...
1895    0.000270   -0.000017    0.000093  ...   8032.001 -0.000052           1
1896   -0.000194    0.000051   -0.000002  ...   8045.004  0.035813           0
1897    0.000082    0.000098   -0.000172  ...   7023.002  0.006644           0
1898   -0.000160   -0.000465    0.000183  ...   7032.001 -0.000014           1
1899    0.000003    0.000297   -0.000254  ...   9009.004  0.052718           0

[1900 rows x 6004 columns]

Training accuracy: 0.96

Training hyperparameters logged for tensorboard at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4

Model saved at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\anomaly_detector.pkl

---------------------------------------------------------------------------

Testing environment set. Testing will be logged at: C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\test

Testing anomaly detection model...

Initializing input processors for anomaly detection model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> No raw data normalization is applied

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

No seperate features extracted, so using components as features: [comp0_dim0, comp0_dim1, comp0_dim2, comp0_dim3...comp999_dim2, comp999_dim3, comp999_dim4, comp999_dim5]

Test inference completed in 5.12 seconds

Dataframe is as follows:
     comp0_dim0  comp0_dim1  comp0_dim2  ...    rep_num    scores  pred_label
0      0.000143    0.000291   -0.000111  ...   2045.003  0.030191           0
1     -0.000093   -0.000290    0.000021  ...   3017.002  0.008423           0
2      0.000219   -0.000409    0.000238  ...   5025.002  0.050348           0
3      0.000029    0.000100    0.000245  ...   2048.003 -0.003083           1
4      0.000175   -0.000117   -0.000205  ...   3038.004  0.015973           0
..          ...         ...         ...  ...        ...       ...         ...
445   -0.000347    0.000123   -0.000006  ...   2023.003  0.010453           0
446   -0.000119   -0.000030   -0.000024  ...  11008.002  0.037543           0
447    0.000160    0.000434   -0.000437  ...  12034.001  0.011321           0
448   -0.000254    0.000074    0.000050  ...  12047.001  0.041688           0
449   -0.000159   -0.000372    0.000069  ...   5020.002 -0.012202           1

[450 rows x 6004 columns]

Test accuracy: 0.89
Precision: 0.00, Recall: 0.00, F1-score: 0.00

Testing hyperparameters logged for tensorboard at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\test

---------------------------------------------------------------------------

<<<<<<<<<<<< CONFUSION MATRIX >>>>>>>>>>>>

> Creating confusion matrix for [ammf_(acc+E1)]-1SVM_fdet_4 / test...

Confusion matrix logged at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\test


<<<<<<<<<<<< ANOMALY SCORE DISTRIBUTION (PRED_LABEL) >>>>>>>>>>>>

Creating anomaly score distribution plot for [ammf_(acc+E1)]-1SVM_fdet_4 / test...

Total OK samples (from pred_label) : 402
---------- Samples in OK bins ----------
- **Bin 13 (-0.00137, 0.00018)**: 42 (11,048.004)
- **Bin 14 (0.00018, 0.00172)**: 9 (5,005.001), 52 (2,017.001), 341 (6,007.003)
- **Bin 15 (0.00172, 0.00327)**: 25 (6,032.001), 89 (10,020.004), 178 (6,007.004), 225 (9,046.002), 342 (4,005.003), 348 (6,032.002), 386 (5,032.002)
- **Bin 16 (0.00327, 0.00482)**: 433 (2,016.003)
- **Bin 17 (0.00482, 0.00636)**: 33 (3,048.003), 210 (3,034.004), 219 (9,011.002), 246 (3,020.004), 339 (11,005.002)
- **Bin 18 (0.00636, 0.00791)**: 138 (3,005.002), 333 (10,048.004), 441 (1,016.003)
- **Bin 19 (0.00791, 0.00945)**: 1 (3,017.002), 91 (12,043.004), 148 (2,032.004), 207 (7,003.004), 304 (5,016.002), 323 (6,048.003), 390 (3,046.001)
- **Bin 20 (0.00945, 0.01100)**: 6 (5,007.004), 24 (4,023.001), 81 (1,016.004), 268 (3,033.004), 278 (7,033.003), 327 (5,033.003), 345 (1,029.002), 357 (7,005.004), 379 (7,011.004), 435 (8,016.003), 445 (2,023.003)
- **Bin 21 (0.01100, 0.01254)**: 125 (3,046.003), 129 (4,023.003), 177 (11,016.001), 191 (3,019.002), 215 (4,023.002), 239 (5,044.004), 256 (7,048.004), 381 (10,011.004), 447 (12,034.001)
- **Bin 22 (0.01254, 0.01409)**: 63 (6,028.003), 69 (2,016.001), 97 (11,044.002), 123 (3,016.001), 164 (5,029.003), 200 (8,041.004), 317 (4,034.002), 343 (7,023.003), 383 (1,048.004)
- **Bin 23 (0.01409, 0.01564)**: 104 (8,034.001), 133 (8,019.004), 316 (3,023.002), 376 (2,003.002), 391 (6,040.003), 414 (2,011.003)
- **Bin 24 (0.01564, 0.01718)**: 4 (3,038.004), 10 (6,034.004), 11 (8,038.003), 12 (12,007.002), 36 (5,019.002), 58 (11,034.004), 65 (8,023.001), 126 (5,003.003), 277 (1,028.003)
- **Bin 25 (0.01718, 0.01873)**: 86 (10,019.002), 116 (6,034.002), 127 (3,011.001), 153 (3,012.002), 192 (10,008.004), 197 (1,012.003), 205 (10,029.001), 270 (6,016.001), 377 (8,029.003), 395 (2,022.003), 396 (10,004.004)
- **Bin 26 (0.01873, 0.02027)**: 82 (4,017.003), 102 (5,038.002), 135 (9,017.003), 154 (12,008.003), 161 (3,048.004), 169 (8,023.002), 182 (4,034.003), 183 (1,012.004), 229 (9,011.004), 230 (2,034.004), 274 (3,044.001), 284 (12,038.001), 289 (3,028.001), 292 (8,018.004), 346 (8,018.001), 365 (9,023.001), 405 (9,003.001)
- **Bin 27 (0.02027, 0.02182)**: 18 (11,016.004), 35 (1,001.004), 43 (6,046.002), 45 (2,018.002), 105 (10,034.001), 114 (8,046.002), 121 (5,011.003), 131 (2,001.001), 142 (11,011.002), 157 (4,004.004), 226 (7,040.003), 227 (9,019.001), 236 (8,044.003), 271 (1,026.003), 287 (11,031.001), 298 (6,028.002), 308 (7,019.004), 322 (8,042.002), 325 (1,004.003), 330 (9,044.002), 353 (10,018.002), 372 (11,038.002), 380 (5,040.004), 382 (7,003.001), 400 (2,029.003), 401 (10,031.003), 413 (12,023.002)
- **Bin 28 (0.02182, 0.02337)**: 50 (11,038.004), 61 (12,019.002), 72 (11,012.002), 78 (12,022.004), 90 (8,023.004), 122 (5,040.001), 152 (10,029.004), 160 (8,041.003), 174 (10,017.003), 190 (2,018.003), 260 (3,004.004), 262 (10,026.003), 324 (11,004.001), 334 (2,018.004), 338 (11,012.001), 359 (5,021.001), 416 (2,034.003)
- **Bin 29 (0.02337, 0.02491)**: 68 (8,019.002), 93 (1,022.004), 106 (2,040.004), 115 (6,022.004), 145 (5,004.003), 151 (12,033.004), 159 (3,023.001), 166 (1,026.004), 172 (2,031.003), 179 (5,041.001), 187 (10,026.004), 247 (4,028.004), 285 (12,029.002), 314 (10,022.004), 358 (2,040.002), 434 (3,021.001)
- **Bin 30 (0.02491, 0.02646)**: 7 (5,042.004), 19 (8,001.002), 26 (2,034.002), 59 (8,019.003), 60 (9,004.004), 199 (1,001.003), 216 (6,044.004), 302 (3,010.001), 369 (11,017.004), 384 (12,018.002), 417 (5,040.002), 428 (9,022.004)
- **Bin 31 (0.02646, 0.02800)**: 48 (7,018.002), 79 (3,018.001), 92 (5,036.002), 143 (4,026.002), 186 (9,031.002), 198 (12,004.001), 224 (8,050.001), 257 (7,031.001), 297 (7,012.004), 321 (2,012.004), 331 (8,011.004), 352 (7,004.002), 367 (6,044.002), 398 (3,011.003), 421 (10,042.002), 438 (6,004.001)
- **Bin 32 (0.02800, 0.02955)**: 94 (5,028.003), 113 (4,012.002), 132 (7,012.002), 208 (5,050.001), 248 (10,036.003), 265 (9,019.002), 301 (4,044.003), 374 (10,038.001), 418 (5,046.001)
- **Bin 33 (0.02955, 0.03109)**: 0 (2,045.003), 20 (5,001.002), 77 (11,026.001), 109 (4,001.001), 130 (2,036.001), 136 (1,038.001), 150 (3,004.002), 156 (10,011.002), 167 (7,045.003), 181 (3,016.004), 188 (4,045.001), 223 (1,039.004), 231 (6,026.001), 235 (12,021.002), 282 (4,010.001), 310 (6,050.002), 318 (2,001.004), 361 (4,019.003), 402 (6,004.002), 409 (1,036.004), 423 (1,011.002)
- **Bin 34 (0.03109, 0.03264)**: 31 (4,014.002), 34 (3,045.002), 41 (4,027.002), 56 (3,050.002), 64 (3,018.004), 76 (3,036.004), 87 (12,017.001), 162 (3,036.003), 211 (7,001.002), 218 (3,004.003), 228 (12,001.002), 237 (6,045.001), 269 (1,006.001), 286 (2,028.002), 291 (7,048.001), 399 (8,050.002), 425 (7,050.002)
- **Bin 35 (0.03264, 0.03419)**: 49 (1,026.001), 84 (1,027.002), 111 (9,036.001), 120 (4,046.001), 128 (4,001.003), 139 (7,036.004), 144 (7,041.004), 155 (6,037.003), 232 (1,002.002), 240 (2,045.001), 252 (8,041.002), 254 (1,041.002), 255 (4,008.001), 264 (10,010.004), 266 (1,014.002), 283 (10,026.001), 300 (10,010.003), 303 (4,014.003), 305 (7,024.003), 336 (12,026.002), 360 (3,002.003), 362 (4,002.004), 368 (8,037.002), 440 (8,050.004)
- **Bin 36 (0.03419, 0.03573)**: 17 (11,037.004), 75 (3,012.004), 85 (8,022.002), 101 (1,022.002), 141 (2,027.003), 158 (7,047.001), 165 (4,027.003), 170 (12,022.002), 195 (3,022.001), 241 (7,010.004), 267 (3,045.003), 332 (5,050.003), 385 (4,039.001), 426 (11,012.003), 439 (12,026.001), 443 (12,039.001)
- **Bin 37 (0.03573, 0.03728)**: 40 (9,050.003), 54 (9,042.001), 66 (6,039.001), 74 (8,014.003), 100 (5,014.004), 203 (3,022.002), 281 (6,026.004), 307 (12,027.003), 363 (3,031.001), 387 (2,010.003), 389 (1,036.001), 394 (8,037.001), 408 (12,049.002), 411 (5,050.004), 431 (1,039.002)
- **Bin 38 (0.03728, 0.03882)**: 62 (6,002.002), 99 (2,030.002), 175 (1,011.001), 238 (2,010.002), 299 (8,014.001), 312 (7,014.003), 315 (12,024.003), 337 (2,037.003), 366 (2,019.001), 397 (4,039.002), 410 (10,024.002), 446 (11,008.002)
- **Bin 39 (0.03882, 0.04037)**: 8 (1,045.004), 38 (10,047.003), 51 (3,049.001), 80 (9,012.004), 112 (2,039.001), 137 (9,015.001), 146 (12,021.003), 184 (7,041.002), 209 (3,024.003), 250 (9,024.003), 261 (7,013.003), 279 (3,002.002), 293 (9,009.002), 351 (9,039.003), 375 (5,025.003)
- **Bin 40 (0.04037, 0.04192)**: 16 (6,024.001), 29 (6,027.004), 37 (7,049.004), 108 (4,013.001), 110 (5,008.003), 149 (7,025.002), 168 (6,049.001), 171 (8,026.003), 193 (2,014.002), 214 (12,049.001), 263 (5,049.004), 311 (12,009.001), 371 (10,009.001), 448 (12,047.001)
- **Bin 41 (0.04192, 0.04346)**: 27 (11,024.001), 98 (8,010.003), 202 (5,024.001), 204 (6,025.002), 217 (10,013.002), 220 (1,039.001), 234 (7,025.003), 253 (1,009.004), 258 (9,021.004), 288 (6,025.001), 290 (10,041.003), 294 (6,030.003), 313 (7,017.001), 326 (3,015.003), 335 (4,049.001), 349 (5,014.001), 388 (6,013.002), 392 (10,009.003), 393 (2,025.004)
- **Bin 42 (0.04346, 0.04501)**: 46 (6,009.003), 83 (3,025.002), 185 (2,025.001), 189 (9,015.003), 213 (5,013.001), 249 (9,023.004), 329 (9,037.004), 364 (4,013.004), 422 (6,013.003), 430 (8,002.001)
- **Bin 43 (0.04501, 0.04655)**: 15 (3,045.004), 140 (1,047.001), 242 (7,009.001), 244 (6,047.003), 251 (7,024.004), 273 (8,025.002), 370 (12,030.003), 378 (6,036.004), 404 (4,025.004), 432 (3,013.001), 442 (8,030.001)
- **Bin 44 (0.04655, 0.04810)**: 30 (9,030.001), 32 (12,023.004), 39 (11,025.003), 44 (6,009.001), 53 (9,001.004), 57 (9,047.003), 67 (7,025.004), 95 (3,030.003), 119 (5,030.003), 272 (11,035.001), 306 (2,013.002), 344 (9,025.003), 356 (6,024.004), 427 (8,013.003)
- **Bin 45 (0.04810, 0.04965)**: 28 (6,045.004), 96 (1,015.004), 118 (6,049.004), 233 (2,013.004), 412 (11,035.004)
- **Bin 46 (0.04965, 0.05119)**: 2 (5,025.002), 88 (10,015.002), 163 (9,049.004), 276 (2,047.003), 340 (12,025.004), 406 (6,015.004), 420 (12,036.004)
- **Bin 48 (0.05274, 0.05428)**: 212 (8,035.004), 320 (2,035.001), 436 (11,035.003)
- **Bin 49 (0.05428, 0.05583)**: 73 (8,047.003), 124 (9,015.004)

Total NOK samples (from pred_label) : 48
---------- Samples in NOK bins ----------
- **Bin 0 (-0.02146, -0.01992)**: 22 (10,043.004), 23 (7,043.004), 103 (7,043.001), 243 (4,043.002), 245 (9,043.003), 347 (12,006.001), 354 (8,043.003)
- **Bin 1 (-0.01992, -0.01837)**: 173 (1,043.003), 275 (11,043.004), 280 (3,006.001), 328 (11,006.004), 403 (7,043.003), 437 (5,006.004)
- **Bin 2 (-0.01837, -0.01683)**: 14 (2,043.004), 47 (4,043.004), 194 (12,006.002), 295 (8,043.002), 429 (8,043.001)
- **Bin 3 (-0.01683, -0.01528)**: 71 (1,006.004), 259 (3,006.002)
- **Bin 4 (-0.01528, -0.01374)**: 206 (11,046.001), 221 (2,043.002)
- **Bin 5 (-0.01374, -0.01219)**: 5 (5,043.002), 449 (5,020.002)
- **Bin 7 (-0.01064, -0.00910)**: 222 (12,007.001), 319 (2,007.002)
- **Bin 8 (-0.00910, -0.00755)**: 355 (1,020.001), 407 (1,007.003)
- **Bin 9 (-0.00755, -0.00601)**: 70 (7,033.002)
- **Bin 10 (-0.00601, -0.00446)**: 196 (5,048.002), 350 (5,048.003), 424 (8,048.003)
- **Bin 11 (-0.00446, -0.00291)**: 3 (2,048.003), 21 (2,020.003), 117 (8,020.004), 147 (7,020.003), 180 (6,020.004), 296 (7,020.002), 309 (8,048.002), 373 (3,005.004), 419 (4,007.003), 444 (1,032.002)
- **Bin 12 (-0.00291, -0.00137)**: 13 (3,020.002), 107 (8,007.003), 176 (12,020.003), 415 (4,005.001)
- **Bin 13 (-0.00137, 0.00018)**: 134 (8,046.001), 201 (6,046.003)


Anomaly score distribution plot logged at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\test


<<<<<<<<<<<< ANOMALY SCORE DISTRIBUTION (GIVEN_LABEL) >>>>>>>>>>>>

Creating anomaly score distribution plot for [ammf_(acc+E1)]-1SVM_fdet_4 / test...

Total OK samples (from given_label) : 450
---------- Samples in OK bins ----------
- **Bin 0 (-0.02146, -0.01992)**: 22 (10,043.004), 23 (7,043.004), 103 (7,043.001), 243 (4,043.002), 245 (9,043.003), 347 (12,006.001), 354 (8,043.003)
- **Bin 1 (-0.01992, -0.01837)**: 173 (1,043.003), 275 (11,043.004), 280 (3,006.001), 328 (11,006.004), 403 (7,043.003), 437 (5,006.004)
- **Bin 2 (-0.01837, -0.01683)**: 14 (2,043.004), 47 (4,043.004), 194 (12,006.002), 295 (8,043.002), 429 (8,043.001)
- **Bin 3 (-0.01683, -0.01528)**: 71 (1,006.004), 259 (3,006.002)
- **Bin 4 (-0.01528, -0.01374)**: 206 (11,046.001), 221 (2,043.002)
- **Bin 5 (-0.01374, -0.01219)**: 5 (5,043.002), 449 (5,020.002)
- **Bin 7 (-0.01064, -0.00910)**: 222 (12,007.001), 319 (2,007.002)
- **Bin 8 (-0.00910, -0.00755)**: 355 (1,020.001), 407 (1,007.003)
- **Bin 9 (-0.00755, -0.00601)**: 70 (7,033.002)
- **Bin 10 (-0.00601, -0.00446)**: 196 (5,048.002), 350 (5,048.003), 424 (8,048.003)
- **Bin 11 (-0.00446, -0.00291)**: 3 (2,048.003), 21 (2,020.003), 117 (8,020.004), 147 (7,020.003), 180 (6,020.004), 296 (7,020.002), 309 (8,048.002), 373 (3,005.004), 419 (4,007.003), 444 (1,032.002)
- **Bin 12 (-0.00291, -0.00137)**: 13 (3,020.002), 107 (8,007.003), 176 (12,020.003), 415 (4,005.001)
- **Bin 13 (-0.00137, 0.00018)**: 42 (11,048.004), 134 (8,046.001), 201 (6,046.003)
- **Bin 14 (0.00018, 0.00172)**: 9 (5,005.001), 52 (2,017.001), 341 (6,007.003)
- **Bin 15 (0.00172, 0.00327)**: 25 (6,032.001), 89 (10,020.004), 178 (6,007.004), 225 (9,046.002), 342 (4,005.003), 348 (6,032.002), 386 (5,032.002)
- **Bin 16 (0.00327, 0.00482)**: 433 (2,016.003)
- **Bin 17 (0.00482, 0.00636)**: 33 (3,048.003), 210 (3,034.004), 219 (9,011.002), 246 (3,020.004), 339 (11,005.002)
- **Bin 18 (0.00636, 0.00791)**: 138 (3,005.002), 333 (10,048.004), 441 (1,016.003)
- **Bin 19 (0.00791, 0.00945)**: 1 (3,017.002), 91 (12,043.004), 148 (2,032.004), 207 (7,003.004), 304 (5,016.002), 323 (6,048.003), 390 (3,046.001)
- **Bin 20 (0.00945, 0.01100)**: 6 (5,007.004), 24 (4,023.001), 81 (1,016.004), 268 (3,033.004), 278 (7,033.003), 327 (5,033.003), 345 (1,029.002), 357 (7,005.004), 379 (7,011.004), 435 (8,016.003), 445 (2,023.003)
- **Bin 21 (0.01100, 0.01254)**: 125 (3,046.003), 129 (4,023.003), 177 (11,016.001), 191 (3,019.002), 215 (4,023.002), 239 (5,044.004), 256 (7,048.004), 381 (10,011.004), 447 (12,034.001)
- **Bin 22 (0.01254, 0.01409)**: 63 (6,028.003), 69 (2,016.001), 97 (11,044.002), 123 (3,016.001), 164 (5,029.003), 200 (8,041.004), 317 (4,034.002), 343 (7,023.003), 383 (1,048.004)
- **Bin 23 (0.01409, 0.01564)**: 104 (8,034.001), 133 (8,019.004), 316 (3,023.002), 376 (2,003.002), 391 (6,040.003), 414 (2,011.003)
- **Bin 24 (0.01564, 0.01718)**: 4 (3,038.004), 10 (6,034.004), 11 (8,038.003), 12 (12,007.002), 36 (5,019.002), 58 (11,034.004), 65 (8,023.001), 126 (5,003.003), 277 (1,028.003)
- **Bin 25 (0.01718, 0.01873)**: 86 (10,019.002), 116 (6,034.002), 127 (3,011.001), 153 (3,012.002), 192 (10,008.004), 197 (1,012.003), 205 (10,029.001), 270 (6,016.001), 377 (8,029.003), 395 (2,022.003), 396 (10,004.004)
- **Bin 26 (0.01873, 0.02027)**: 82 (4,017.003), 102 (5,038.002), 135 (9,017.003), 154 (12,008.003), 161 (3,048.004), 169 (8,023.002), 182 (4,034.003), 183 (1,012.004), 229 (9,011.004), 230 (2,034.004), 274 (3,044.001), 284 (12,038.001), 289 (3,028.001), 292 (8,018.004), 346 (8,018.001), 365 (9,023.001), 405 (9,003.001)
- **Bin 27 (0.02027, 0.02182)**: 18 (11,016.004), 35 (1,001.004), 43 (6,046.002), 45 (2,018.002), 105 (10,034.001), 114 (8,046.002), 121 (5,011.003), 131 (2,001.001), 142 (11,011.002), 157 (4,004.004), 226 (7,040.003), 227 (9,019.001), 236 (8,044.003), 271 (1,026.003), 287 (11,031.001), 298 (6,028.002), 308 (7,019.004), 322 (8,042.002), 325 (1,004.003), 330 (9,044.002), 353 (10,018.002), 372 (11,038.002), 380 (5,040.004), 382 (7,003.001), 400 (2,029.003), 401 (10,031.003), 413 (12,023.002)
- **Bin 28 (0.02182, 0.02337)**: 50 (11,038.004), 61 (12,019.002), 72 (11,012.002), 78 (12,022.004), 90 (8,023.004), 122 (5,040.001), 152 (10,029.004), 160 (8,041.003), 174 (10,017.003), 190 (2,018.003), 260 (3,004.004), 262 (10,026.003), 324 (11,004.001), 334 (2,018.004), 338 (11,012.001), 359 (5,021.001), 416 (2,034.003)
- **Bin 29 (0.02337, 0.02491)**: 68 (8,019.002), 93 (1,022.004), 106 (2,040.004), 115 (6,022.004), 145 (5,004.003), 151 (12,033.004), 159 (3,023.001), 166 (1,026.004), 172 (2,031.003), 179 (5,041.001), 187 (10,026.004), 247 (4,028.004), 285 (12,029.002), 314 (10,022.004), 358 (2,040.002), 434 (3,021.001)
- **Bin 30 (0.02491, 0.02646)**: 7 (5,042.004), 19 (8,001.002), 26 (2,034.002), 59 (8,019.003), 60 (9,004.004), 199 (1,001.003), 216 (6,044.004), 302 (3,010.001), 369 (11,017.004), 384 (12,018.002), 417 (5,040.002), 428 (9,022.004)
- **Bin 31 (0.02646, 0.02800)**: 48 (7,018.002), 79 (3,018.001), 92 (5,036.002), 143 (4,026.002), 186 (9,031.002), 198 (12,004.001), 224 (8,050.001), 257 (7,031.001), 297 (7,012.004), 321 (2,012.004), 331 (8,011.004), 352 (7,004.002), 367 (6,044.002), 398 (3,011.003), 421 (10,042.002), 438 (6,004.001)
- **Bin 32 (0.02800, 0.02955)**: 94 (5,028.003), 113 (4,012.002), 132 (7,012.002), 208 (5,050.001), 248 (10,036.003), 265 (9,019.002), 301 (4,044.003), 374 (10,038.001), 418 (5,046.001)
- **Bin 33 (0.02955, 0.03109)**: 0 (2,045.003), 20 (5,001.002), 77 (11,026.001), 109 (4,001.001), 130 (2,036.001), 136 (1,038.001), 150 (3,004.002), 156 (10,011.002), 167 (7,045.003), 181 (3,016.004), 188 (4,045.001), 223 (1,039.004), 231 (6,026.001), 235 (12,021.002), 282 (4,010.001), 310 (6,050.002), 318 (2,001.004), 361 (4,019.003), 402 (6,004.002), 409 (1,036.004), 423 (1,011.002)
- **Bin 34 (0.03109, 0.03264)**: 31 (4,014.002), 34 (3,045.002), 41 (4,027.002), 56 (3,050.002), 64 (3,018.004), 76 (3,036.004), 87 (12,017.001), 162 (3,036.003), 211 (7,001.002), 218 (3,004.003), 228 (12,001.002), 237 (6,045.001), 269 (1,006.001), 286 (2,028.002), 291 (7,048.001), 399 (8,050.002), 425 (7,050.002)
- **Bin 35 (0.03264, 0.03419)**: 49 (1,026.001), 84 (1,027.002), 111 (9,036.001), 120 (4,046.001), 128 (4,001.003), 139 (7,036.004), 144 (7,041.004), 155 (6,037.003), 232 (1,002.002), 240 (2,045.001), 252 (8,041.002), 254 (1,041.002), 255 (4,008.001), 264 (10,010.004), 266 (1,014.002), 283 (10,026.001), 300 (10,010.003), 303 (4,014.003), 305 (7,024.003), 336 (12,026.002), 360 (3,002.003), 362 (4,002.004), 368 (8,037.002), 440 (8,050.004)
- **Bin 36 (0.03419, 0.03573)**: 17 (11,037.004), 75 (3,012.004), 85 (8,022.002), 101 (1,022.002), 141 (2,027.003), 158 (7,047.001), 165 (4,027.003), 170 (12,022.002), 195 (3,022.001), 241 (7,010.004), 267 (3,045.003), 332 (5,050.003), 385 (4,039.001), 426 (11,012.003), 439 (12,026.001), 443 (12,039.001)
- **Bin 37 (0.03573, 0.03728)**: 40 (9,050.003), 54 (9,042.001), 66 (6,039.001), 74 (8,014.003), 100 (5,014.004), 203 (3,022.002), 281 (6,026.004), 307 (12,027.003), 363 (3,031.001), 387 (2,010.003), 389 (1,036.001), 394 (8,037.001), 408 (12,049.002), 411 (5,050.004), 431 (1,039.002)
- **Bin 38 (0.03728, 0.03882)**: 62 (6,002.002), 99 (2,030.002), 175 (1,011.001), 238 (2,010.002), 299 (8,014.001), 312 (7,014.003), 315 (12,024.003), 337 (2,037.003), 366 (2,019.001), 397 (4,039.002), 410 (10,024.002), 446 (11,008.002)
- **Bin 39 (0.03882, 0.04037)**: 8 (1,045.004), 38 (10,047.003), 51 (3,049.001), 80 (9,012.004), 112 (2,039.001), 137 (9,015.001), 146 (12,021.003), 184 (7,041.002), 209 (3,024.003), 250 (9,024.003), 261 (7,013.003), 279 (3,002.002), 293 (9,009.002), 351 (9,039.003), 375 (5,025.003)
- **Bin 40 (0.04037, 0.04192)**: 16 (6,024.001), 29 (6,027.004), 37 (7,049.004), 108 (4,013.001), 110 (5,008.003), 149 (7,025.002), 168 (6,049.001), 171 (8,026.003), 193 (2,014.002), 214 (12,049.001), 263 (5,049.004), 311 (12,009.001), 371 (10,009.001), 448 (12,047.001)
- **Bin 41 (0.04192, 0.04346)**: 27 (11,024.001), 98 (8,010.003), 202 (5,024.001), 204 (6,025.002), 217 (10,013.002), 220 (1,039.001), 234 (7,025.003), 253 (1,009.004), 258 (9,021.004), 288 (6,025.001), 290 (10,041.003), 294 (6,030.003), 313 (7,017.001), 326 (3,015.003), 335 (4,049.001), 349 (5,014.001), 388 (6,013.002), 392 (10,009.003), 393 (2,025.004)
- **Bin 42 (0.04346, 0.04501)**: 46 (6,009.003), 83 (3,025.002), 185 (2,025.001), 189 (9,015.003), 213 (5,013.001), 249 (9,023.004), 329 (9,037.004), 364 (4,013.004), 422 (6,013.003), 430 (8,002.001)
- **Bin 43 (0.04501, 0.04655)**: 15 (3,045.004), 140 (1,047.001), 242 (7,009.001), 244 (6,047.003), 251 (7,024.004), 273 (8,025.002), 370 (12,030.003), 378 (6,036.004), 404 (4,025.004), 432 (3,013.001), 442 (8,030.001)
- **Bin 44 (0.04655, 0.04810)**: 30 (9,030.001), 32 (12,023.004), 39 (11,025.003), 44 (6,009.001), 53 (9,001.004), 57 (9,047.003), 67 (7,025.004), 95 (3,030.003), 119 (5,030.003), 272 (11,035.001), 306 (2,013.002), 344 (9,025.003), 356 (6,024.004), 427 (8,013.003)
- **Bin 45 (0.04810, 0.04965)**: 28 (6,045.004), 96 (1,015.004), 118 (6,049.004), 233 (2,013.004), 412 (11,035.004)
- **Bin 46 (0.04965, 0.05119)**: 2 (5,025.002), 88 (10,015.002), 163 (9,049.004), 276 (2,047.003), 340 (12,025.004), 406 (6,015.004), 420 (12,036.004)
- **Bin 48 (0.05274, 0.05428)**: 212 (8,035.004), 320 (2,035.001), 436 (11,035.003)
- **Bin 49 (0.05428, 0.05583)**: 73 (8,047.003), 124 (9,015.004)

Total NOK samples (from given_label) : 0
---------- Samples in NOK bins ----------


Anomaly score distribution plot logged at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\test


<<<<<<<<<<<< PAIR PLOT >>>>>>>>>>>>

> Creating pair plot for [ammf_(acc+E1)]-1SVM_fdet_4 / test...

Pair plot logged at C:\AFD\fault_detection\logs\asml\NXE\full_wafer\train\ammf\acc\set_E1\1SVM\tswp_1\[ammf_(acc+E1)]-1SVM_fdet_4\test


===========================================================================

Fault detection model '[ammf_(acc+E1)]-1SVM_fdet_4' training completed.


=== EXECUTION COMPLETED ===
Log saved at: 2025-09-02 07:19:19
