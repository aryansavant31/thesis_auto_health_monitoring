=== SCRIPT EXECUTION LOG ===
Script: topology_estimation.train.py
Base Name: [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12
Start Time: 2025-09-17 11:58:35
End Time: 2025-09-17 12:09:13

CPU: Intel64 Family 6 Model 154 Stepping 3, GenuineIntel (Cores: 20), Max Frequency: 2300.00 MHz
GPUs Detected: 1
GPU 0: NVIDIA GeForce RTX 3050 Ti Laptop GPU, Memory: 4.00 GB
OS: Windows 11 (10.0.26100)

Python Version: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 12:58:53) [MSC v.1929 64 bit (AMD64)]
========================================================================================================================


Starting nri model training...

'Train' type dataset selected:


Dataset selections:
---------------------------------------------
*_(<ds_subtype_num>) <ds_subtype> : [<augments>]_*

- **Healthy configs**
  (1) series_tp    : [OG]

- **Unhealthy configs**

- **Unknown configs**


Node and signal types:
---------------------------------------------
*_(<node_num>) <node_type> : [<signal_types>]_*

  (1) mass_1   : [acc, pos, vel]
  (2) mass_2   : [acc, pos, vel]
  (3) mass_3   : [acc, pos, vel]
  (4) mass_4   : [acc, pos, vel]

Node group name: m004
Signal group name: apv


For ds_type 'OK' and others....
---------------------------------------------
Maximum timesteps across all node types: 500,001

No data interpolation applied.

'fs' is updated in data_config as given in loaded healthy (or unknown) data.
New fs:
[[500., 500., 500.],
 [500., 500., 500.],
 [500., 500., 500.],
 [500., 500., 500.]]

No exclusive rep numbers found in keys of hfd5 file. Hence, using default rep numbers.


[1 sample = (n_nodes, n_timesteps (window_length), n_dims)]
------------------------------------------------------------
Total samples: 5000 
Train: 4000/4000 [OK=4000, NOK=0, UK=0], Test: 500/500 [OK=500, NOK=0, UK=0], Val: 500/500 [OK=500, NOK=0, UK=0],
Remainder: 0 [OK=0, NOK=0, UK=0]

train_data_loader statistics:
Number of batches: 80
torch.Size([50, 4, 100, 3])  => (batch_size, n_nodes, n_timesteps, n_dims)

test_data_loader statistics:
Number of batches: 10
torch.Size([50, 4, 100, 3]) 

val_data_loader statistics:
Number of batches: 10
torch.Size([50, 4, 100, 3]) 

---------------------------------------------------------------------------

Loading Relation Matrices...

Relation Matrices loaded successfully.

## Relation Matrices Summary 

**Adjacency matrix for input** => shape: (4, 4)
     n1   n2   n3   n4
n1  0.0  1.0  1.0  1.0
n2  1.0  0.0  1.0  1.0
n3  1.0  1.0  0.0  1.0
n4  1.0  1.0  1.0  0.0


**Receiver relation matrix** => shape: (12, 4)
      n1   n2   n3   n4
e12  0.0  1.0  0.0  0.0
e13  0.0  0.0  1.0  0.0
e14  0.0  0.0  0.0  1.0
e21  1.0  0.0  0.0  0.0
e23  0.0  0.0  1.0  0.0
e24  0.0  0.0  0.0  1.0
e31  1.0  0.0  0.0  0.0
e32  0.0  1.0  0.0  0.0
e34  0.0  0.0  0.0  1.0
e41  1.0  0.0  0.0  0.0
e42  0.0  1.0  0.0  0.0
e43  0.0  0.0  1.0  0.0


**Sender relation matrix:** => shape: (12, 4)
      n1   n2   n3   n4
e12  1.0  0.0  0.0  0.0
e13  1.0  0.0  0.0  0.0
e14  1.0  0.0  0.0  0.0
e21  0.0  1.0  0.0  0.0
e23  0.0  1.0  0.0  0.0
e24  0.0  1.0  0.0  0.0
e31  0.0  0.0  1.0  0.0
e32  0.0  0.0  1.0  0.0
e34  0.0  0.0  1.0  0.0
e41  0.0  0.0  0.0  1.0
e42  0.0  0.0  0.0  1.0
e43  0.0  0.0  0.0  1.0


---------------------------------------------------------------------------

<<<<<< ENCODER PARAMETERS >>>>>>
Encoder model parameters:
-------------------------
n_edge_types: 2
is_residual_connection: False
do_prob: {'mlp': 0.0, 'cnn': 0.0}
is_batch_norm: {'mlp': True, 'cnn': False}
is_xavier_weights: True
attention_output_size: 5
domain_config: {'type': 'time', 'cutoff_freq': 0}
raw_data_norm: min_max
feat_configs: []
reduc_config: None
feat_norm: None
pipeline: [['1/node_emd.1', 'mlp'], ['1/pairwise_op', 'concat'], ['1/edge_emd.1.@', 'mlp'], ['2/aggregate', 'mean'], ['2/node_emd.1', 'mlp'], ['2/pairwise_op', 'concat'], ['2/edge_emd.1', 'mlp']]
edge_emb_configs: {'mlp': [[512, 'elu'], [512, 'elu']], 'cnn': [[5, 2, 64], [8]]}
node_emb_configs: {'mlp': [[512, 'elu'], [512, 'elu']], 'cnn': [[5, 2, 64], [8]]}
n_comps: 100
n_dims: 3

<<<<<< DECODER PARAMETERS >>>>>>

Decoder model parameters:
-------------------------
n_edge_types: 2
msg_out_size: 64
edge_mlp_config: [[64, 'tanh'], [64, 'tanh']]
out_mlp_config: [[64, 'relu'], [64, 'relu']]
do_prob: 0
is_batch_norm: False
is_xavier_weights: False
recur_emb_type: gru
domain_config: {'type': 'time', 'cutoff_freq': 0}
raw_data_norm: min_max
feat_configs: []
feat_norm: None
reduc_config: None
n_dims: 3

Decoder run parameters:
-------------------------
is_hard: False
skip_first_edge_type: True
pred_steps: 10
is_burn_in: True
final_pred_steps: 30
is_dynamic_graph: False
show_conf_band: False

Training parameters set to: 
lr_enc=0.0002, 
lr_dec=0.0001, 
final_beta=0.001, 
warmup_frac=0.8, 
optimizer=adam, 
loss_type_encoder=kld, 
loss_type_decoder=mse, 
prior=tensor([0.5000, 0.5000]), 
add_const_kld=True
is_enc_warmup: True, 
warmup_acc_cutoff: 0.85
, 
final_gamma: 0.5, 
warmup_frac_gamma: 0.3


---------------------------------------------------------------------------

NRI Model Initialized with the following configurations:
----- NRI Model Summary -----
-- Encoder Summary
Encoder(
  (emb_fn_dict): ModuleDict(
    (1/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=300, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=512, out_features=512, bias=True)
        (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
    (1/edge_emd1@): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=512, out_features=512, bias=True)
        (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
    (2/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=512, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=512, out_features=512, bias=True)
        (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
    (2/edge_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=1024, out_features=512, bias=True)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=512, out_features=512, bias=True)
        (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
  )
  (attention_layer_dict): ModuleDict()
  (output_layer): Linear(in_features=512, out_features=2, bias=True)
)
-- Decoder Summary
Decoder(
  (edge_mlp_fn): ModuleList(
    (0-1): 2 x MLP(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): Tanh()
        (2): Dropout(p=0, inplace=False)
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): Tanh()
      )
    )
  )
  (recurrent_emb_fn): GRU(
    (input_u): Linear(in_features=3, out_features=64, bias=True)
    (hidden_u): Linear(in_features=64, out_features=64, bias=True)
    (input_r): Linear(in_features=3, out_features=64, bias=True)
    (hidden_r): Linear(in_features=64, out_features=64, bias=True)
    (input_h): Linear(in_features=3, out_features=64, bias=True)
    (hidden_h): Linear(in_features=64, out_features=64, bias=True)
  )
  (mean_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
      (2): Dropout(p=0, inplace=False)
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): ReLU()
    )
  )
  (var_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
      (2): Dropout(p=0, inplace=False)
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): ReLU()
    )
  )
  (mean_output_layer): Linear(in_features=64, out_features=3, bias=True)
  (var_output_layer): Linear(in_features=64, out_features=3, bias=True)
)

---------------------------------------------------------------------------
Model parameters saved to C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12.

Training environment set. Training will be logged at: C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12

---------------------------------------------------------------------------
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.

Initializing input processors for encoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Initializing input processors for decoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------
Step 0, Epoch 1/20, Batch 0/80
temp: 0.9990, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.7321, 
nri_train_loss: 2.0616, enc_train_loss: 1.4804, enc_train_entropy: 0.5698, dec_train_loss: 2.0616, train_edge_accuracy: 0.4817, 

Step 5, Epoch 1/20, Batch 5/80
temp: 0.9990, beta: 0.0000, gamma: 0.0052, 
enc_train_warmup_loss: 0.8007, 
nri_train_loss: 1.6074, enc_train_loss: 6.9398, enc_train_entropy: 0.1148, dec_train_loss: 1.6032, train_edge_accuracy: 0.4883, 

Step 10, Epoch 1/20, Batch 10/80
temp: 0.9990, beta: 0.0000, gamma: 0.0104, 
enc_train_warmup_loss: 0.7920, 
nri_train_loss: 1.3182, enc_train_loss: 6.8919, enc_train_entropy: 0.1188, dec_train_loss: 1.3099, train_edge_accuracy: 0.5017, 

Step 15, Epoch 1/20, Batch 15/80
temp: 0.9990, beta: 0.0000, gamma: 0.0156, 
enc_train_warmup_loss: 0.7818, 
nri_train_loss: 1.0236, enc_train_loss: 6.3250, enc_train_entropy: 0.1661, dec_train_loss: 1.0113, train_edge_accuracy: 0.5050, 

Step 20, Epoch 1/20, Batch 20/80
temp: 0.9990, beta: 0.0000, gamma: 0.0208, 
enc_train_warmup_loss: 0.7826, 
nri_train_loss: 0.8180, enc_train_loss: 7.1197, enc_train_entropy: 0.0998, dec_train_loss: 0.8016, train_edge_accuracy: 0.5183, 

Step 25, Epoch 1/20, Batch 25/80
temp: 0.9990, beta: 0.0000, gamma: 0.0260, 
enc_train_warmup_loss: 0.7733, 
nri_train_loss: 0.6616, enc_train_loss: 7.4569, enc_train_entropy: 0.0717, dec_train_loss: 0.6413, train_edge_accuracy: 0.5250, 

Step 30, Epoch 1/20, Batch 30/80
temp: 0.9990, beta: 0.0000, gamma: 0.0312, 
enc_train_warmup_loss: 0.7827, 
nri_train_loss: 0.5141, enc_train_loss: 7.4721, enc_train_entropy: 0.0705, dec_train_loss: 0.4894, train_edge_accuracy: 0.5217, 

Step 35, Epoch 1/20, Batch 35/80
temp: 0.9990, beta: 0.0000, gamma: 0.0365, 
enc_train_warmup_loss: 0.7715, 
nri_train_loss: 0.4089, enc_train_loss: 7.7466, enc_train_entropy: 0.0476, dec_train_loss: 0.3805, train_edge_accuracy: 0.5367, 

Step 40, Epoch 1/20, Batch 40/80
temp: 0.9990, beta: 0.0000, gamma: 0.0417, 
enc_train_warmup_loss: 0.7427, 
nri_train_loss: 0.3214, enc_train_loss: 7.1148, enc_train_entropy: 0.1003, dec_train_loss: 0.2903, train_edge_accuracy: 0.5533, 

Step 45, Epoch 1/20, Batch 45/80
temp: 0.9990, beta: 0.0000, gamma: 0.0469, 
enc_train_warmup_loss: 0.7108, 
nri_train_loss: 0.2607, enc_train_loss: 7.1423, enc_train_entropy: 0.0980, dec_train_loss: 0.2272, train_edge_accuracy: 0.5933, 

Step 50, Epoch 1/20, Batch 50/80
temp: 0.9990, beta: 0.0000, gamma: 0.0521, 
enc_train_warmup_loss: 0.6765, 
nri_train_loss: 0.2138, enc_train_loss: 7.3082, enc_train_entropy: 0.0841, dec_train_loss: 0.1783, train_edge_accuracy: 0.6333, 

Step 55, Epoch 1/20, Batch 55/80
temp: 0.9990, beta: 0.0000, gamma: 0.0573, 
enc_train_warmup_loss: 0.6492, 
nri_train_loss: 0.1691, enc_train_loss: 7.2087, enc_train_entropy: 0.0924, dec_train_loss: 0.1316, train_edge_accuracy: 0.6617, 

Step 60, Epoch 1/20, Batch 60/80
temp: 0.9990, beta: 0.0000, gamma: 0.0625, 
enc_train_warmup_loss: 0.6307, 
nri_train_loss: 0.1308, enc_train_loss: 7.1564, enc_train_entropy: 0.0968, dec_train_loss: 0.0911, train_edge_accuracy: 0.6767, 

Step 65, Epoch 1/20, Batch 65/80
temp: 0.9990, beta: 0.0001, gamma: 0.0677, 
enc_train_warmup_loss: 0.6106, 
nri_train_loss: 0.1116, enc_train_loss: 7.0746, enc_train_entropy: 0.1036, dec_train_loss: 0.0699, train_edge_accuracy: 0.6983, 

Step 70, Epoch 1/20, Batch 70/80
temp: 0.9990, beta: 0.0001, gamma: 0.0729, 
enc_train_warmup_loss: 0.5719, 
nri_train_loss: 0.0904, enc_train_loss: 6.9957, enc_train_entropy: 0.1102, dec_train_loss: 0.0483, train_edge_accuracy: 0.7283, 

Step 75, Epoch 1/20, Batch 75/80
temp: 0.9990, beta: 0.0001, gamma: 0.0781, 
enc_train_warmup_loss: 0.5311, 
nri_train_loss: 0.0853, enc_train_loss: 6.8921, enc_train_entropy: 0.1188, dec_train_loss: 0.0434, train_edge_accuracy: 0.7633, 


Epoch 1/20 completed, Global Step: 80
nri_train_loss: 0.0853, enc_train_loss: 6.8921, enc_train_warmup_loss: 0.5311, enc_train_entropy: 0.1188, dec_train_loss: 0.0434, train_edge_accuracy: 0.7633
nri_val_loss: 0.0738, enc_val_loss: 6.6609, enc_val_warmup_loss: 0.4232, enc_val_entropy: 0.1381, dec_val_loss: 0.0381, val_edge_accuracy: 0.8910

---------------------------------------------------------------------------

Step 80, Epoch 2/20, Batch 0/80
temp: 0.9990, beta: 0.0001, gamma: 0.0833, 
enc_train_warmup_loss: 0.4324, 
nri_train_loss: 0.0725, enc_train_loss: 6.6474, enc_train_entropy: 0.1392, dec_train_loss: 0.0361, train_edge_accuracy: 0.8833, 


Encoder warmup completed at step 81. Encoder warmup disabled for the rest of training.

Step 85, Epoch 2/20, Batch 5/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0321, enc_train_loss: 6.6758, enc_train_entropy: 0.1368, dec_train_loss: 0.0317, train_edge_accuracy: 0.7083, 

Step 90, Epoch 2/20, Batch 10/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0297, enc_train_loss: 6.9757, enc_train_entropy: 0.1118, dec_train_loss: 0.0292, train_edge_accuracy: 0.6717, 

Step 95, Epoch 2/20, Batch 15/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0284, enc_train_loss: 6.9495, enc_train_entropy: 0.1140, dec_train_loss: 0.0279, train_edge_accuracy: 0.6150, 

Step 100, Epoch 2/20, Batch 20/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0284, enc_train_loss: 7.1403, enc_train_entropy: 0.0981, dec_train_loss: 0.0279, train_edge_accuracy: 0.6050, 

Step 105, Epoch 2/20, Batch 25/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0277, enc_train_loss: 6.9073, enc_train_entropy: 0.1175, dec_train_loss: 0.0271, train_edge_accuracy: 0.6183, 

Step 110, Epoch 2/20, Batch 30/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0264, enc_train_loss: 6.8179, enc_train_entropy: 0.1250, dec_train_loss: 0.0258, train_edge_accuracy: 0.6083, 

Step 115, Epoch 2/20, Batch 35/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0258, enc_train_loss: 7.0707, enc_train_entropy: 0.1039, dec_train_loss: 0.0252, train_edge_accuracy: 0.6217, 

Step 120, Epoch 2/20, Batch 40/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0259, enc_train_loss: 7.0099, enc_train_entropy: 0.1090, dec_train_loss: 0.0253, train_edge_accuracy: 0.6467, 

Step 125, Epoch 2/20, Batch 45/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0256, enc_train_loss: 6.9266, enc_train_entropy: 0.1159, dec_train_loss: 0.0249, train_edge_accuracy: 0.6183, 

Step 130, Epoch 2/20, Batch 50/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0258, enc_train_loss: 6.9695, enc_train_entropy: 0.1124, dec_train_loss: 0.0251, train_edge_accuracy: 0.6167, 

Step 135, Epoch 2/20, Batch 55/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0251, enc_train_loss: 7.0448, enc_train_entropy: 0.1061, dec_train_loss: 0.0244, train_edge_accuracy: 0.6350, 

Step 140, Epoch 2/20, Batch 60/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0249, enc_train_loss: 6.8933, enc_train_entropy: 0.1187, dec_train_loss: 0.0241, train_edge_accuracy: 0.6100, 

Step 145, Epoch 2/20, Batch 65/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0249, enc_train_loss: 6.9348, enc_train_entropy: 0.1152, dec_train_loss: 0.0241, train_edge_accuracy: 0.6350, 

Step 150, Epoch 2/20, Batch 70/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0242, enc_train_loss: 6.7192, enc_train_entropy: 0.1332, dec_train_loss: 0.0234, train_edge_accuracy: 0.6567, 

Step 155, Epoch 2/20, Batch 75/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0242, enc_train_loss: 6.7490, enc_train_entropy: 0.1307, dec_train_loss: 0.0234, train_edge_accuracy: 0.6317, 


Epoch 2/20 completed, Global Step: 160
nri_train_loss: 0.0242, enc_train_loss: 6.7490, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1307, dec_train_loss: 0.0234, train_edge_accuracy: 0.6317
nri_val_loss: 0.0241, enc_val_loss: 6.7007, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1348, dec_val_loss: 0.0232, val_edge_accuracy: 0.6453

---------------------------------------------------------------------------

Step 160, Epoch 3/20, Batch 0/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0242, enc_train_loss: 6.8089, enc_train_entropy: 0.1257, dec_train_loss: 0.0234, train_edge_accuracy: 0.6667, 

Step 165, Epoch 3/20, Batch 5/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0241, enc_train_loss: 6.7497, enc_train_entropy: 0.1307, dec_train_loss: 0.0232, train_edge_accuracy: 0.6333, 

Step 170, Epoch 3/20, Batch 10/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0240, enc_train_loss: 6.7601, enc_train_entropy: 0.1298, dec_train_loss: 0.0231, train_edge_accuracy: 0.6300, 

Step 175, Epoch 3/20, Batch 15/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0237, enc_train_loss: 6.6362, enc_train_entropy: 0.1401, dec_train_loss: 0.0227, train_edge_accuracy: 0.6150, 

Step 180, Epoch 3/20, Batch 20/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0235, enc_train_loss: 6.6999, enc_train_entropy: 0.1348, dec_train_loss: 0.0225, train_edge_accuracy: 0.6383, 

Step 185, Epoch 3/20, Batch 25/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0236, enc_train_loss: 6.6416, enc_train_entropy: 0.1397, dec_train_loss: 0.0227, train_edge_accuracy: 0.6317, 

Step 190, Epoch 3/20, Batch 30/80
temp: 0.9990, beta: 0.0001, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0239, enc_train_loss: 6.7365, enc_train_entropy: 0.1318, dec_train_loss: 0.0229, train_edge_accuracy: 0.6483, 

Step 195, Epoch 3/20, Batch 35/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0235, enc_train_loss: 6.5937, enc_train_entropy: 0.1437, dec_train_loss: 0.0225, train_edge_accuracy: 0.6367, 

Step 200, Epoch 3/20, Batch 40/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0232, enc_train_loss: 6.5566, enc_train_entropy: 0.1468, dec_train_loss: 0.0221, train_edge_accuracy: 0.6417, 

Step 205, Epoch 3/20, Batch 45/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0234, enc_train_loss: 6.4151, enc_train_entropy: 0.1586, dec_train_loss: 0.0223, train_edge_accuracy: 0.6450, 

Step 210, Epoch 3/20, Batch 50/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0233, enc_train_loss: 6.3061, enc_train_entropy: 0.1676, dec_train_loss: 0.0222, train_edge_accuracy: 0.6450, 

Step 215, Epoch 3/20, Batch 55/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0235, enc_train_loss: 6.5479, enc_train_entropy: 0.1475, dec_train_loss: 0.0224, train_edge_accuracy: 0.6550, 

Step 220, Epoch 3/20, Batch 60/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0235, enc_train_loss: 6.2047, enc_train_entropy: 0.1761, dec_train_loss: 0.0224, train_edge_accuracy: 0.6250, 

Step 225, Epoch 3/20, Batch 65/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0230, enc_train_loss: 6.2945, enc_train_entropy: 0.1686, dec_train_loss: 0.0219, train_edge_accuracy: 0.6367, 

Step 230, Epoch 3/20, Batch 70/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0231, enc_train_loss: 6.3128, enc_train_entropy: 0.1671, dec_train_loss: 0.0219, train_edge_accuracy: 0.6517, 

Step 235, Epoch 3/20, Batch 75/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0232, enc_train_loss: 6.1112, enc_train_entropy: 0.1839, dec_train_loss: 0.0221, train_edge_accuracy: 0.6483, 


Epoch 3/20 completed, Global Step: 240
nri_train_loss: 0.0232, enc_train_loss: 6.1112, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1839, dec_train_loss: 0.0221, train_edge_accuracy: 0.6483
nri_val_loss: 0.0229, enc_val_loss: 6.1099, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1840, dec_val_loss: 0.0218, val_edge_accuracy: 0.6438

---------------------------------------------------------------------------

Step 240, Epoch 4/20, Batch 0/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0229, enc_train_loss: 6.1115, enc_train_entropy: 0.1839, dec_train_loss: 0.0218, train_edge_accuracy: 0.6450, 

Step 245, Epoch 4/20, Batch 5/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0230, enc_train_loss: 6.0085, enc_train_entropy: 0.1924, dec_train_loss: 0.0218, train_edge_accuracy: 0.6283, 

Step 250, Epoch 4/20, Batch 10/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0227, enc_train_loss: 5.9888, enc_train_entropy: 0.1941, dec_train_loss: 0.0215, train_edge_accuracy: 0.6333, 

Step 255, Epoch 4/20, Batch 15/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0229, enc_train_loss: 6.0251, enc_train_entropy: 0.1911, dec_train_loss: 0.0217, train_edge_accuracy: 0.6333, 

Step 260, Epoch 4/20, Batch 20/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0227, enc_train_loss: 5.7358, enc_train_entropy: 0.2152, dec_train_loss: 0.0216, train_edge_accuracy: 0.6567, 

Step 265, Epoch 4/20, Batch 25/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0229, enc_train_loss: 5.7333, enc_train_entropy: 0.2154, dec_train_loss: 0.0217, train_edge_accuracy: 0.6450, 

Step 270, Epoch 4/20, Batch 30/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0231, enc_train_loss: 5.3225, enc_train_entropy: 0.2496, dec_train_loss: 0.0220, train_edge_accuracy: 0.6450, 

Step 275, Epoch 4/20, Batch 35/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0228, enc_train_loss: 5.1993, enc_train_entropy: 0.2599, dec_train_loss: 0.0216, train_edge_accuracy: 0.6633, 

Step 280, Epoch 4/20, Batch 40/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0225, enc_train_loss: 5.0064, enc_train_entropy: 0.2759, dec_train_loss: 0.0214, train_edge_accuracy: 0.6733, 

Step 285, Epoch 4/20, Batch 45/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0224, enc_train_loss: 4.6698, enc_train_entropy: 0.3040, dec_train_loss: 0.0213, train_edge_accuracy: 0.6517, 

Step 290, Epoch 4/20, Batch 50/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0223, enc_train_loss: 4.4387, enc_train_entropy: 0.3233, dec_train_loss: 0.0213, train_edge_accuracy: 0.6600, 

Step 295, Epoch 4/20, Batch 55/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0224, enc_train_loss: 4.5497, enc_train_entropy: 0.3140, dec_train_loss: 0.0213, train_edge_accuracy: 0.6217, 

Step 300, Epoch 4/20, Batch 60/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0226, enc_train_loss: 4.3696, enc_train_entropy: 0.3290, dec_train_loss: 0.0216, train_edge_accuracy: 0.6250, 

Step 305, Epoch 4/20, Batch 65/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0227, enc_train_loss: 4.1862, enc_train_entropy: 0.3443, dec_train_loss: 0.0217, train_edge_accuracy: 0.6417, 

Step 310, Epoch 4/20, Batch 70/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0224, enc_train_loss: 3.9026, enc_train_entropy: 0.3679, dec_train_loss: 0.0214, train_edge_accuracy: 0.6083, 

Step 315, Epoch 4/20, Batch 75/80
temp: 0.9990, beta: 0.0002, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0220, enc_train_loss: 3.5427, enc_train_entropy: 0.3979, dec_train_loss: 0.0211, train_edge_accuracy: 0.6250, 


Epoch 4/20 completed, Global Step: 320
nri_train_loss: 0.0220, enc_train_loss: 3.5427, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.3979, dec_train_loss: 0.0211, train_edge_accuracy: 0.6250
nri_val_loss: 0.0222, enc_val_loss: 3.4476, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.4058, dec_val_loss: 0.0213, val_edge_accuracy: 0.6002

---------------------------------------------------------------------------

Step 320, Epoch 5/20, Batch 0/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0222, enc_train_loss: 3.4564, enc_train_entropy: 0.4051, dec_train_loss: 0.0214, train_edge_accuracy: 0.5900, 

Step 325, Epoch 5/20, Batch 5/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0222, enc_train_loss: 3.2459, enc_train_entropy: 0.4227, dec_train_loss: 0.0214, train_edge_accuracy: 0.5600, 

Step 330, Epoch 5/20, Batch 10/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0222, enc_train_loss: 3.0117, enc_train_entropy: 0.4422, dec_train_loss: 0.0214, train_edge_accuracy: 0.5783, 

Step 335, Epoch 5/20, Batch 15/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0218, enc_train_loss: 3.0043, enc_train_entropy: 0.4428, dec_train_loss: 0.0210, train_edge_accuracy: 0.5300, 

Step 340, Epoch 5/20, Batch 20/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0217, enc_train_loss: 2.7863, enc_train_entropy: 0.4610, dec_train_loss: 0.0209, train_edge_accuracy: 0.5167, 

Step 345, Epoch 5/20, Batch 25/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0221, enc_train_loss: 2.3598, enc_train_entropy: 0.4965, dec_train_loss: 0.0214, train_edge_accuracy: 0.4883, 

Step 350, Epoch 5/20, Batch 30/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0215, enc_train_loss: 2.6559, enc_train_entropy: 0.4718, dec_train_loss: 0.0208, train_edge_accuracy: 0.4717, 

Step 355, Epoch 5/20, Batch 35/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0217, enc_train_loss: 2.4884, enc_train_entropy: 0.4858, dec_train_loss: 0.0210, train_edge_accuracy: 0.5017, 

Step 360, Epoch 5/20, Batch 40/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0219, enc_train_loss: 2.3729, enc_train_entropy: 0.4954, dec_train_loss: 0.0212, train_edge_accuracy: 0.4950, 

Step 365, Epoch 5/20, Batch 45/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0218, enc_train_loss: 1.9212, enc_train_entropy: 0.5330, dec_train_loss: 0.0212, train_edge_accuracy: 0.4583, 

Step 370, Epoch 5/20, Batch 50/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0218, enc_train_loss: 2.4153, enc_train_entropy: 0.4919, dec_train_loss: 0.0211, train_edge_accuracy: 0.4483, 

Step 375, Epoch 5/20, Batch 55/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0217, enc_train_loss: 2.1343, enc_train_entropy: 0.5153, dec_train_loss: 0.0210, train_edge_accuracy: 0.4567, 

Step 380, Epoch 5/20, Batch 60/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0216, enc_train_loss: 2.0405, enc_train_entropy: 0.5231, dec_train_loss: 0.0210, train_edge_accuracy: 0.4450, 

Step 385, Epoch 5/20, Batch 65/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0217, enc_train_loss: 2.0770, enc_train_entropy: 0.5201, dec_train_loss: 0.0211, train_edge_accuracy: 0.4617, 

Step 390, Epoch 5/20, Batch 70/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0216, enc_train_loss: 1.7628, enc_train_entropy: 0.5462, dec_train_loss: 0.0210, train_edge_accuracy: 0.4517, 

Step 395, Epoch 5/20, Batch 75/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0214, enc_train_loss: 2.0018, enc_train_entropy: 0.5263, dec_train_loss: 0.0208, train_edge_accuracy: 0.4867, 


Epoch 5/20 completed, Global Step: 400
nri_train_loss: 0.0214, enc_train_loss: 2.0018, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.5263, dec_train_loss: 0.0208, train_edge_accuracy: 0.4867
nri_val_loss: 0.0214, enc_val_loss: 1.7818, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.5447, dec_val_loss: 0.0208, val_edge_accuracy: 0.4632

---------------------------------------------------------------------------

Step 400, Epoch 6/20, Batch 0/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0213, enc_train_loss: 1.7746, enc_train_entropy: 0.5453, dec_train_loss: 0.0208, train_edge_accuracy: 0.4633, 

Step 405, Epoch 6/20, Batch 5/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0213, enc_train_loss: 1.8355, enc_train_entropy: 0.5402, dec_train_loss: 0.0208, train_edge_accuracy: 0.4533, 

Step 410, Epoch 6/20, Batch 10/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0212, enc_train_loss: 1.6373, enc_train_entropy: 0.5567, dec_train_loss: 0.0207, train_edge_accuracy: 0.4667, 

Step 415, Epoch 6/20, Batch 15/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0213, enc_train_loss: 1.7849, enc_train_entropy: 0.5444, dec_train_loss: 0.0207, train_edge_accuracy: 0.4433, 

Step 420, Epoch 6/20, Batch 20/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0211, enc_train_loss: 1.3931, enc_train_entropy: 0.5771, dec_train_loss: 0.0207, train_edge_accuracy: 0.4467, 

Step 425, Epoch 6/20, Batch 25/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0210, enc_train_loss: 1.9481, enc_train_entropy: 0.5308, dec_train_loss: 0.0203, train_edge_accuracy: 0.4667, 

Step 430, Epoch 6/20, Batch 30/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0214, enc_train_loss: 1.1915, enc_train_entropy: 0.5939, dec_train_loss: 0.0210, train_edge_accuracy: 0.4500, 

Step 435, Epoch 6/20, Batch 35/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 1.5977, enc_train_entropy: 0.5600, dec_train_loss: 0.0203, train_edge_accuracy: 0.4817, 

Step 440, Epoch 6/20, Batch 40/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0212, enc_train_loss: 1.3476, enc_train_entropy: 0.5808, dec_train_loss: 0.0207, train_edge_accuracy: 0.4567, 

Step 445, Epoch 6/20, Batch 45/80
temp: 0.9990, beta: 0.0003, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0210, enc_train_loss: 1.2256, enc_train_entropy: 0.5910, dec_train_loss: 0.0206, train_edge_accuracy: 0.4600, 

Step 450, Epoch 6/20, Batch 50/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0209, enc_train_loss: 1.1916, enc_train_entropy: 0.5938, dec_train_loss: 0.0205, train_edge_accuracy: 0.4733, 

Step 455, Epoch 6/20, Batch 55/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 1.2627, enc_train_entropy: 0.5879, dec_train_loss: 0.0204, train_edge_accuracy: 0.4533, 

Step 460, Epoch 6/20, Batch 60/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0209, enc_train_loss: 1.3062, enc_train_entropy: 0.5843, dec_train_loss: 0.0205, train_edge_accuracy: 0.4683, 

Step 465, Epoch 6/20, Batch 65/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0210, enc_train_loss: 1.0264, enc_train_entropy: 0.6076, dec_train_loss: 0.0206, train_edge_accuracy: 0.4633, 

Step 470, Epoch 6/20, Batch 70/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0209, enc_train_loss: 1.0548, enc_train_entropy: 0.6052, dec_train_loss: 0.0205, train_edge_accuracy: 0.4700, 

Step 475, Epoch 6/20, Batch 75/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 0.9461, enc_train_entropy: 0.6143, dec_train_loss: 0.0205, train_edge_accuracy: 0.4617, 


Epoch 6/20 completed, Global Step: 480
nri_train_loss: 0.0208, enc_train_loss: 0.9461, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6143, dec_train_loss: 0.0205, train_edge_accuracy: 0.4617
nri_val_loss: 0.0207, enc_val_loss: 1.1625, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.5963, dec_val_loss: 0.0202, val_edge_accuracy: 0.4645

---------------------------------------------------------------------------

Step 480, Epoch 7/20, Batch 0/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0207, enc_train_loss: 1.2496, enc_train_entropy: 0.5890, dec_train_loss: 0.0202, train_edge_accuracy: 0.4633, 

Step 485, Epoch 7/20, Batch 5/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 0.9049, enc_train_entropy: 0.6177, dec_train_loss: 0.0204, train_edge_accuracy: 0.4517, 

Step 490, Epoch 7/20, Batch 10/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0206, enc_train_loss: 1.0111, enc_train_entropy: 0.6089, dec_train_loss: 0.0202, train_edge_accuracy: 0.4683, 

Step 495, Epoch 7/20, Batch 15/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0206, enc_train_loss: 0.7882, enc_train_entropy: 0.6275, dec_train_loss: 0.0203, train_edge_accuracy: 0.4533, 

Step 500, Epoch 7/20, Batch 20/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 0.8689, enc_train_entropy: 0.6207, dec_train_loss: 0.0204, train_edge_accuracy: 0.4833, 

Step 505, Epoch 7/20, Batch 25/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0204, enc_train_loss: 0.9435, enc_train_entropy: 0.6145, dec_train_loss: 0.0201, train_edge_accuracy: 0.4433, 

Step 510, Epoch 7/20, Batch 30/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0205, enc_train_loss: 0.7946, enc_train_entropy: 0.6269, dec_train_loss: 0.0202, train_edge_accuracy: 0.4550, 

Step 515, Epoch 7/20, Batch 35/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0205, enc_train_loss: 0.6704, enc_train_entropy: 0.6373, dec_train_loss: 0.0202, train_edge_accuracy: 0.4683, 

Step 520, Epoch 7/20, Batch 40/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0206, enc_train_loss: 0.8468, enc_train_entropy: 0.6226, dec_train_loss: 0.0202, train_edge_accuracy: 0.4417, 

Step 525, Epoch 7/20, Batch 45/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0204, enc_train_loss: 0.7872, enc_train_entropy: 0.6275, dec_train_loss: 0.0201, train_edge_accuracy: 0.4550, 

Step 530, Epoch 7/20, Batch 50/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0205, enc_train_loss: 0.6696, enc_train_entropy: 0.6373, dec_train_loss: 0.0203, train_edge_accuracy: 0.4800, 

Step 535, Epoch 7/20, Batch 55/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0205, enc_train_loss: 0.6822, enc_train_entropy: 0.6363, dec_train_loss: 0.0202, train_edge_accuracy: 0.4500, 

Step 540, Epoch 7/20, Batch 60/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0199, enc_train_loss: 0.8434, enc_train_entropy: 0.6229, dec_train_loss: 0.0195, train_edge_accuracy: 0.4683, 

Step 545, Epoch 7/20, Batch 65/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0202, enc_train_loss: 0.5878, enc_train_entropy: 0.6442, dec_train_loss: 0.0200, train_edge_accuracy: 0.4517, 

Step 550, Epoch 7/20, Batch 70/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0200, enc_train_loss: 0.6340, enc_train_entropy: 0.6403, dec_train_loss: 0.0197, train_edge_accuracy: 0.4767, 

Step 555, Epoch 7/20, Batch 75/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0201, enc_train_loss: 0.4959, enc_train_entropy: 0.6518, dec_train_loss: 0.0199, train_edge_accuracy: 0.4600, 


Epoch 7/20 completed, Global Step: 560
nri_train_loss: 0.0201, enc_train_loss: 0.4959, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6518, dec_train_loss: 0.0199, train_edge_accuracy: 0.4600
nri_val_loss: 0.0200, enc_val_loss: 0.6933, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6354, dec_val_loss: 0.0197, val_edge_accuracy: 0.4453

---------------------------------------------------------------------------

Step 560, Epoch 8/20, Batch 0/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0201, enc_train_loss: 0.6995, enc_train_entropy: 0.6349, dec_train_loss: 0.0198, train_edge_accuracy: 0.4400, 

Step 565, Epoch 8/20, Batch 5/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0201, enc_train_loss: 0.4610, enc_train_entropy: 0.6547, dec_train_loss: 0.0199, train_edge_accuracy: 0.4450, 

Step 570, Epoch 8/20, Batch 10/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0198, enc_train_loss: 0.6811, enc_train_entropy: 0.6364, dec_train_loss: 0.0195, train_edge_accuracy: 0.4600, 

Step 575, Epoch 8/20, Batch 15/80
temp: 0.9990, beta: 0.0004, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0202, enc_train_loss: 0.5145, enc_train_entropy: 0.6503, dec_train_loss: 0.0200, train_edge_accuracy: 0.4667, 

Step 580, Epoch 8/20, Batch 20/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0197, enc_train_loss: 0.5841, enc_train_entropy: 0.6445, dec_train_loss: 0.0194, train_edge_accuracy: 0.4683, 

Step 585, Epoch 8/20, Batch 25/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0199, enc_train_loss: 0.5413, enc_train_entropy: 0.6480, dec_train_loss: 0.0197, train_edge_accuracy: 0.4517, 

Step 590, Epoch 8/20, Batch 30/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.5461, enc_train_entropy: 0.6476, dec_train_loss: 0.0194, train_edge_accuracy: 0.4767, 

Step 595, Epoch 8/20, Batch 35/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0198, enc_train_loss: 0.5359, enc_train_entropy: 0.6485, dec_train_loss: 0.0195, train_edge_accuracy: 0.4733, 

Step 600, Epoch 8/20, Batch 40/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0200, enc_train_loss: 0.5666, enc_train_entropy: 0.6459, dec_train_loss: 0.0197, train_edge_accuracy: 0.4467, 

Step 605, Epoch 8/20, Batch 45/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0200, enc_train_loss: 0.5541, enc_train_entropy: 0.6470, dec_train_loss: 0.0197, train_edge_accuracy: 0.4783, 

Step 610, Epoch 8/20, Batch 50/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0195, enc_train_loss: 0.4958, enc_train_entropy: 0.6518, dec_train_loss: 0.0193, train_edge_accuracy: 0.4517, 

Step 615, Epoch 8/20, Batch 55/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0199, enc_train_loss: 0.4793, enc_train_entropy: 0.6532, dec_train_loss: 0.0196, train_edge_accuracy: 0.4750, 

Step 620, Epoch 8/20, Batch 60/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.4530, enc_train_entropy: 0.6554, dec_train_loss: 0.0194, train_edge_accuracy: 0.4650, 

Step 625, Epoch 8/20, Batch 65/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0198, enc_train_loss: 0.6728, enc_train_entropy: 0.6371, dec_train_loss: 0.0195, train_edge_accuracy: 0.4500, 

Step 630, Epoch 8/20, Batch 70/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0194, enc_train_loss: 0.4555, enc_train_entropy: 0.6552, dec_train_loss: 0.0192, train_edge_accuracy: 0.4567, 

Step 635, Epoch 8/20, Batch 75/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.3823, enc_train_entropy: 0.6613, dec_train_loss: 0.0194, train_edge_accuracy: 0.4583, 


Epoch 8/20 completed, Global Step: 640
nri_train_loss: 0.0196, enc_train_loss: 0.3823, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6613, dec_train_loss: 0.0194, train_edge_accuracy: 0.4583
nri_val_loss: 0.0195, enc_val_loss: 0.5399, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6482, dec_val_loss: 0.0192, val_edge_accuracy: 0.4740

---------------------------------------------------------------------------

Step 640, Epoch 9/20, Batch 0/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.5702, enc_train_entropy: 0.6456, dec_train_loss: 0.0193, train_edge_accuracy: 0.4683, 

Step 645, Epoch 9/20, Batch 5/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.4714, enc_train_entropy: 0.6539, dec_train_loss: 0.0193, train_edge_accuracy: 0.4750, 

Step 650, Epoch 9/20, Batch 10/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0194, enc_train_loss: 0.4450, enc_train_entropy: 0.6561, dec_train_loss: 0.0192, train_edge_accuracy: 0.4567, 

Step 655, Epoch 9/20, Batch 15/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.5845, enc_train_entropy: 0.6444, dec_train_loss: 0.0193, train_edge_accuracy: 0.4817, 

Step 660, Epoch 9/20, Batch 20/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0195, enc_train_loss: 0.4133, enc_train_entropy: 0.6587, dec_train_loss: 0.0193, train_edge_accuracy: 0.4650, 

Step 665, Epoch 9/20, Batch 25/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0193, enc_train_loss: 0.5454, enc_train_entropy: 0.6477, dec_train_loss: 0.0191, train_edge_accuracy: 0.4700, 

Step 670, Epoch 9/20, Batch 30/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0193, enc_train_loss: 0.3864, enc_train_entropy: 0.6609, dec_train_loss: 0.0191, train_edge_accuracy: 0.4900, 

Step 675, Epoch 9/20, Batch 35/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0194, enc_train_loss: 0.4443, enc_train_entropy: 0.6561, dec_train_loss: 0.0192, train_edge_accuracy: 0.4633, 

Step 680, Epoch 9/20, Batch 40/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0191, enc_train_loss: 0.5061, enc_train_entropy: 0.6510, dec_train_loss: 0.0189, train_edge_accuracy: 0.4667, 

Step 685, Epoch 9/20, Batch 45/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0193, enc_train_loss: 0.4195, enc_train_entropy: 0.6582, dec_train_loss: 0.0191, train_edge_accuracy: 0.4967, 

Step 690, Epoch 9/20, Batch 50/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0191, enc_train_loss: 0.4482, enc_train_entropy: 0.6558, dec_train_loss: 0.0188, train_edge_accuracy: 0.4667, 

Step 695, Epoch 9/20, Batch 55/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0196, enc_train_loss: 0.4928, enc_train_entropy: 0.6521, dec_train_loss: 0.0193, train_edge_accuracy: 0.4717, 

Step 700, Epoch 9/20, Batch 60/80
temp: 0.9990, beta: 0.0005, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0192, enc_train_loss: 0.4214, enc_train_entropy: 0.6580, dec_train_loss: 0.0189, train_edge_accuracy: 0.4683, 

Step 705, Epoch 9/20, Batch 65/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0193, enc_train_loss: 0.4513, enc_train_entropy: 0.6555, dec_train_loss: 0.0190, train_edge_accuracy: 0.4783, 

Step 710, Epoch 9/20, Batch 70/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0192, enc_train_loss: 0.4709, enc_train_entropy: 0.6539, dec_train_loss: 0.0189, train_edge_accuracy: 0.4700, 

Step 715, Epoch 9/20, Batch 75/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0193, enc_train_loss: 0.4292, enc_train_entropy: 0.6574, dec_train_loss: 0.0191, train_edge_accuracy: 0.4500, 


Epoch 9/20 completed, Global Step: 720
nri_train_loss: 0.0193, enc_train_loss: 0.4292, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6574, dec_train_loss: 0.0191, train_edge_accuracy: 0.4500
nri_val_loss: 0.0191, enc_val_loss: 0.4137, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6587, dec_val_loss: 0.0189, val_edge_accuracy: 0.4760

---------------------------------------------------------------------------

Step 720, Epoch 10/20, Batch 0/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0193, enc_train_loss: 0.4354, enc_train_entropy: 0.6569, dec_train_loss: 0.0190, train_edge_accuracy: 0.5033, 

Step 725, Epoch 10/20, Batch 5/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0192, enc_train_loss: 0.5012, enc_train_entropy: 0.6514, dec_train_loss: 0.0189, train_edge_accuracy: 0.4500, 

Step 730, Epoch 10/20, Batch 10/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0191, enc_train_loss: 0.3867, enc_train_entropy: 0.6609, dec_train_loss: 0.0188, train_edge_accuracy: 0.4633, 

Step 735, Epoch 10/20, Batch 15/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0192, enc_train_loss: 0.4080, enc_train_entropy: 0.6591, dec_train_loss: 0.0189, train_edge_accuracy: 0.4800, 

Step 740, Epoch 10/20, Batch 20/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0192, enc_train_loss: 0.5198, enc_train_entropy: 0.6498, dec_train_loss: 0.0189, train_edge_accuracy: 0.4617, 

Step 745, Epoch 10/20, Batch 25/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.4323, enc_train_entropy: 0.6571, dec_train_loss: 0.0186, train_edge_accuracy: 0.4667, 

Step 750, Epoch 10/20, Batch 30/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.4167, enc_train_entropy: 0.6584, dec_train_loss: 0.0188, train_edge_accuracy: 0.4900, 

Step 755, Epoch 10/20, Batch 35/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.3365, enc_train_entropy: 0.6651, dec_train_loss: 0.0188, train_edge_accuracy: 0.4633, 

Step 760, Epoch 10/20, Batch 40/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 0.3929, enc_train_entropy: 0.6604, dec_train_loss: 0.0184, train_edge_accuracy: 0.4667, 

Step 765, Epoch 10/20, Batch 45/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0189, enc_train_loss: 0.3091, enc_train_entropy: 0.6674, dec_train_loss: 0.0187, train_edge_accuracy: 0.4683, 

Step 770, Epoch 10/20, Batch 50/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0191, enc_train_loss: 0.4378, enc_train_entropy: 0.6567, dec_train_loss: 0.0189, train_edge_accuracy: 0.4767, 

Step 775, Epoch 10/20, Batch 55/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.3771, enc_train_entropy: 0.6617, dec_train_loss: 0.0188, train_edge_accuracy: 0.4800, 

Step 780, Epoch 10/20, Batch 60/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0191, enc_train_loss: 0.3258, enc_train_entropy: 0.6660, dec_train_loss: 0.0189, train_edge_accuracy: 0.4567, 

Step 785, Epoch 10/20, Batch 65/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.3723, enc_train_entropy: 0.6621, dec_train_loss: 0.0188, train_edge_accuracy: 0.4667, 

Step 790, Epoch 10/20, Batch 70/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 0.3247, enc_train_entropy: 0.6661, dec_train_loss: 0.0185, train_edge_accuracy: 0.4717, 

Step 795, Epoch 10/20, Batch 75/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.4113, enc_train_entropy: 0.6589, dec_train_loss: 0.0187, train_edge_accuracy: 0.4617, 


Epoch 10/20 completed, Global Step: 800
nri_train_loss: 0.0190, enc_train_loss: 0.4113, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6589, dec_train_loss: 0.0187, train_edge_accuracy: 0.4617
nri_val_loss: 0.0188, enc_val_loss: 0.3873, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6609, dec_val_loss: 0.0186, val_edge_accuracy: 0.4758

---------------------------------------------------------------------------

Step 800, Epoch 11/20, Batch 0/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.3749, enc_train_entropy: 0.6619, dec_train_loss: 0.0185, train_edge_accuracy: 0.4833, 

Step 805, Epoch 11/20, Batch 5/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.2712, enc_train_entropy: 0.6705, dec_train_loss: 0.0188, train_edge_accuracy: 0.4500, 

Step 810, Epoch 11/20, Batch 10/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 0.3761, enc_train_entropy: 0.6618, dec_train_loss: 0.0185, train_edge_accuracy: 0.4750, 

Step 815, Epoch 11/20, Batch 15/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.3472, enc_train_entropy: 0.6642, dec_train_loss: 0.0186, train_edge_accuracy: 0.4700, 

Step 820, Epoch 11/20, Batch 20/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0190, enc_train_loss: 0.3629, enc_train_entropy: 0.6629, dec_train_loss: 0.0187, train_edge_accuracy: 0.4783, 

Step 825, Epoch 11/20, Batch 25/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.4389, enc_train_entropy: 0.6566, dec_train_loss: 0.0186, train_edge_accuracy: 0.4933, 

Step 830, Epoch 11/20, Batch 30/80
temp: 0.9990, beta: 0.0006, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2866, enc_train_entropy: 0.6693, dec_train_loss: 0.0183, train_edge_accuracy: 0.4650, 

Step 835, Epoch 11/20, Batch 35/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.3863, enc_train_entropy: 0.6610, dec_train_loss: 0.0185, train_edge_accuracy: 0.4750, 

Step 840, Epoch 11/20, Batch 40/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.3406, enc_train_entropy: 0.6648, dec_train_loss: 0.0186, train_edge_accuracy: 0.4533, 

Step 845, Epoch 11/20, Batch 45/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.4076, enc_train_entropy: 0.6592, dec_train_loss: 0.0185, train_edge_accuracy: 0.4717, 

Step 850, Epoch 11/20, Batch 50/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0185, enc_train_loss: 0.3218, enc_train_entropy: 0.6663, dec_train_loss: 0.0183, train_edge_accuracy: 0.4750, 

Step 855, Epoch 11/20, Batch 55/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.3638, enc_train_entropy: 0.6628, dec_train_loss: 0.0185, train_edge_accuracy: 0.4733, 

Step 860, Epoch 11/20, Batch 60/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.3300, enc_train_entropy: 0.6657, dec_train_loss: 0.0186, train_edge_accuracy: 0.4717, 

Step 865, Epoch 11/20, Batch 65/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0186, enc_train_loss: 0.3566, enc_train_entropy: 0.6634, dec_train_loss: 0.0184, train_edge_accuracy: 0.4833, 

Step 870, Epoch 11/20, Batch 70/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0188, enc_train_loss: 0.2214, enc_train_entropy: 0.6747, dec_train_loss: 0.0186, train_edge_accuracy: 0.4817, 

Step 875, Epoch 11/20, Batch 75/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 0.3951, enc_train_entropy: 0.6602, dec_train_loss: 0.0185, train_edge_accuracy: 0.4933, 


Epoch 11/20 completed, Global Step: 880
nri_train_loss: 0.0187, enc_train_loss: 0.3951, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6602, dec_train_loss: 0.0185, train_edge_accuracy: 0.4933
nri_val_loss: 0.0186, enc_val_loss: 0.2972, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6684, dec_val_loss: 0.0184, val_edge_accuracy: 0.4823

---------------------------------------------------------------------------

Step 880, Epoch 12/20, Batch 0/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0186, enc_train_loss: 0.2904, enc_train_entropy: 0.6689, dec_train_loss: 0.0184, train_edge_accuracy: 0.4883, 

Step 885, Epoch 12/20, Batch 5/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0185, enc_train_loss: 0.3541, enc_train_entropy: 0.6636, dec_train_loss: 0.0182, train_edge_accuracy: 0.4833, 

Step 890, Epoch 12/20, Batch 10/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0189, enc_train_loss: 0.3305, enc_train_entropy: 0.6656, dec_train_loss: 0.0187, train_edge_accuracy: 0.4500, 

Step 895, Epoch 12/20, Batch 15/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 0.3373, enc_train_entropy: 0.6650, dec_train_loss: 0.0184, train_edge_accuracy: 0.4667, 

Step 900, Epoch 12/20, Batch 20/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2798, enc_train_entropy: 0.6698, dec_train_loss: 0.0182, train_edge_accuracy: 0.4800, 

Step 905, Epoch 12/20, Batch 25/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2725, enc_train_entropy: 0.6704, dec_train_loss: 0.0182, train_edge_accuracy: 0.4667, 

Step 910, Epoch 12/20, Batch 30/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0186, enc_train_loss: 0.3211, enc_train_entropy: 0.6664, dec_train_loss: 0.0184, train_edge_accuracy: 0.4683, 

Step 915, Epoch 12/20, Batch 35/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2744, enc_train_entropy: 0.6703, dec_train_loss: 0.0182, train_edge_accuracy: 0.4583, 

Step 920, Epoch 12/20, Batch 40/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2725, enc_train_entropy: 0.6704, dec_train_loss: 0.0183, train_edge_accuracy: 0.4700, 

Step 925, Epoch 12/20, Batch 45/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2654, enc_train_entropy: 0.6710, dec_train_loss: 0.0181, train_edge_accuracy: 0.4550, 

Step 930, Epoch 12/20, Batch 50/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2194, enc_train_entropy: 0.6749, dec_train_loss: 0.0181, train_edge_accuracy: 0.4767, 

Step 935, Epoch 12/20, Batch 55/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2672, enc_train_entropy: 0.6709, dec_train_loss: 0.0182, train_edge_accuracy: 0.4733, 

Step 940, Epoch 12/20, Batch 60/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2533, enc_train_entropy: 0.6720, dec_train_loss: 0.0181, train_edge_accuracy: 0.4517, 

Step 945, Epoch 12/20, Batch 65/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2316, enc_train_entropy: 0.6738, dec_train_loss: 0.0182, train_edge_accuracy: 0.4767, 

Step 950, Epoch 12/20, Batch 70/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2710, enc_train_entropy: 0.6706, dec_train_loss: 0.0181, train_edge_accuracy: 0.4750, 

Step 955, Epoch 12/20, Batch 75/80
temp: 0.9990, beta: 0.0007, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2499, enc_train_entropy: 0.6723, dec_train_loss: 0.0181, train_edge_accuracy: 0.4750, 


Epoch 12/20 completed, Global Step: 960
nri_train_loss: 0.0183, enc_train_loss: 0.2499, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6723, dec_train_loss: 0.0181, train_edge_accuracy: 0.4750
nri_val_loss: 0.0183, enc_val_loss: 0.3120, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6671, dec_val_loss: 0.0181, val_edge_accuracy: 0.4852

---------------------------------------------------------------------------

Step 960, Epoch 13/20, Batch 0/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.3193, enc_train_entropy: 0.6665, dec_train_loss: 0.0179, train_edge_accuracy: 0.4883, 

Step 965, Epoch 13/20, Batch 5/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 0.2635, enc_train_entropy: 0.6712, dec_train_loss: 0.0185, train_edge_accuracy: 0.4917, 

Step 970, Epoch 13/20, Batch 10/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2486, enc_train_entropy: 0.6724, dec_train_loss: 0.0181, train_edge_accuracy: 0.4700, 

Step 975, Epoch 13/20, Batch 15/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2477, enc_train_entropy: 0.6725, dec_train_loss: 0.0182, train_edge_accuracy: 0.4833, 

Step 980, Epoch 13/20, Batch 20/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0186, enc_train_loss: 0.2841, enc_train_entropy: 0.6695, dec_train_loss: 0.0184, train_edge_accuracy: 0.4883, 

Step 985, Epoch 13/20, Batch 25/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0186, enc_train_loss: 0.2846, enc_train_entropy: 0.6694, dec_train_loss: 0.0183, train_edge_accuracy: 0.4600, 

Step 990, Epoch 13/20, Batch 30/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2171, enc_train_entropy: 0.6751, dec_train_loss: 0.0182, train_edge_accuracy: 0.4667, 

Step 995, Epoch 13/20, Batch 35/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.2285, enc_train_entropy: 0.6741, dec_train_loss: 0.0181, train_edge_accuracy: 0.4800, 

Step 1000, Epoch 13/20, Batch 40/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0185, enc_train_loss: 0.2731, enc_train_entropy: 0.6704, dec_train_loss: 0.0183, train_edge_accuracy: 0.4750, 

Step 1005, Epoch 13/20, Batch 45/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0185, enc_train_loss: 0.2851, enc_train_entropy: 0.6694, dec_train_loss: 0.0183, train_edge_accuracy: 0.4550, 

Step 1010, Epoch 13/20, Batch 50/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.2358, enc_train_entropy: 0.6735, dec_train_loss: 0.0182, train_edge_accuracy: 0.4783, 

Step 1015, Epoch 13/20, Batch 55/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.2141, enc_train_entropy: 0.6753, dec_train_loss: 0.0180, train_edge_accuracy: 0.4617, 

Step 1020, Epoch 13/20, Batch 60/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.2689, enc_train_entropy: 0.6707, dec_train_loss: 0.0180, train_edge_accuracy: 0.4667, 

Step 1025, Epoch 13/20, Batch 65/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 0.2131, enc_train_entropy: 0.6754, dec_train_loss: 0.0182, train_edge_accuracy: 0.4467, 

Step 1030, Epoch 13/20, Batch 70/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.2333, enc_train_entropy: 0.6737, dec_train_loss: 0.0180, train_edge_accuracy: 0.4550, 

Step 1035, Epoch 13/20, Batch 75/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.2239, enc_train_entropy: 0.6745, dec_train_loss: 0.0180, train_edge_accuracy: 0.4717, 


Epoch 13/20 completed, Global Step: 1040
nri_train_loss: 0.0181, enc_train_loss: 0.2239, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6745, dec_train_loss: 0.0180, train_edge_accuracy: 0.4717
nri_val_loss: 0.0182, enc_val_loss: 0.2210, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6747, dec_val_loss: 0.0180, val_edge_accuracy: 0.4623

---------------------------------------------------------------------------

Step 1040, Epoch 14/20, Batch 0/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.2089, enc_train_entropy: 0.6757, dec_train_loss: 0.0179, train_edge_accuracy: 0.4367, 

Step 1045, Epoch 14/20, Batch 5/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.2161, enc_train_entropy: 0.6751, dec_train_loss: 0.0179, train_edge_accuracy: 0.4850, 

Step 1050, Epoch 14/20, Batch 10/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.1953, enc_train_entropy: 0.6769, dec_train_loss: 0.0181, train_edge_accuracy: 0.4767, 

Step 1055, Epoch 14/20, Batch 15/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1815, enc_train_entropy: 0.6780, dec_train_loss: 0.0179, train_edge_accuracy: 0.4900, 

Step 1060, Epoch 14/20, Batch 20/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.2280, enc_train_entropy: 0.6741, dec_train_loss: 0.0178, train_edge_accuracy: 0.4700, 

Step 1065, Epoch 14/20, Batch 25/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1915, enc_train_entropy: 0.6772, dec_train_loss: 0.0179, train_edge_accuracy: 0.4733, 

Step 1070, Epoch 14/20, Batch 30/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1753, enc_train_entropy: 0.6785, dec_train_loss: 0.0179, train_edge_accuracy: 0.4867, 

Step 1075, Epoch 14/20, Batch 35/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.2397, enc_train_entropy: 0.6732, dec_train_loss: 0.0179, train_edge_accuracy: 0.4617, 

Step 1080, Epoch 14/20, Batch 40/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.2029, enc_train_entropy: 0.6762, dec_train_loss: 0.0177, train_edge_accuracy: 0.4767, 

Step 1085, Epoch 14/20, Batch 45/80
temp: 0.9990, beta: 0.0008, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.2116, enc_train_entropy: 0.6755, dec_train_loss: 0.0179, train_edge_accuracy: 0.4867, 

Step 1090, Epoch 14/20, Batch 50/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.1834, enc_train_entropy: 0.6779, dec_train_loss: 0.0181, train_edge_accuracy: 0.4867, 

Step 1095, Epoch 14/20, Batch 55/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.2094, enc_train_entropy: 0.6757, dec_train_loss: 0.0179, train_edge_accuracy: 0.4917, 

Step 1100, Epoch 14/20, Batch 60/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.1637, enc_train_entropy: 0.6795, dec_train_loss: 0.0180, train_edge_accuracy: 0.4567, 

Step 1105, Epoch 14/20, Batch 65/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1973, enc_train_entropy: 0.6767, dec_train_loss: 0.0179, train_edge_accuracy: 0.4683, 

Step 1110, Epoch 14/20, Batch 70/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0183, enc_train_loss: 0.1652, enc_train_entropy: 0.6794, dec_train_loss: 0.0181, train_edge_accuracy: 0.4883, 

Step 1115, Epoch 14/20, Batch 75/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0179, enc_train_loss: 0.2159, enc_train_entropy: 0.6752, dec_train_loss: 0.0177, train_edge_accuracy: 0.4917, 


Epoch 14/20 completed, Global Step: 1120
nri_train_loss: 0.0179, enc_train_loss: 0.2159, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6752, dec_train_loss: 0.0177, train_edge_accuracy: 0.4917
nri_val_loss: 0.0180, enc_val_loss: 0.1645, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6794, dec_val_loss: 0.0179, val_edge_accuracy: 0.4728

---------------------------------------------------------------------------

Step 1120, Epoch 15/20, Batch 0/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1605, enc_train_entropy: 0.6798, dec_train_loss: 0.0180, train_edge_accuracy: 0.4767, 

Step 1125, Epoch 15/20, Batch 5/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1598, enc_train_entropy: 0.6798, dec_train_loss: 0.0176, train_edge_accuracy: 0.4700, 

Step 1130, Epoch 15/20, Batch 10/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1621, enc_train_entropy: 0.6796, dec_train_loss: 0.0179, train_edge_accuracy: 0.4917, 

Step 1135, Epoch 15/20, Batch 15/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1519, enc_train_entropy: 0.6805, dec_train_loss: 0.0179, train_edge_accuracy: 0.4500, 

Step 1140, Epoch 15/20, Batch 20/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1768, enc_train_entropy: 0.6784, dec_train_loss: 0.0177, train_edge_accuracy: 0.4583, 

Step 1145, Epoch 15/20, Batch 25/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1751, enc_train_entropy: 0.6786, dec_train_loss: 0.0179, train_edge_accuracy: 0.4600, 

Step 1150, Epoch 15/20, Batch 30/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1272, enc_train_entropy: 0.6825, dec_train_loss: 0.0177, train_edge_accuracy: 0.4733, 

Step 1155, Epoch 15/20, Batch 35/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1982, enc_train_entropy: 0.6766, dec_train_loss: 0.0178, train_edge_accuracy: 0.4850, 

Step 1160, Epoch 15/20, Batch 40/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.1610, enc_train_entropy: 0.6797, dec_train_loss: 0.0180, train_edge_accuracy: 0.4900, 

Step 1165, Epoch 15/20, Batch 45/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1790, enc_train_entropy: 0.6782, dec_train_loss: 0.0179, train_edge_accuracy: 0.4717, 

Step 1170, Epoch 15/20, Batch 50/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1507, enc_train_entropy: 0.6806, dec_train_loss: 0.0175, train_edge_accuracy: 0.4583, 

Step 1175, Epoch 15/20, Batch 55/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1998, enc_train_entropy: 0.6765, dec_train_loss: 0.0175, train_edge_accuracy: 0.4867, 

Step 1180, Epoch 15/20, Batch 60/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1437, enc_train_entropy: 0.6812, dec_train_loss: 0.0178, train_edge_accuracy: 0.4983, 

Step 1185, Epoch 15/20, Batch 65/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1803, enc_train_entropy: 0.6781, dec_train_loss: 0.0177, train_edge_accuracy: 0.4650, 

Step 1190, Epoch 15/20, Batch 70/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1526, enc_train_entropy: 0.6804, dec_train_loss: 0.0177, train_edge_accuracy: 0.4583, 

Step 1195, Epoch 15/20, Batch 75/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1922, enc_train_entropy: 0.6771, dec_train_loss: 0.0179, train_edge_accuracy: 0.4667, 


Epoch 15/20 completed, Global Step: 1200
nri_train_loss: 0.0181, enc_train_loss: 0.1922, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6771, dec_train_loss: 0.0179, train_edge_accuracy: 0.4667
nri_val_loss: 0.0179, enc_val_loss: 0.1382, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6816, dec_val_loss: 0.0177, val_edge_accuracy: 0.4753

---------------------------------------------------------------------------

Step 1200, Epoch 16/20, Batch 0/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1452, enc_train_entropy: 0.6810, dec_train_loss: 0.0176, train_edge_accuracy: 0.4817, 

Step 1205, Epoch 16/20, Batch 5/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 0.1752, enc_train_entropy: 0.6785, dec_train_loss: 0.0180, train_edge_accuracy: 0.4917, 

Step 1210, Epoch 16/20, Batch 10/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1120, enc_train_entropy: 0.6838, dec_train_loss: 0.0180, train_edge_accuracy: 0.4500, 

Step 1215, Epoch 16/20, Batch 15/80
temp: 0.9990, beta: 0.0009, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0180, enc_train_loss: 0.1265, enc_train_entropy: 0.6826, dec_train_loss: 0.0179, train_edge_accuracy: 0.4667, 

Step 1220, Epoch 16/20, Batch 20/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1268, enc_train_entropy: 0.6826, dec_train_loss: 0.0176, train_edge_accuracy: 0.4617, 

Step 1225, Epoch 16/20, Batch 25/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1881, enc_train_entropy: 0.6775, dec_train_loss: 0.0179, train_edge_accuracy: 0.4650, 

Step 1230, Epoch 16/20, Batch 30/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0181, enc_train_loss: 0.1271, enc_train_entropy: 0.6826, dec_train_loss: 0.0179, train_edge_accuracy: 0.4650, 

Step 1235, Epoch 16/20, Batch 35/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0179, enc_train_loss: 0.1170, enc_train_entropy: 0.6834, dec_train_loss: 0.0177, train_edge_accuracy: 0.4650, 

Step 1240, Epoch 16/20, Batch 40/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1175, enc_train_entropy: 0.6834, dec_train_loss: 0.0174, train_edge_accuracy: 0.4717, 

Step 1245, Epoch 16/20, Batch 45/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0179, enc_train_loss: 0.1197, enc_train_entropy: 0.6832, dec_train_loss: 0.0178, train_edge_accuracy: 0.4650, 

Step 1250, Epoch 16/20, Batch 50/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1382, enc_train_entropy: 0.6816, dec_train_loss: 0.0177, train_edge_accuracy: 0.4683, 

Step 1255, Epoch 16/20, Batch 55/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1274, enc_train_entropy: 0.6825, dec_train_loss: 0.0175, train_edge_accuracy: 0.4650, 

Step 1260, Epoch 16/20, Batch 60/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1315, enc_train_entropy: 0.6822, dec_train_loss: 0.0175, train_edge_accuracy: 0.4733, 

Step 1265, Epoch 16/20, Batch 65/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1080, enc_train_entropy: 0.6841, dec_train_loss: 0.0175, train_edge_accuracy: 0.4750, 

Step 1270, Epoch 16/20, Batch 70/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0179, enc_train_loss: 0.0997, enc_train_entropy: 0.6848, dec_train_loss: 0.0178, train_edge_accuracy: 0.4617, 

Step 1275, Epoch 16/20, Batch 75/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1111, enc_train_entropy: 0.6839, dec_train_loss: 0.0176, train_edge_accuracy: 0.4617, 


Epoch 16/20 completed, Global Step: 1280
nri_train_loss: 0.0177, enc_train_loss: 0.1111, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6839, dec_train_loss: 0.0176, train_edge_accuracy: 0.4617
nri_val_loss: 0.0177, enc_val_loss: 0.1112, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6839, dec_val_loss: 0.0176, val_edge_accuracy: 0.4655

---------------------------------------------------------------------------

Step 1280, Epoch 17/20, Batch 0/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0179, enc_train_loss: 0.1178, enc_train_entropy: 0.6833, dec_train_loss: 0.0178, train_edge_accuracy: 0.4650, 

Step 1285, Epoch 17/20, Batch 5/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1109, enc_train_entropy: 0.6839, dec_train_loss: 0.0176, train_edge_accuracy: 0.4450, 

Step 1290, Epoch 17/20, Batch 10/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.1018, enc_train_entropy: 0.6847, dec_train_loss: 0.0175, train_edge_accuracy: 0.5017, 

Step 1295, Epoch 17/20, Batch 15/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.0965, enc_train_entropy: 0.6851, dec_train_loss: 0.0177, train_edge_accuracy: 0.4783, 

Step 1300, Epoch 17/20, Batch 20/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1272, enc_train_entropy: 0.6825, dec_train_loss: 0.0176, train_edge_accuracy: 0.4900, 

Step 1305, Epoch 17/20, Batch 25/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1180, enc_train_entropy: 0.6833, dec_train_loss: 0.0176, train_edge_accuracy: 0.4667, 

Step 1310, Epoch 17/20, Batch 30/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1221, enc_train_entropy: 0.6830, dec_train_loss: 0.0176, train_edge_accuracy: 0.4650, 

Step 1315, Epoch 17/20, Batch 35/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.0974, enc_train_entropy: 0.6850, dec_train_loss: 0.0176, train_edge_accuracy: 0.4600, 

Step 1320, Epoch 17/20, Batch 40/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.1295, enc_train_entropy: 0.6824, dec_train_loss: 0.0175, train_edge_accuracy: 0.4633, 

Step 1325, Epoch 17/20, Batch 45/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.1224, enc_train_entropy: 0.6830, dec_train_loss: 0.0172, train_edge_accuracy: 0.4650, 

Step 1330, Epoch 17/20, Batch 50/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1141, enc_train_entropy: 0.6836, dec_train_loss: 0.0177, train_edge_accuracy: 0.4750, 

Step 1335, Epoch 17/20, Batch 55/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1125, enc_train_entropy: 0.6838, dec_train_loss: 0.0174, train_edge_accuracy: 0.4783, 

Step 1340, Epoch 17/20, Batch 60/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0893, enc_train_entropy: 0.6857, dec_train_loss: 0.0175, train_edge_accuracy: 0.4850, 

Step 1345, Epoch 17/20, Batch 65/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1240, enc_train_entropy: 0.6828, dec_train_loss: 0.0175, train_edge_accuracy: 0.4600, 

Step 1350, Epoch 17/20, Batch 70/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0910, enc_train_entropy: 0.6856, dec_train_loss: 0.0175, train_edge_accuracy: 0.4650, 

Step 1355, Epoch 17/20, Batch 75/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1009, enc_train_entropy: 0.6847, dec_train_loss: 0.0174, train_edge_accuracy: 0.4533, 


Epoch 17/20 completed, Global Step: 1360
nri_train_loss: 0.0175, enc_train_loss: 0.1009, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6847, dec_train_loss: 0.0174, train_edge_accuracy: 0.4533
nri_val_loss: 0.0176, enc_val_loss: 0.1122, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6838, dec_val_loss: 0.0175, val_edge_accuracy: 0.4588

---------------------------------------------------------------------------

Step 1360, Epoch 18/20, Batch 0/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1285, enc_train_entropy: 0.6824, dec_train_loss: 0.0176, train_edge_accuracy: 0.4700, 

Step 1365, Epoch 18/20, Batch 5/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1082, enc_train_entropy: 0.6841, dec_train_loss: 0.0174, train_edge_accuracy: 0.4867, 

Step 1370, Epoch 18/20, Batch 10/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1003, enc_train_entropy: 0.6848, dec_train_loss: 0.0176, train_edge_accuracy: 0.4900, 

Step 1375, Epoch 18/20, Batch 15/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1029, enc_train_entropy: 0.6846, dec_train_loss: 0.0174, train_edge_accuracy: 0.4567, 

Step 1380, Epoch 18/20, Batch 20/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.1050, enc_train_entropy: 0.6844, dec_train_loss: 0.0171, train_edge_accuracy: 0.4700, 

Step 1385, Epoch 18/20, Batch 25/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.0988, enc_train_entropy: 0.6849, dec_train_loss: 0.0177, train_edge_accuracy: 0.4700, 

Step 1390, Epoch 18/20, Batch 30/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0968, enc_train_entropy: 0.6851, dec_train_loss: 0.0173, train_edge_accuracy: 0.4583, 

Step 1395, Epoch 18/20, Batch 35/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.1037, enc_train_entropy: 0.6845, dec_train_loss: 0.0175, train_edge_accuracy: 0.4533, 

Step 1400, Epoch 18/20, Batch 40/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0959, enc_train_entropy: 0.6852, dec_train_loss: 0.0175, train_edge_accuracy: 0.4550, 

Step 1405, Epoch 18/20, Batch 45/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1048, enc_train_entropy: 0.6844, dec_train_loss: 0.0176, train_edge_accuracy: 0.4583, 

Step 1410, Epoch 18/20, Batch 50/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0969, enc_train_entropy: 0.6851, dec_train_loss: 0.0175, train_edge_accuracy: 0.4600, 

Step 1415, Epoch 18/20, Batch 55/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.1065, enc_train_entropy: 0.6843, dec_train_loss: 0.0175, train_edge_accuracy: 0.4767, 

Step 1420, Epoch 18/20, Batch 60/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 0.1158, enc_train_entropy: 0.6835, dec_train_loss: 0.0176, train_edge_accuracy: 0.4600, 

Step 1425, Epoch 18/20, Batch 65/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0880, enc_train_entropy: 0.6858, dec_train_loss: 0.0173, train_edge_accuracy: 0.4783, 

Step 1430, Epoch 18/20, Batch 70/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.1064, enc_train_entropy: 0.6843, dec_train_loss: 0.0171, train_edge_accuracy: 0.4767, 

Step 1435, Epoch 18/20, Batch 75/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0821, enc_train_entropy: 0.6863, dec_train_loss: 0.0173, train_edge_accuracy: 0.4617, 


Epoch 18/20 completed, Global Step: 1440
nri_train_loss: 0.0174, enc_train_loss: 0.0821, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6863, dec_train_loss: 0.0173, train_edge_accuracy: 0.4617
nri_val_loss: 0.0175, enc_val_loss: 0.0933, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6854, dec_val_loss: 0.0174, val_edge_accuracy: 0.4723

---------------------------------------------------------------------------

Step 1440, Epoch 19/20, Batch 0/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0855, enc_train_entropy: 0.6860, dec_train_loss: 0.0173, train_edge_accuracy: 0.4600, 

Step 1445, Epoch 19/20, Batch 5/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 0.1169, enc_train_entropy: 0.6834, dec_train_loss: 0.0177, train_edge_accuracy: 0.4600, 

Step 1450, Epoch 19/20, Batch 10/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1162, enc_train_entropy: 0.6835, dec_train_loss: 0.0173, train_edge_accuracy: 0.4700, 

Step 1455, Epoch 19/20, Batch 15/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0793, enc_train_entropy: 0.6865, dec_train_loss: 0.0173, train_edge_accuracy: 0.4717, 

Step 1460, Epoch 19/20, Batch 20/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.1058, enc_train_entropy: 0.6843, dec_train_loss: 0.0173, train_edge_accuracy: 0.4433, 

Step 1465, Epoch 19/20, Batch 25/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.0760, enc_train_entropy: 0.6868, dec_train_loss: 0.0171, train_edge_accuracy: 0.4450, 

Step 1470, Epoch 19/20, Batch 30/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0900, enc_train_entropy: 0.6856, dec_train_loss: 0.0175, train_edge_accuracy: 0.4683, 

Step 1475, Epoch 19/20, Batch 35/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0864, enc_train_entropy: 0.6859, dec_train_loss: 0.0175, train_edge_accuracy: 0.4817, 

Step 1480, Epoch 19/20, Batch 40/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.1005, enc_train_entropy: 0.6848, dec_train_loss: 0.0172, train_edge_accuracy: 0.4450, 

Step 1485, Epoch 19/20, Batch 45/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1154, enc_train_entropy: 0.6835, dec_train_loss: 0.0173, train_edge_accuracy: 0.4717, 

Step 1490, Epoch 19/20, Batch 50/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0960, enc_train_entropy: 0.6851, dec_train_loss: 0.0174, train_edge_accuracy: 0.4633, 

Step 1495, Epoch 19/20, Batch 55/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.1057, enc_train_entropy: 0.6843, dec_train_loss: 0.0172, train_edge_accuracy: 0.4483, 

Step 1500, Epoch 19/20, Batch 60/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0964, enc_train_entropy: 0.6851, dec_train_loss: 0.0173, train_edge_accuracy: 0.4750, 

Step 1505, Epoch 19/20, Batch 65/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.1063, enc_train_entropy: 0.6843, dec_train_loss: 0.0174, train_edge_accuracy: 0.4767, 

Step 1510, Epoch 19/20, Batch 70/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.1007, enc_train_entropy: 0.6848, dec_train_loss: 0.0173, train_edge_accuracy: 0.4600, 

Step 1515, Epoch 19/20, Batch 75/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0174, enc_train_loss: 0.0843, enc_train_entropy: 0.6861, dec_train_loss: 0.0174, train_edge_accuracy: 0.4567, 


Epoch 19/20 completed, Global Step: 1520
nri_train_loss: 0.0174, enc_train_loss: 0.0843, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6861, dec_train_loss: 0.0174, train_edge_accuracy: 0.4567
nri_val_loss: 0.0173, enc_val_loss: 0.0950, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6852, dec_val_loss: 0.0172, val_edge_accuracy: 0.4768

---------------------------------------------------------------------------

Step 1520, Epoch 20/20, Batch 0/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.0952, enc_train_entropy: 0.6852, dec_train_loss: 0.0172, train_edge_accuracy: 0.4917, 

Step 1525, Epoch 20/20, Batch 5/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.0748, enc_train_entropy: 0.6869, dec_train_loss: 0.0172, train_edge_accuracy: 0.4783, 

Step 1530, Epoch 20/20, Batch 10/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0908, enc_train_entropy: 0.6856, dec_train_loss: 0.0175, train_edge_accuracy: 0.4650, 

Step 1535, Epoch 20/20, Batch 15/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.0904, enc_train_entropy: 0.6856, dec_train_loss: 0.0172, train_edge_accuracy: 0.4483, 

Step 1540, Epoch 20/20, Batch 20/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 0.0746, enc_train_entropy: 0.6869, dec_train_loss: 0.0174, train_edge_accuracy: 0.4350, 

Step 1545, Epoch 20/20, Batch 25/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.0742, enc_train_entropy: 0.6870, dec_train_loss: 0.0173, train_edge_accuracy: 0.4700, 

Step 1550, Epoch 20/20, Batch 30/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 0.0867, enc_train_entropy: 0.6859, dec_train_loss: 0.0175, train_edge_accuracy: 0.4617, 

Step 1555, Epoch 20/20, Batch 35/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.0964, enc_train_entropy: 0.6851, dec_train_loss: 0.0172, train_edge_accuracy: 0.4483, 

Step 1560, Epoch 20/20, Batch 40/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.1261, enc_train_entropy: 0.6826, dec_train_loss: 0.0172, train_edge_accuracy: 0.4850, 

Step 1565, Epoch 20/20, Batch 45/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.0885, enc_train_entropy: 0.6858, dec_train_loss: 0.0172, train_edge_accuracy: 0.4950, 

Step 1570, Epoch 20/20, Batch 50/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 0.1159, enc_train_entropy: 0.6835, dec_train_loss: 0.0172, train_edge_accuracy: 0.4817, 

Step 1575, Epoch 20/20, Batch 55/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0171, enc_train_loss: 0.1102, enc_train_entropy: 0.6840, dec_train_loss: 0.0170, train_edge_accuracy: 0.4483, 

Step 1580, Epoch 20/20, Batch 60/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.0915, enc_train_entropy: 0.6855, dec_train_loss: 0.0171, train_edge_accuracy: 0.4867, 

Step 1585, Epoch 20/20, Batch 65/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.0929, enc_train_entropy: 0.6854, dec_train_loss: 0.0171, train_edge_accuracy: 0.4567, 

Step 1590, Epoch 20/20, Batch 70/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0172, enc_train_loss: 0.0966, enc_train_entropy: 0.6851, dec_train_loss: 0.0171, train_edge_accuracy: 0.4800, 

Step 1595, Epoch 20/20, Batch 75/80
temp: 0.9990, beta: 0.0010, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0170, enc_train_loss: 0.0922, enc_train_entropy: 0.6855, dec_train_loss: 0.0169, train_edge_accuracy: 0.4550, 


Epoch 20/20 completed, Global Step: 1600
nri_train_loss: 0.0170, enc_train_loss: 0.0922, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.6855, dec_train_loss: 0.0169, train_edge_accuracy: 0.4550
nri_val_loss: 0.0172, enc_val_loss: 0.0948, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.6852, dec_val_loss: 0.0171, val_edge_accuracy: 0.4655

---------------------------------------------------------------------------


Training completed in 595.74 seconds or 9.93 minutes or 0.1654829044474496 hours.
Total training steps: 1600

Training completed for model '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12'. Trained model saved at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12\checkpoints

---------------------------------------------------------------------------

<<<<<<<<<<<< TRAINING LOSS PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating training loss plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12...

Training loss (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12


<<<<<<<<<<<< ENCODER EDGE ACCURACY PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating encoder edge accuracy plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12...

Encoder edge accuracy (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12


<<<<<<<<<<<< ENCODER EDGE ENTROPY PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating encoder edge entropy plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12...

Encoder edge entropy (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12


<<<<<<<<<<<< DECODER OUTPUT PLOT (TRAIN) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.386' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12...

Decoder output plot for rep '1001.3859' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12


<<<<<<<<<<<< DECODER OUTPUT PLOT (VAL) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.288' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12...

Decoder output plot for rep '1001.2882' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12


---------------------------------------------------------------------------

TESTING TRAINED NRI MODEL...

.ckpt_files available in C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12\checkpoints:

['best-model-epoch=19-val_loss=0.0000.ckpt']

Trained NRI Model Loaded for testing.

Testing environment set. Testing will be logged at: C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12\test
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Testing: |                                                                                    | 0/? [00:00<?, ?it/s]
Initializing input processors for encoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Initializing input processors for decoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------
Testing:   0%|                                                                               | 0/10 [00:00<?, ?it/s]Testing DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]Testing DataLoader 0:  10%|#####8                                                    | 1/10 [00:00<00:03,  2.36it/s]Testing DataLoader 0:  20%|###########6                                              | 2/10 [00:00<00:03,  2.42it/s]Testing DataLoader 0:  30%|#################4                                        | 3/10 [00:01<00:03,  2.30it/s]Testing DataLoader 0:  40%|#######################2                                  | 4/10 [00:01<00:02,  2.32it/s]Testing DataLoader 0:  50%|#############################                             | 5/10 [00:02<00:02,  2.38it/s]Testing DataLoader 0:  60%|##################################8                       | 6/10 [00:02<00:01,  2.40it/s]Testing DataLoader 0:  70%|########################################5                 | 7/10 [00:02<00:01,  2.36it/s]Testing DataLoader 0:  80%|##############################################4           | 8/10 [00:03<00:00,  2.36it/s]Testing DataLoader 0:  90%|####################################################2     | 9/10 [00:03<00:00,  2.36it/s]Testing DataLoader 0: 100%|#########################################################| 10/10 [00:04<00:00,  2.38it/s]
Testing completed in 4.21 seconds or 0.07 minutes or 0.0011682328250673083 hours.

nri_test_loss: 0.1144, enc_test_loss: 0.0971, dec_test_loss: 0.0173, test_edge_accuracy: 0.4690

Edge predictions are as follows (showing probabilities for each edge type):

Rep 1,001.217:
[[0.56028605 0.43971393]
 [0.5471341  0.4528659 ]
 [0.48062012 0.5193799 ]
 [0.5394847  0.46051532]
 [0.55489796 0.44510198]
 [0.47371662 0.5262833 ]
 [0.5449755  0.45502445]
 [0.5534352  0.44656482]
 [0.47063622 0.52936375]
 [0.5383139  0.4616861 ]
 [0.5648336  0.43516642]
 [0.5622992  0.43770075]]

Rep 1,001.399:
[[0.43641266 0.56358737]
 [0.45834997 0.54165   ]
 [0.44580767 0.5541923 ]
 [0.41812608 0.5818739 ]
 [0.4605248  0.53947526]
 [0.43359423 0.5664058 ]
 [0.4119029  0.5880971 ]
 [0.4193505  0.5806495 ]
 [0.436897   0.56310296]
 [0.42540002 0.5746    ]
 [0.4311194  0.56888056]
 [0.45704532 0.5429546 ]]

Rep 1,001.425:
[[0.5051527  0.4948473 ]
 [0.49240768 0.5075923 ]
 [0.4475823  0.55241764]
 [0.48834085 0.51165915]
 [0.51127416 0.4887258 ]
 [0.45048118 0.5495188 ]
 [0.47564438 0.5243556 ]
 [0.5004772  0.49952286]
 [0.44808304 0.55191696]
 [0.48846263 0.5115374 ]
 [0.5158103  0.48418966]
 [0.5137451  0.48625484]]

Rep 1,001.211:
[[0.43163773 0.5683623 ]
 [0.36439648 0.6356035 ]
 [0.35527825 0.6447218 ]
 [0.49769783 0.50230217]
 [0.3750682  0.62493175]
 [0.36380574 0.6361942 ]
 [0.49344563 0.50655437]
 [0.44666958 0.5533304 ]
 [0.37624532 0.6237546 ]
 [0.50483567 0.49516436]
 [0.44794932 0.5520507 ]
 [0.38591042 0.61408955]]

Rep 1,001.218:
[[0.46240315 0.5375969 ]
 [0.40108797 0.598912  ]
 [0.3952233  0.60477674]
 [0.4942931  0.50570685]
 [0.4134041  0.58659583]
 [0.3876535  0.6123465 ]
 [0.4947557  0.50524426]
 [0.47736362 0.5226364 ]
 [0.39498025 0.6050197 ]
 [0.50063515 0.49936485]
 [0.48056376 0.5194363 ]
 [0.41506884 0.5849312 ]]

Rep 1,001.531:
[[0.49481162 0.50518835]
 [0.44736364 0.5526363 ]
 [0.39650297 0.60349697]
 [0.49133173 0.50866824]
 [0.4501544  0.54984564]
 [0.39720127 0.6027987 ]
 [0.48299584 0.51700413]
 [0.4972454  0.5027546 ]
 [0.39923942 0.60076064]
 [0.49272403 0.50727594]
 [0.5065772  0.4934228 ]
 [0.4640707  0.53592926]]

Rep 1,001.110:
[[0.44076508 0.5592349 ]
 [0.43498284 0.56501716]
 [0.4187153  0.5812847 ]
 [0.38547269 0.61452734]
 [0.43200302 0.567997  ]
 [0.40864822 0.5913518 ]
 [0.37469643 0.6253036 ]
 [0.42178926 0.5782107 ]
 [0.4159223  0.5840777 ]
 [0.38668546 0.6133145 ]
 [0.4232212  0.5767788 ]
 [0.42819232 0.57180774]]

Rep 1,001.491:
[[0.52578217 0.47421783]
 [0.57523054 0.4247694 ]
 [0.52642214 0.4735779 ]
 [0.4981097  0.5018903 ]
 [0.5752397  0.4247603 ]
 [0.527704   0.472296  ]
 [0.4779886  0.5220114 ]
 [0.52014995 0.47985008]
 [0.5198939  0.48010617]
 [0.48855686 0.51144314]
 [0.5323517  0.46764833]
 [0.58448464 0.4155153 ]]

Rep 1,001.107:
[[0.5405128  0.4594872 ]
 [0.5204114  0.47958863]
 [0.47388208 0.5261179 ]
 [0.56415385 0.4358461 ]
 [0.5276018  0.4723982 ]
 [0.47474337 0.52525663]
 [0.5540397  0.4459603 ]
 [0.524064   0.47593597]
 [0.45769855 0.5423015 ]
 [0.56852275 0.43147728]
 [0.5380688  0.46193126]
 [0.52602077 0.47397923]]

Rep 1,001.130:
[[0.56242466 0.43757528]
 [0.5068057  0.49319428]
 [0.46804896 0.53195107]
 [0.510187   0.4898131 ]
 [0.50017434 0.49982566]
 [0.46281245 0.5371876 ]
 [0.5075123  0.49248773]
 [0.5454504  0.45454958]
 [0.46222296 0.537777  ]
 [0.5113175  0.4886825 ]
 [0.55872214 0.44127786]
 [0.5152409  0.48475912]]

Rep 1,001.237:
[[0.45355833 0.5464417 ]
 [0.45714018 0.5428598 ]
 [0.4533519  0.5466481 ]
 [0.45101133 0.54898864]
 [0.45389956 0.54610044]
 [0.45841852 0.54158145]
 [0.43416473 0.56583524]
 [0.43845433 0.56154567]
 [0.4474861  0.5525139 ]
 [0.43391937 0.5660807 ]
 [0.44097573 0.5590243 ]
 [0.45311153 0.5468884 ]]

Rep 1,001.287:
[[0.4882075  0.51179254]
 [0.5036187  0.49638128]
 [0.4816277  0.5183723 ]
 [0.45756972 0.54243034]
 [0.5021216  0.49787834]
 [0.48581675 0.5141833 ]
 [0.4399348  0.5600652 ]
 [0.4773642  0.5226358 ]
 [0.47933087 0.5206691 ]
 [0.45626885 0.54373115]
 [0.4953269  0.50467306]
 [0.50961167 0.49038833]]

Rep 1,001.291:
[[0.5317422  0.46825778]
 [0.5728644  0.42713562]
 [0.5164077  0.48359224]
 [0.5025309  0.4974691 ]
 [0.5724787  0.42752135]
 [0.5112967  0.48870328]
 [0.5037536  0.4962464 ]
 [0.54783565 0.45216438]
 [0.5061355  0.49386448]
 [0.5020568  0.49794322]
 [0.5482026  0.45179746]
 [0.57207125 0.42792875]]

Rep 1,001.438:
[[0.5761703  0.42382962]
 [0.5136009  0.4863991 ]
 [0.44044352 0.5595565 ]
 [0.59646875 0.4035312 ]
 [0.5223443  0.47765574]
 [0.44265532 0.5573447 ]
 [0.6088404  0.3911596 ]
 [0.57177156 0.4282284 ]
 [0.44413024 0.55586976]
 [0.60236    0.39763993]
 [0.5697945  0.43020555]
 [0.5329409  0.46705908]]

Rep 1,001.223:
[[0.5182229  0.48177704]
 [0.5390183  0.46098176]
 [0.47665355 0.5233464 ]
 [0.49180862 0.50819135]
 [0.54648405 0.45351598]
 [0.47480956 0.5251904 ]
 [0.47220474 0.52779526]
 [0.51666135 0.48333862]
 [0.46903133 0.53096867]
 [0.4920886  0.5079114 ]
 [0.51877743 0.48122254]
 [0.55001473 0.44998524]]

Rep 1,001.199:
[[0.41830605 0.58169395]
 [0.45262757 0.5473724 ]
 [0.4414247  0.55857533]
 [0.42585465 0.5741453 ]
 [0.46079978 0.53920025]
 [0.44572005 0.5542799 ]
 [0.4195174  0.58048254]
 [0.41789678 0.5821032 ]
 [0.44139275 0.5586072 ]
 [0.43281218 0.56718785]
 [0.40861824 0.5913817 ]
 [0.4734626  0.5265374 ]]

Rep 1,001.350:
[[0.42033148 0.5796685 ]
 [0.43570083 0.56429917]
 [0.438165   0.561835  ]
 [0.40580332 0.5941966 ]
 [0.42865634 0.57134366]
 [0.43052197 0.56947803]
 [0.3990154  0.60098463]
 [0.3977694  0.6022306 ]
 [0.43092585 0.56907415]
 [0.41326535 0.5867346 ]
 [0.41234806 0.5876519 ]
 [0.4316382  0.5683618 ]]

Rep 1,001.387:
[[0.41072217 0.5892778 ]
 [0.38287333 0.6171267 ]
 [0.3813976  0.61860234]
 [0.44469854 0.5553014 ]
 [0.39567763 0.6043223 ]
 [0.39459231 0.6054077 ]
 [0.43257567 0.5674243 ]
 [0.4113041  0.5886959 ]
 [0.40003002 0.59997   ]
 [0.45244783 0.54755217]
 [0.4249295  0.5750705 ]
 [0.408826   0.591174  ]]

Rep 1,001.364:
[[0.5565015  0.44349852]
 [0.57922775 0.42077222]
 [0.51693636 0.48306364]
 [0.5185195  0.4814805 ]
 [0.579571   0.42042893]
 [0.5166115  0.48338848]
 [0.5147554  0.48524454]
 [0.5608726  0.43912736]
 [0.5190159  0.48098412]
 [0.5190817  0.4809183 ]
 [0.56082404 0.43917596]
 [0.587626   0.41237405]]

Rep 1,001.151:
[[0.60247755 0.39752242]
 [0.52019274 0.47980726]
 [0.46372327 0.53627676]
 [0.59806025 0.4019398 ]
 [0.5248311  0.47516888]
 [0.4614662  0.53853375]
 [0.59389335 0.4061067 ]
 [0.5864452  0.4135548 ]
 [0.45922425 0.5407757 ]
 [0.6064194  0.39358065]
 [0.5981641  0.40183592]
 [0.5351139  0.46488616]]

Rep 1,001.141:
[[0.4903522  0.5096478 ]
 [0.49430645 0.50569355]
 [0.44694516 0.5530548 ]
 [0.49666637 0.50333357]
 [0.50429416 0.49570584]
 [0.44754097 0.552459  ]
 [0.49982044 0.5001796 ]
 [0.49617773 0.5038223 ]
 [0.44326857 0.5567314 ]
 [0.50024027 0.4997597 ]
 [0.49977207 0.5002279 ]
 [0.5173271  0.48267296]]

Rep 1,001.734:
[[0.51932913 0.4806709 ]
 [0.50928575 0.49071425]
 [0.48208243 0.5179176 ]
 [0.487469   0.51253104]
 [0.51579416 0.48420587]
 [0.48751637 0.51248366]
 [0.47735277 0.5226472 ]
 [0.5027743  0.49722573]
 [0.4765321  0.5234679 ]
 [0.48756737 0.51243263]
 [0.5104758  0.48952416]
 [0.5168658  0.4831342 ]]

Rep 1,001.395:
[[0.52251107 0.47748896]
 [0.4857573  0.5142427 ]
 [0.44378945 0.5562106 ]
 [0.56310326 0.43689677]
 [0.49078986 0.50921017]
 [0.44689062 0.55310935]
 [0.5483642  0.45163575]
 [0.50967586 0.4903241 ]
 [0.4357494  0.56425065]
 [0.5598038  0.44019622]
 [0.5246936  0.47530645]
 [0.48488072 0.5151193 ]]

Rep 1,001.219:
[[0.6084148  0.39158523]
 [0.55267584 0.4473242 ]
 [0.4943159  0.5056841 ]
 [0.5888282  0.4111718 ]
 [0.5528079  0.44719204]
 [0.50123036 0.49876964]
 [0.57850575 0.42149422]
 [0.60448194 0.39551806]
 [0.499112   0.500888  ]
 [0.5882402  0.41175976]
 [0.61044604 0.389554  ]
 [0.5652097  0.4347903 ]]

Rep 1,001.459:
[[0.38524815 0.6147519 ]
 [0.43601337 0.56398666]
 [0.4197355  0.5802645 ]
 [0.40014312 0.59985685]
 [0.45024857 0.5497514 ]
 [0.42479828 0.5752017 ]
 [0.37196803 0.62803197]
 [0.36380324 0.63619673]
 [0.42638597 0.57361406]
 [0.38216838 0.6178316 ]
 [0.37883076 0.6211692 ]
 [0.44192305 0.5580769 ]]

Rep 1,001.016:
[[0.58157164 0.41842836]
 [0.5916437  0.40835628]
 [0.49734193 0.50265807]
 [0.5802784  0.4197216 ]
 [0.60701406 0.3929859 ]
 [0.50592864 0.49407142]
 [0.58198476 0.41801524]
 [0.583057   0.41694295]
 [0.50363857 0.49636146]
 [0.5774717  0.42252833]
 [0.5894776  0.4105224 ]
 [0.61359596 0.38640404]]

Rep 1,001.157:
[[0.5621168  0.4378832 ]
 [0.6286076  0.3713925 ]
 [0.5242655  0.47573447]
 [0.53123146 0.46876854]
 [0.62440974 0.37559023]
 [0.5302944  0.46970558]
 [0.53473634 0.4652637 ]
 [0.56841075 0.43158922]
 [0.5351187  0.4648813 ]
 [0.5262772  0.47372285]
 [0.5728662  0.4271338 ]
 [0.6243268  0.37567317]]

Rep 1,001.635:
[[0.5225203  0.4774797 ]
 [0.56263846 0.43736154]
 [0.4836305  0.51636946]
 [0.5414839  0.45851612]
 [0.5596273  0.44037268]
 [0.48026326 0.5197367 ]
 [0.5458471  0.45415285]
 [0.520511   0.47948906]
 [0.48224372 0.5177563 ]
 [0.5576511  0.44234893]
 [0.538727   0.46127307]
 [0.5669812  0.4330188 ]]

Rep 1,001.491:
[[0.45466566 0.54533434]
 [0.48868522 0.5113148 ]
 [0.45688602 0.54311395]
 [0.43169633 0.5683037 ]
 [0.4856199  0.5143801 ]
 [0.46322188 0.5367781 ]
 [0.42244104 0.577559  ]
 [0.47112176 0.5288783 ]
 [0.46458218 0.53541785]
 [0.4317922  0.5682078 ]
 [0.45875922 0.5412408 ]
 [0.49467152 0.5053285 ]]

Rep 1,001.482:
[[0.43306887 0.5669311 ]
 [0.4403509  0.55964917]
 [0.4272617  0.5727383 ]
 [0.42186567 0.57813436]
 [0.4385395  0.5614605 ]
 [0.43095246 0.5690476 ]
 [0.40318796 0.596812  ]
 [0.40747324 0.5925268 ]
 [0.4153267  0.5846733 ]
 [0.40175292 0.59824705]
 [0.40366378 0.59633625]
 [0.44243443 0.5575656 ]]

Rep 1,001.963:
[[0.59208256 0.40791747]
 [0.5650836  0.43491632]
 [0.48916388 0.5108361 ]
 [0.5241466  0.47585335]
 [0.5812163  0.41878372]
 [0.5087657  0.49123427]
 [0.5187639  0.48123616]
 [0.5849184  0.41508165]
 [0.49876457 0.5012354 ]
 [0.53456724 0.4654327 ]
 [0.5863121  0.4136879 ]
 [0.577657   0.42234305]]

Rep 1,001.334:
[[0.41749448 0.5825055 ]
 [0.37752733 0.6224727 ]
 [0.3665298  0.63347024]
 [0.49120113 0.50879884]
 [0.39056367 0.60943633]
 [0.3760172  0.6239827 ]
 [0.48000184 0.5199982 ]
 [0.44318092 0.55681914]
 [0.38823807 0.6117619 ]
 [0.49178952 0.5082105 ]
 [0.4505469  0.5494531 ]
 [0.41006377 0.58993626]]

Rep 1,001.282:
[[0.56693065 0.43306935]
 [0.58133674 0.41866323]
 [0.529669   0.47033107]
 [0.5422255  0.45777455]
 [0.5837723  0.41622773]
 [0.52780896 0.47219107]
 [0.5379654  0.46203452]
 [0.56958234 0.43041772]
 [0.5378024  0.46219763]
 [0.5511308  0.4488693 ]
 [0.57746375 0.42253628]
 [0.584951   0.41504905]]

Rep 1,001.340:
[[0.46414396 0.535856  ]
 [0.49084118 0.50915885]
 [0.47126582 0.5287342 ]
 [0.45762175 0.5423782 ]
 [0.4856331  0.51436687]
 [0.4763966  0.52360344]
 [0.4414601  0.5585399 ]
 [0.45116943 0.5488305 ]
 [0.4617831  0.5382169 ]
 [0.4443195  0.5556805 ]
 [0.4594339  0.5405661 ]
 [0.49011332 0.5098867 ]]

Rep 1,001.454:
[[0.51899165 0.48100838]
 [0.4568943  0.5431057 ]
 [0.42389965 0.5761004 ]
 [0.54646814 0.45353192]
 [0.46407393 0.53592604]
 [0.42308867 0.57691133]
 [0.53948146 0.46051854]
 [0.51332104 0.48667896]
 [0.4286179  0.5713821 ]
 [0.54706854 0.4529314 ]
 [0.5159426  0.48405746]
 [0.46619746 0.5338025 ]]

Rep 1,001.429:
[[0.46287286 0.53712714]
 [0.39256623 0.60743374]
 [0.37919283 0.6208071 ]
 [0.48711646 0.51288354]
 [0.4005697  0.59943026]
 [0.36756378 0.6324362 ]
 [0.48706272 0.51293725]
 [0.4784976  0.5215024 ]
 [0.36964902 0.63035095]
 [0.49218264 0.5078174 ]
 [0.49248657 0.50751346]
 [0.4185046  0.58149546]]

Rep 1,001.426:
[[0.44928068 0.5507194 ]
 [0.45884714 0.5411529 ]
 [0.44578275 0.5542173 ]
 [0.42747408 0.57252586]
 [0.4502541  0.5497459 ]
 [0.44527614 0.5547239 ]
 [0.42262125 0.57737875]
 [0.42789412 0.5721059 ]
 [0.43702626 0.56297374]
 [0.42616278 0.5738372 ]
 [0.4349623  0.5650377 ]
 [0.45544413 0.54455584]]

Rep 1,001.319:
[[0.4667072  0.5332928 ]
 [0.458086   0.5419139 ]
 [0.4196569  0.58034307]
 [0.4688448  0.5311552 ]
 [0.47459576 0.5254043 ]
 [0.42636245 0.57363755]
 [0.4706504  0.5293496 ]
 [0.47433013 0.5256699 ]
 [0.4147922  0.5852078 ]
 [0.4746672  0.5253328 ]
 [0.47571498 0.52428496]
 [0.49637386 0.5036261 ]]

Rep 1,001.333:
[[0.4384208  0.56157917]
 [0.4943221  0.50567794]
 [0.46158558 0.5384144 ]
 [0.4495263  0.5504737 ]
 [0.4960787  0.5039213 ]
 [0.46992812 0.53007185]
 [0.43624473 0.56375533]
 [0.4381018  0.5618982 ]
 [0.46125752 0.53874254]
 [0.44639573 0.55360425]
 [0.4492485  0.5507515 ]
 [0.5030938  0.49690625]]

Rep 1,001.144:
[[0.5975618  0.4024382 ]
 [0.5477224  0.4522776 ]
 [0.49443644 0.50556356]
 [0.6181713  0.38182876]
 [0.5416478  0.4583522 ]
 [0.49396276 0.5060372 ]
 [0.6041599  0.39584005]
 [0.5921557  0.4078443 ]
 [0.49125612 0.5087439 ]
 [0.6153095  0.3846905 ]
 [0.60108304 0.398917  ]
 [0.55760676 0.44239324]]

Rep 1,001.330:
[[0.41136009 0.58863986]
 [0.44345748 0.5565426 ]
 [0.4251376  0.57486236]
 [0.41343555 0.5865645 ]
 [0.45162705 0.5483729 ]
 [0.42842367 0.57157636]
 [0.39743042 0.6025695 ]
 [0.404695   0.59530497]
 [0.43616652 0.5638335 ]
 [0.41416824 0.58583176]
 [0.40928715 0.59071285]
 [0.4508543  0.5491457 ]]

Rep 1,001.328:
[[0.3966745  0.6033254 ]
 [0.4221024  0.5778976 ]
 [0.4358952  0.5641048 ]
 [0.39414328 0.60585666]
 [0.42869258 0.57130736]
 [0.44379726 0.5562027 ]
 [0.370458   0.629542  ]
 [0.37372673 0.6262732 ]
 [0.4400287  0.5599713 ]
 [0.3770486  0.6229514 ]
 [0.3805895  0.61941046]
 [0.42523503 0.5747649 ]]

Rep 1,001.254:
[[0.55197746 0.4480225 ]
 [0.55575347 0.4442466 ]
 [0.5082714  0.4917286 ]
 [0.5090534  0.4909466 ]
 [0.572322   0.427678  ]
 [0.49442348 0.50557655]
 [0.50731057 0.49268943]
 [0.5474173  0.45258278]
 [0.4943075  0.50569254]
 [0.5070487  0.4929513 ]
 [0.55360615 0.44639382]
 [0.57336223 0.42663774]]

Rep 1,001.297:
[[0.44974592 0.5502541 ]
 [0.4007743  0.59922564]
 [0.36716115 0.63283885]
 [0.49702105 0.502979  ]
 [0.40072814 0.59927183]
 [0.36969793 0.6303021 ]
 [0.49800724 0.5019928 ]
 [0.45694155 0.54305845]
 [0.37701234 0.6229877 ]
 [0.50666213 0.49333787]
 [0.4608491  0.5391509 ]
 [0.4077522  0.5922478 ]]

Rep 1,001.494:
[[0.50012946 0.49987054]
 [0.460617   0.539383  ]
 [0.42630702 0.57369304]
 [0.52486104 0.47513902]
 [0.47188747 0.52811253]
 [0.43143886 0.56856114]
 [0.51375633 0.4862437 ]
 [0.49893004 0.50106996]
 [0.44425124 0.5557488 ]
 [0.52291226 0.47708768]
 [0.5056939  0.4943061 ]
 [0.49346262 0.5065374 ]]

Rep 1,001.483:
[[0.39172596 0.60827404]
 [0.4127549  0.58724505]
 [0.40611106 0.59388894]
 [0.3930022  0.6069978 ]
 [0.41134927 0.5886507 ]
 [0.398587   0.6014131 ]
 [0.38450515 0.61549485]
 [0.37553784 0.6244621 ]
 [0.39263642 0.6073636 ]
 [0.37916976 0.62083024]
 [0.373908   0.62609196]
 [0.3967502  0.6032498 ]]

Rep 1,001.272:
[[0.46341518 0.5365848 ]
 [0.4308998  0.56910014]
 [0.40936053 0.5906395 ]
 [0.52090067 0.47909936]
 [0.44155926 0.55844074]
 [0.41807958 0.58192044]
 [0.52078116 0.47921884]
 [0.47995153 0.52004844]
 [0.40761313 0.59238684]
 [0.52296853 0.47703147]
 [0.47344112 0.5265589 ]
 [0.45945922 0.54054075]]

Rep 1,001.368:
[[0.42135364 0.5786463 ]
 [0.43479997 0.5652001 ]
 [0.43356326 0.56643677]
 [0.4100134  0.5899866 ]
 [0.438476   0.561524  ]
 [0.43633217 0.5636679 ]
 [0.41267335 0.58732665]
 [0.43641782 0.5635822 ]
 [0.43306056 0.5669395 ]
 [0.4184284  0.5815716 ]
 [0.4300466  0.5699534 ]
 [0.4605411  0.5394589 ]]

Rep 1,001.077:
[[0.5031937  0.49680635]
 [0.45283842 0.54716164]
 [0.42237452 0.5776255 ]
 [0.47149822 0.5285018 ]
 [0.46001425 0.5399857 ]
 [0.42003158 0.5799684 ]
 [0.48648146 0.5135186 ]
 [0.50644994 0.4935501 ]
 [0.4269774  0.57302266]
 [0.4853915  0.5146085 ]
 [0.51156056 0.48843944]
 [0.47988278 0.5201172 ]]

Rep 1,001.256:
[[0.4658511  0.5341489 ]
 [0.4509659  0.54903406]
 [0.41857716 0.5814228 ]
 [0.4527848  0.54721516]
 [0.46214485 0.53785515]
 [0.42216656 0.5778334 ]
 [0.45722634 0.54277366]
 [0.4676334  0.5323666 ]
 [0.42505333 0.5749467 ]
 [0.46452242 0.5354776 ]
 [0.47544345 0.5245566 ]
 [0.47427648 0.5257235 ]]

Adjacency matrix from edge pred is as follows:

Rep 1,001.217:
[[[0.         0.        ]
  [0.56028605 0.43971393]
  [0.5471341  0.4528659 ]
  [0.48062012 0.5193799 ]]

 [[0.5394847  0.46051532]
  [0.         0.        ]
  [0.55489796 0.44510198]
  [0.47371662 0.5262833 ]]

 [[0.5449755  0.45502445]
  [0.5534352  0.44656482]
  [0.         0.        ]
  [0.47063622 0.52936375]]

 [[0.5383139  0.4616861 ]
  [0.5648336  0.43516642]
  [0.5622992  0.43770075]
  [0.         0.        ]]]

Rep 1,001.399:
[[[0.         0.        ]
  [0.43641266 0.56358737]
  [0.45834997 0.54165   ]
  [0.44580767 0.5541923 ]]

 [[0.41812608 0.5818739 ]
  [0.         0.        ]
  [0.4605248  0.53947526]
  [0.43359423 0.5664058 ]]

 [[0.4119029  0.5880971 ]
  [0.4193505  0.5806495 ]
  [0.         0.        ]
  [0.436897   0.56310296]]

 [[0.42540002 0.5746    ]
  [0.4311194  0.56888056]
  [0.45704532 0.5429546 ]
  [0.         0.        ]]]

Rep 1,001.425:
[[[0.         0.        ]
  [0.5051527  0.4948473 ]
  [0.49240768 0.5075923 ]
  [0.4475823  0.55241764]]

 [[0.48834085 0.51165915]
  [0.         0.        ]
  [0.51127416 0.4887258 ]
  [0.45048118 0.5495188 ]]

 [[0.47564438 0.5243556 ]
  [0.5004772  0.49952286]
  [0.         0.        ]
  [0.44808304 0.55191696]]

 [[0.48846263 0.5115374 ]
  [0.5158103  0.48418966]
  [0.5137451  0.48625484]
  [0.         0.        ]]]

Rep 1,001.211:
[[[0.         0.        ]
  [0.43163773 0.5683623 ]
  [0.36439648 0.6356035 ]
  [0.35527825 0.6447218 ]]

 [[0.49769783 0.50230217]
  [0.         0.        ]
  [0.3750682  0.62493175]
  [0.36380574 0.6361942 ]]

 [[0.49344563 0.50655437]
  [0.44666958 0.5533304 ]
  [0.         0.        ]
  [0.37624532 0.6237546 ]]

 [[0.50483567 0.49516436]
  [0.44794932 0.5520507 ]
  [0.38591042 0.61408955]
  [0.         0.        ]]]

Rep 1,001.218:
[[[0.         0.        ]
  [0.46240315 0.5375969 ]
  [0.40108797 0.598912  ]
  [0.3952233  0.60477674]]

 [[0.4942931  0.50570685]
  [0.         0.        ]
  [0.4134041  0.58659583]
  [0.3876535  0.6123465 ]]

 [[0.4947557  0.50524426]
  [0.47736362 0.5226364 ]
  [0.         0.        ]
  [0.39498025 0.6050197 ]]

 [[0.50063515 0.49936485]
  [0.48056376 0.5194363 ]
  [0.41506884 0.5849312 ]
  [0.         0.        ]]]

Rep 1,001.531:
[[[0.         0.        ]
  [0.49481162 0.50518835]
  [0.44736364 0.5526363 ]
  [0.39650297 0.60349697]]

 [[0.49133173 0.50866824]
  [0.         0.        ]
  [0.4501544  0.54984564]
  [0.39720127 0.6027987 ]]

 [[0.48299584 0.51700413]
  [0.4972454  0.5027546 ]
  [0.         0.        ]
  [0.39923942 0.60076064]]

 [[0.49272403 0.50727594]
  [0.5065772  0.4934228 ]
  [0.4640707  0.53592926]
  [0.         0.        ]]]

Rep 1,001.110:
[[[0.         0.        ]
  [0.44076508 0.5592349 ]
  [0.43498284 0.56501716]
  [0.4187153  0.5812847 ]]

 [[0.38547269 0.61452734]
  [0.         0.        ]
  [0.43200302 0.567997  ]
  [0.40864822 0.5913518 ]]

 [[0.37469643 0.6253036 ]
  [0.42178926 0.5782107 ]
  [0.         0.        ]
  [0.4159223  0.5840777 ]]

 [[0.38668546 0.6133145 ]
  [0.4232212  0.5767788 ]
  [0.42819232 0.57180774]
  [0.         0.        ]]]

Rep 1,001.491:
[[[0.         0.        ]
  [0.52578217 0.47421783]
  [0.57523054 0.4247694 ]
  [0.52642214 0.4735779 ]]

 [[0.4981097  0.5018903 ]
  [0.         0.        ]
  [0.5752397  0.4247603 ]
  [0.527704   0.472296  ]]

 [[0.4779886  0.5220114 ]
  [0.52014995 0.47985008]
  [0.         0.        ]
  [0.5198939  0.48010617]]

 [[0.48855686 0.51144314]
  [0.5323517  0.46764833]
  [0.58448464 0.4155153 ]
  [0.         0.        ]]]

Rep 1,001.107:
[[[0.         0.        ]
  [0.5405128  0.4594872 ]
  [0.5204114  0.47958863]
  [0.47388208 0.5261179 ]]

 [[0.56415385 0.4358461 ]
  [0.         0.        ]
  [0.5276018  0.4723982 ]
  [0.47474337 0.52525663]]

 [[0.5540397  0.4459603 ]
  [0.524064   0.47593597]
  [0.         0.        ]
  [0.45769855 0.5423015 ]]

 [[0.56852275 0.43147728]
  [0.5380688  0.46193126]
  [0.52602077 0.47397923]
  [0.         0.        ]]]

Rep 1,001.130:
[[[0.         0.        ]
  [0.56242466 0.43757528]
  [0.5068057  0.49319428]
  [0.46804896 0.53195107]]

 [[0.510187   0.4898131 ]
  [0.         0.        ]
  [0.50017434 0.49982566]
  [0.46281245 0.5371876 ]]

 [[0.5075123  0.49248773]
  [0.5454504  0.45454958]
  [0.         0.        ]
  [0.46222296 0.537777  ]]

 [[0.5113175  0.4886825 ]
  [0.55872214 0.44127786]
  [0.5152409  0.48475912]
  [0.         0.        ]]]

Rep 1,001.237:
[[[0.         0.        ]
  [0.45355833 0.5464417 ]
  [0.45714018 0.5428598 ]
  [0.4533519  0.5466481 ]]

 [[0.45101133 0.54898864]
  [0.         0.        ]
  [0.45389956 0.54610044]
  [0.45841852 0.54158145]]

 [[0.43416473 0.56583524]
  [0.43845433 0.56154567]
  [0.         0.        ]
  [0.4474861  0.5525139 ]]

 [[0.43391937 0.5660807 ]
  [0.44097573 0.5590243 ]
  [0.45311153 0.5468884 ]
  [0.         0.        ]]]

Rep 1,001.287:
[[[0.         0.        ]
  [0.4882075  0.51179254]
  [0.5036187  0.49638128]
  [0.4816277  0.5183723 ]]

 [[0.45756972 0.54243034]
  [0.         0.        ]
  [0.5021216  0.49787834]
  [0.48581675 0.5141833 ]]

 [[0.4399348  0.5600652 ]
  [0.4773642  0.5226358 ]
  [0.         0.        ]
  [0.47933087 0.5206691 ]]

 [[0.45626885 0.54373115]
  [0.4953269  0.50467306]
  [0.50961167 0.49038833]
  [0.         0.        ]]]

Rep 1,001.291:
[[[0.         0.        ]
  [0.5317422  0.46825778]
  [0.5728644  0.42713562]
  [0.5164077  0.48359224]]

 [[0.5025309  0.4974691 ]
  [0.         0.        ]
  [0.5724787  0.42752135]
  [0.5112967  0.48870328]]

 [[0.5037536  0.4962464 ]
  [0.54783565 0.45216438]
  [0.         0.        ]
  [0.5061355  0.49386448]]

 [[0.5020568  0.49794322]
  [0.5482026  0.45179746]
  [0.57207125 0.42792875]
  [0.         0.        ]]]

Rep 1,001.438:
[[[0.         0.        ]
  [0.5761703  0.42382962]
  [0.5136009  0.4863991 ]
  [0.44044352 0.5595565 ]]

 [[0.59646875 0.4035312 ]
  [0.         0.        ]
  [0.5223443  0.47765574]
  [0.44265532 0.5573447 ]]

 [[0.6088404  0.3911596 ]
  [0.57177156 0.4282284 ]
  [0.         0.        ]
  [0.44413024 0.55586976]]

 [[0.60236    0.39763993]
  [0.5697945  0.43020555]
  [0.5329409  0.46705908]
  [0.         0.        ]]]

Rep 1,001.223:
[[[0.         0.        ]
  [0.5182229  0.48177704]
  [0.5390183  0.46098176]
  [0.47665355 0.5233464 ]]

 [[0.49180862 0.50819135]
  [0.         0.        ]
  [0.54648405 0.45351598]
  [0.47480956 0.5251904 ]]

 [[0.47220474 0.52779526]
  [0.51666135 0.48333862]
  [0.         0.        ]
  [0.46903133 0.53096867]]

 [[0.4920886  0.5079114 ]
  [0.51877743 0.48122254]
  [0.55001473 0.44998524]
  [0.         0.        ]]]

Rep 1,001.199:
[[[0.         0.        ]
  [0.41830605 0.58169395]
  [0.45262757 0.5473724 ]
  [0.4414247  0.55857533]]

 [[0.42585465 0.5741453 ]
  [0.         0.        ]
  [0.46079978 0.53920025]
  [0.44572005 0.5542799 ]]

 [[0.4195174  0.58048254]
  [0.41789678 0.5821032 ]
  [0.         0.        ]
  [0.44139275 0.5586072 ]]

 [[0.43281218 0.56718785]
  [0.40861824 0.5913817 ]
  [0.4734626  0.5265374 ]
  [0.         0.        ]]]

Rep 1,001.350:
[[[0.         0.        ]
  [0.42033148 0.5796685 ]
  [0.43570083 0.56429917]
  [0.438165   0.561835  ]]

 [[0.40580332 0.5941966 ]
  [0.         0.        ]
  [0.42865634 0.57134366]
  [0.43052197 0.56947803]]

 [[0.3990154  0.60098463]
  [0.3977694  0.6022306 ]
  [0.         0.        ]
  [0.43092585 0.56907415]]

 [[0.41326535 0.5867346 ]
  [0.41234806 0.5876519 ]
  [0.4316382  0.5683618 ]
  [0.         0.        ]]]

Rep 1,001.387:
[[[0.         0.        ]
  [0.41072217 0.5892778 ]
  [0.38287333 0.6171267 ]
  [0.3813976  0.61860234]]

 [[0.44469854 0.5553014 ]
  [0.         0.        ]
  [0.39567763 0.6043223 ]
  [0.39459231 0.6054077 ]]

 [[0.43257567 0.5674243 ]
  [0.4113041  0.5886959 ]
  [0.         0.        ]
  [0.40003002 0.59997   ]]

 [[0.45244783 0.54755217]
  [0.4249295  0.5750705 ]
  [0.408826   0.591174  ]
  [0.         0.        ]]]

Rep 1,001.364:
[[[0.         0.        ]
  [0.5565015  0.44349852]
  [0.57922775 0.42077222]
  [0.51693636 0.48306364]]

 [[0.5185195  0.4814805 ]
  [0.         0.        ]
  [0.579571   0.42042893]
  [0.5166115  0.48338848]]

 [[0.5147554  0.48524454]
  [0.5608726  0.43912736]
  [0.         0.        ]
  [0.5190159  0.48098412]]

 [[0.5190817  0.4809183 ]
  [0.56082404 0.43917596]
  [0.587626   0.41237405]
  [0.         0.        ]]]

Rep 1,001.151:
[[[0.         0.        ]
  [0.60247755 0.39752242]
  [0.52019274 0.47980726]
  [0.46372327 0.53627676]]

 [[0.59806025 0.4019398 ]
  [0.         0.        ]
  [0.5248311  0.47516888]
  [0.4614662  0.53853375]]

 [[0.59389335 0.4061067 ]
  [0.5864452  0.4135548 ]
  [0.         0.        ]
  [0.45922425 0.5407757 ]]

 [[0.6064194  0.39358065]
  [0.5981641  0.40183592]
  [0.5351139  0.46488616]
  [0.         0.        ]]]

Rep 1,001.141:
[[[0.         0.        ]
  [0.4903522  0.5096478 ]
  [0.49430645 0.50569355]
  [0.44694516 0.5530548 ]]

 [[0.49666637 0.50333357]
  [0.         0.        ]
  [0.50429416 0.49570584]
  [0.44754097 0.552459  ]]

 [[0.49982044 0.5001796 ]
  [0.49617773 0.5038223 ]
  [0.         0.        ]
  [0.44326857 0.5567314 ]]

 [[0.50024027 0.4997597 ]
  [0.49977207 0.5002279 ]
  [0.5173271  0.48267296]
  [0.         0.        ]]]

Rep 1,001.734:
[[[0.         0.        ]
  [0.51932913 0.4806709 ]
  [0.50928575 0.49071425]
  [0.48208243 0.5179176 ]]

 [[0.487469   0.51253104]
  [0.         0.        ]
  [0.51579416 0.48420587]
  [0.48751637 0.51248366]]

 [[0.47735277 0.5226472 ]
  [0.5027743  0.49722573]
  [0.         0.        ]
  [0.4765321  0.5234679 ]]

 [[0.48756737 0.51243263]
  [0.5104758  0.48952416]
  [0.5168658  0.4831342 ]
  [0.         0.        ]]]

Rep 1,001.395:
[[[0.         0.        ]
  [0.52251107 0.47748896]
  [0.4857573  0.5142427 ]
  [0.44378945 0.5562106 ]]

 [[0.56310326 0.43689677]
  [0.         0.        ]
  [0.49078986 0.50921017]
  [0.44689062 0.55310935]]

 [[0.5483642  0.45163575]
  [0.50967586 0.4903241 ]
  [0.         0.        ]
  [0.4357494  0.56425065]]

 [[0.5598038  0.44019622]
  [0.5246936  0.47530645]
  [0.48488072 0.5151193 ]
  [0.         0.        ]]]

Rep 1,001.219:
[[[0.         0.        ]
  [0.6084148  0.39158523]
  [0.55267584 0.4473242 ]
  [0.4943159  0.5056841 ]]

 [[0.5888282  0.4111718 ]
  [0.         0.        ]
  [0.5528079  0.44719204]
  [0.50123036 0.49876964]]

 [[0.57850575 0.42149422]
  [0.60448194 0.39551806]
  [0.         0.        ]
  [0.499112   0.500888  ]]

 [[0.5882402  0.41175976]
  [0.61044604 0.389554  ]
  [0.5652097  0.4347903 ]
  [0.         0.        ]]]

Rep 1,001.459:
[[[0.         0.        ]
  [0.38524815 0.6147519 ]
  [0.43601337 0.56398666]
  [0.4197355  0.5802645 ]]

 [[0.40014312 0.59985685]
  [0.         0.        ]
  [0.45024857 0.5497514 ]
  [0.42479828 0.5752017 ]]

 [[0.37196803 0.62803197]
  [0.36380324 0.63619673]
  [0.         0.        ]
  [0.42638597 0.57361406]]

 [[0.38216838 0.6178316 ]
  [0.37883076 0.6211692 ]
  [0.44192305 0.5580769 ]
  [0.         0.        ]]]

Rep 1,001.016:
[[[0.         0.        ]
  [0.58157164 0.41842836]
  [0.5916437  0.40835628]
  [0.49734193 0.50265807]]

 [[0.5802784  0.4197216 ]
  [0.         0.        ]
  [0.60701406 0.3929859 ]
  [0.50592864 0.49407142]]

 [[0.58198476 0.41801524]
  [0.583057   0.41694295]
  [0.         0.        ]
  [0.50363857 0.49636146]]

 [[0.5774717  0.42252833]
  [0.5894776  0.4105224 ]
  [0.61359596 0.38640404]
  [0.         0.        ]]]

Rep 1,001.157:
[[[0.         0.        ]
  [0.5621168  0.4378832 ]
  [0.6286076  0.3713925 ]
  [0.5242655  0.47573447]]

 [[0.53123146 0.46876854]
  [0.         0.        ]
  [0.62440974 0.37559023]
  [0.5302944  0.46970558]]

 [[0.53473634 0.4652637 ]
  [0.56841075 0.43158922]
  [0.         0.        ]
  [0.5351187  0.4648813 ]]

 [[0.5262772  0.47372285]
  [0.5728662  0.4271338 ]
  [0.6243268  0.37567317]
  [0.         0.        ]]]

Rep 1,001.635:
[[[0.         0.        ]
  [0.5225203  0.4774797 ]
  [0.56263846 0.43736154]
  [0.4836305  0.51636946]]

 [[0.5414839  0.45851612]
  [0.         0.        ]
  [0.5596273  0.44037268]
  [0.48026326 0.5197367 ]]

 [[0.5458471  0.45415285]
  [0.520511   0.47948906]
  [0.         0.        ]
  [0.48224372 0.5177563 ]]

 [[0.5576511  0.44234893]
  [0.538727   0.46127307]
  [0.5669812  0.4330188 ]
  [0.         0.        ]]]

Rep 1,001.491:
[[[0.         0.        ]
  [0.45466566 0.54533434]
  [0.48868522 0.5113148 ]
  [0.45688602 0.54311395]]

 [[0.43169633 0.5683037 ]
  [0.         0.        ]
  [0.4856199  0.5143801 ]
  [0.46322188 0.5367781 ]]

 [[0.42244104 0.577559  ]
  [0.47112176 0.5288783 ]
  [0.         0.        ]
  [0.46458218 0.53541785]]

 [[0.4317922  0.5682078 ]
  [0.45875922 0.5412408 ]
  [0.49467152 0.5053285 ]
  [0.         0.        ]]]

Rep 1,001.482:
[[[0.         0.        ]
  [0.43306887 0.5669311 ]
  [0.4403509  0.55964917]
  [0.4272617  0.5727383 ]]

 [[0.42186567 0.57813436]
  [0.         0.        ]
  [0.4385395  0.5614605 ]
  [0.43095246 0.5690476 ]]

 [[0.40318796 0.596812  ]
  [0.40747324 0.5925268 ]
  [0.         0.        ]
  [0.4153267  0.5846733 ]]

 [[0.40175292 0.59824705]
  [0.40366378 0.59633625]
  [0.44243443 0.5575656 ]
  [0.         0.        ]]]

Rep 1,001.963:
[[[0.         0.        ]
  [0.59208256 0.40791747]
  [0.5650836  0.43491632]
  [0.48916388 0.5108361 ]]

 [[0.5241466  0.47585335]
  [0.         0.        ]
  [0.5812163  0.41878372]
  [0.5087657  0.49123427]]

 [[0.5187639  0.48123616]
  [0.5849184  0.41508165]
  [0.         0.        ]
  [0.49876457 0.5012354 ]]

 [[0.53456724 0.4654327 ]
  [0.5863121  0.4136879 ]
  [0.577657   0.42234305]
  [0.         0.        ]]]

Rep 1,001.334:
[[[0.         0.        ]
  [0.41749448 0.5825055 ]
  [0.37752733 0.6224727 ]
  [0.3665298  0.63347024]]

 [[0.49120113 0.50879884]
  [0.         0.        ]
  [0.39056367 0.60943633]
  [0.3760172  0.6239827 ]]

 [[0.48000184 0.5199982 ]
  [0.44318092 0.55681914]
  [0.         0.        ]
  [0.38823807 0.6117619 ]]

 [[0.49178952 0.5082105 ]
  [0.4505469  0.5494531 ]
  [0.41006377 0.58993626]
  [0.         0.        ]]]

Rep 1,001.282:
[[[0.         0.        ]
  [0.56693065 0.43306935]
  [0.58133674 0.41866323]
  [0.529669   0.47033107]]

 [[0.5422255  0.45777455]
  [0.         0.        ]
  [0.5837723  0.41622773]
  [0.52780896 0.47219107]]

 [[0.5379654  0.46203452]
  [0.56958234 0.43041772]
  [0.         0.        ]
  [0.5378024  0.46219763]]

 [[0.5511308  0.4488693 ]
  [0.57746375 0.42253628]
  [0.584951   0.41504905]
  [0.         0.        ]]]

Rep 1,001.340:
[[[0.         0.        ]
  [0.46414396 0.535856  ]
  [0.49084118 0.50915885]
  [0.47126582 0.5287342 ]]

 [[0.45762175 0.5423782 ]
  [0.         0.        ]
  [0.4856331  0.51436687]
  [0.4763966  0.52360344]]

 [[0.4414601  0.5585399 ]
  [0.45116943 0.5488305 ]
  [0.         0.        ]
  [0.4617831  0.5382169 ]]

 [[0.4443195  0.5556805 ]
  [0.4594339  0.5405661 ]
  [0.49011332 0.5098867 ]
  [0.         0.        ]]]

Rep 1,001.454:
[[[0.         0.        ]
  [0.51899165 0.48100838]
  [0.4568943  0.5431057 ]
  [0.42389965 0.5761004 ]]

 [[0.54646814 0.45353192]
  [0.         0.        ]
  [0.46407393 0.53592604]
  [0.42308867 0.57691133]]

 [[0.53948146 0.46051854]
  [0.51332104 0.48667896]
  [0.         0.        ]
  [0.4286179  0.5713821 ]]

 [[0.54706854 0.4529314 ]
  [0.5159426  0.48405746]
  [0.46619746 0.5338025 ]
  [0.         0.        ]]]

Rep 1,001.429:
[[[0.         0.        ]
  [0.46287286 0.53712714]
  [0.39256623 0.60743374]
  [0.37919283 0.6208071 ]]

 [[0.48711646 0.51288354]
  [0.         0.        ]
  [0.4005697  0.59943026]
  [0.36756378 0.6324362 ]]

 [[0.48706272 0.51293725]
  [0.4784976  0.5215024 ]
  [0.         0.        ]
  [0.36964902 0.63035095]]

 [[0.49218264 0.5078174 ]
  [0.49248657 0.50751346]
  [0.4185046  0.58149546]
  [0.         0.        ]]]

Rep 1,001.426:
[[[0.         0.        ]
  [0.44928068 0.5507194 ]
  [0.45884714 0.5411529 ]
  [0.44578275 0.5542173 ]]

 [[0.42747408 0.57252586]
  [0.         0.        ]
  [0.4502541  0.5497459 ]
  [0.44527614 0.5547239 ]]

 [[0.42262125 0.57737875]
  [0.42789412 0.5721059 ]
  [0.         0.        ]
  [0.43702626 0.56297374]]

 [[0.42616278 0.5738372 ]
  [0.4349623  0.5650377 ]
  [0.45544413 0.54455584]
  [0.         0.        ]]]

Rep 1,001.319:
[[[0.         0.        ]
  [0.4667072  0.5332928 ]
  [0.458086   0.5419139 ]
  [0.4196569  0.58034307]]

 [[0.4688448  0.5311552 ]
  [0.         0.        ]
  [0.47459576 0.5254043 ]
  [0.42636245 0.57363755]]

 [[0.4706504  0.5293496 ]
  [0.47433013 0.5256699 ]
  [0.         0.        ]
  [0.4147922  0.5852078 ]]

 [[0.4746672  0.5253328 ]
  [0.47571498 0.52428496]
  [0.49637386 0.5036261 ]
  [0.         0.        ]]]

Rep 1,001.333:
[[[0.         0.        ]
  [0.4384208  0.56157917]
  [0.4943221  0.50567794]
  [0.46158558 0.5384144 ]]

 [[0.4495263  0.5504737 ]
  [0.         0.        ]
  [0.4960787  0.5039213 ]
  [0.46992812 0.53007185]]

 [[0.43624473 0.56375533]
  [0.4381018  0.5618982 ]
  [0.         0.        ]
  [0.46125752 0.53874254]]

 [[0.44639573 0.55360425]
  [0.4492485  0.5507515 ]
  [0.5030938  0.49690625]
  [0.         0.        ]]]

Rep 1,001.144:
[[[0.         0.        ]
  [0.5975618  0.4024382 ]
  [0.5477224  0.4522776 ]
  [0.49443644 0.50556356]]

 [[0.6181713  0.38182876]
  [0.         0.        ]
  [0.5416478  0.4583522 ]
  [0.49396276 0.5060372 ]]

 [[0.6041599  0.39584005]
  [0.5921557  0.4078443 ]
  [0.         0.        ]
  [0.49125612 0.5087439 ]]

 [[0.6153095  0.3846905 ]
  [0.60108304 0.398917  ]
  [0.55760676 0.44239324]
  [0.         0.        ]]]

Rep 1,001.330:
[[[0.         0.        ]
  [0.41136009 0.58863986]
  [0.44345748 0.5565426 ]
  [0.4251376  0.57486236]]

 [[0.41343555 0.5865645 ]
  [0.         0.        ]
  [0.45162705 0.5483729 ]
  [0.42842367 0.57157636]]

 [[0.39743042 0.6025695 ]
  [0.404695   0.59530497]
  [0.         0.        ]
  [0.43616652 0.5638335 ]]

 [[0.41416824 0.58583176]
  [0.40928715 0.59071285]
  [0.4508543  0.5491457 ]
  [0.         0.        ]]]

Rep 1,001.328:
[[[0.         0.        ]
  [0.3966745  0.6033254 ]
  [0.4221024  0.5778976 ]
  [0.4358952  0.5641048 ]]

 [[0.39414328 0.60585666]
  [0.         0.        ]
  [0.42869258 0.57130736]
  [0.44379726 0.5562027 ]]

 [[0.370458   0.629542  ]
  [0.37372673 0.6262732 ]
  [0.         0.        ]
  [0.4400287  0.5599713 ]]

 [[0.3770486  0.6229514 ]
  [0.3805895  0.61941046]
  [0.42523503 0.5747649 ]
  [0.         0.        ]]]

Rep 1,001.254:
[[[0.         0.        ]
  [0.55197746 0.4480225 ]
  [0.55575347 0.4442466 ]
  [0.5082714  0.4917286 ]]

 [[0.5090534  0.4909466 ]
  [0.         0.        ]
  [0.572322   0.427678  ]
  [0.49442348 0.50557655]]

 [[0.50731057 0.49268943]
  [0.5474173  0.45258278]
  [0.         0.        ]
  [0.4943075  0.50569254]]

 [[0.5070487  0.4929513 ]
  [0.55360615 0.44639382]
  [0.57336223 0.42663774]
  [0.         0.        ]]]

Rep 1,001.297:
[[[0.         0.        ]
  [0.44974592 0.5502541 ]
  [0.4007743  0.59922564]
  [0.36716115 0.63283885]]

 [[0.49702105 0.502979  ]
  [0.         0.        ]
  [0.40072814 0.59927183]
  [0.36969793 0.6303021 ]]

 [[0.49800724 0.5019928 ]
  [0.45694155 0.54305845]
  [0.         0.        ]
  [0.37701234 0.6229877 ]]

 [[0.50666213 0.49333787]
  [0.4608491  0.5391509 ]
  [0.4077522  0.5922478 ]
  [0.         0.        ]]]

Rep 1,001.494:
[[[0.         0.        ]
  [0.50012946 0.49987054]
  [0.460617   0.539383  ]
  [0.42630702 0.57369304]]

 [[0.52486104 0.47513902]
  [0.         0.        ]
  [0.47188747 0.52811253]
  [0.43143886 0.56856114]]

 [[0.51375633 0.4862437 ]
  [0.49893004 0.50106996]
  [0.         0.        ]
  [0.44425124 0.5557488 ]]

 [[0.52291226 0.47708768]
  [0.5056939  0.4943061 ]
  [0.49346262 0.5065374 ]
  [0.         0.        ]]]

Rep 1,001.483:
[[[0.         0.        ]
  [0.39172596 0.60827404]
  [0.4127549  0.58724505]
  [0.40611106 0.59388894]]

 [[0.3930022  0.6069978 ]
  [0.         0.        ]
  [0.41134927 0.5886507 ]
  [0.398587   0.6014131 ]]

 [[0.38450515 0.61549485]
  [0.37553784 0.6244621 ]
  [0.         0.        ]
  [0.39263642 0.6073636 ]]

 [[0.37916976 0.62083024]
  [0.373908   0.62609196]
  [0.3967502  0.6032498 ]
  [0.         0.        ]]]

Rep 1,001.272:
[[[0.         0.        ]
  [0.46341518 0.5365848 ]
  [0.4308998  0.56910014]
  [0.40936053 0.5906395 ]]

 [[0.52090067 0.47909936]
  [0.         0.        ]
  [0.44155926 0.55844074]
  [0.41807958 0.58192044]]

 [[0.52078116 0.47921884]
  [0.47995153 0.52004844]
  [0.         0.        ]
  [0.40761313 0.59238684]]

 [[0.52296853 0.47703147]
  [0.47344112 0.5265589 ]
  [0.45945922 0.54054075]
  [0.         0.        ]]]

Rep 1,001.368:
[[[0.         0.        ]
  [0.42135364 0.5786463 ]
  [0.43479997 0.5652001 ]
  [0.43356326 0.56643677]]

 [[0.4100134  0.5899866 ]
  [0.         0.        ]
  [0.438476   0.561524  ]
  [0.43633217 0.5636679 ]]

 [[0.41267335 0.58732665]
  [0.43641782 0.5635822 ]
  [0.         0.        ]
  [0.43306056 0.5669395 ]]

 [[0.4184284  0.5815716 ]
  [0.4300466  0.5699534 ]
  [0.4605411  0.5394589 ]
  [0.         0.        ]]]

Rep 1,001.077:
[[[0.         0.        ]
  [0.5031937  0.49680635]
  [0.45283842 0.54716164]
  [0.42237452 0.5776255 ]]

 [[0.47149822 0.5285018 ]
  [0.         0.        ]
  [0.46001425 0.5399857 ]
  [0.42003158 0.5799684 ]]

 [[0.48648146 0.5135186 ]
  [0.50644994 0.4935501 ]
  [0.         0.        ]
  [0.4269774  0.57302266]]

 [[0.4853915  0.5146085 ]
  [0.51156056 0.48843944]
  [0.47988278 0.5201172 ]
  [0.         0.        ]]]

Rep 1,001.256:
[[[0.         0.        ]
  [0.4658511  0.5341489 ]
  [0.4509659  0.54903406]
  [0.41857716 0.5814228 ]]

 [[0.4527848  0.54721516]
  [0.         0.        ]
  [0.46214485 0.53785515]
  [0.42216656 0.5778334 ]]

 [[0.45722634 0.54277366]
  [0.4676334  0.5323666 ]
  [0.         0.        ]
  [0.42505333 0.5749467 ]]

 [[0.46452242 0.5354776 ]
  [0.47544345 0.5245566 ]
  [0.47427648 0.5257235 ]
  [0.         0.        ]]]

Test metrics and hyperparameters logged for tensorboard at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12\test

---------------------------------------------------------------------------

<<<<<<<<<<<< DECODER OUTPUT PLOT (TEST) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.217' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12...

Decoder output plot for rep '1001.2175' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12\test

Testing DataLoader 0: 100%|#########################################################| 10/10 [00:07<00:00,  1.34it/s]

        Test metric               DataLoader 0        

       dec/test_loss          0.017339803278446198    
  enc/test_edge_accuracy       0.4690000116825104     
     enc/test_entropy          0.6850595474243164     
       enc/test_loss           0.09705226123332977    
       nri/test_loss           0.11439205706119537    


===========================================================================

Nri model '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.12' training completed.


=== EXECUTION COMPLETED ===
Log saved at: 2025-09-17 12:09:13
