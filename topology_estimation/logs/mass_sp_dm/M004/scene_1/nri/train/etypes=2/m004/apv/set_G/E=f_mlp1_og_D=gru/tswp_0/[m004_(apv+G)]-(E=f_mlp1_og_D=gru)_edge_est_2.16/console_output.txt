=== SCRIPT EXECUTION LOG ===
Script: topology_estimation.train.py
Base Name: [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16
Start Time: 2025-09-18 17:58:20
End Time: 2025-09-18 18:21:54

CPU: Intel64 Family 6 Model 154 Stepping 3, GenuineIntel (Cores: 20), Max Frequency: 2300.00 MHz
GPUs Detected: 1
GPU 0: NVIDIA GeForce RTX 3050 Ti Laptop GPU, Memory: 4.00 GB
OS: Windows 11 (10.0.26100)

Python Version: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 12:58:53) [MSC v.1929 64 bit (AMD64)]
========================================================================================================================


Starting nri model training...

'Train' type dataset selected:


Dataset selections:
---------------------------------------------
*_(<ds_subtype_num>) <ds_subtype> : [<augments>]_*

- **Healthy configs**
  (1) series_tp    : [OG]

- **Unhealthy configs**

- **Unknown configs**


Node and signal types:
---------------------------------------------
*_(<node_num>) <node_type> : [<signal_types>]_*

  (1) mass_1   : [acc, pos, vel]
  (2) mass_2   : [acc, pos, vel]
  (3) mass_3   : [acc, pos, vel]
  (4) mass_4   : [acc, pos, vel]

Node group name: m004
Signal group name: apv


For ds_type 'OK' and others....
---------------------------------------------
Maximum timesteps across all node types: 500,001

No data interpolation applied.

'fs' is updated in data_config as given in loaded healthy (or unknown) data.
New fs:
[[500., 500., 500.],
 [500., 500., 500.],
 [500., 500., 500.],
 [500., 500., 500.]]

No exclusive rep numbers found in keys of hfd5 file. Hence, using default rep numbers.


[1 sample = (n_nodes, n_timesteps (window_length), n_dims)]
------------------------------------------------------------
Total samples: 5000 
Train: 4000/4000 [OK=4000, NOK=0, UK=0], Test: 500/500 [OK=500, NOK=0, UK=0], Val: 500/500 [OK=500, NOK=0, UK=0],
Remainder: 0 [OK=0, NOK=0, UK=0]

train_data_loader statistics:
Number of batches: 80
torch.Size([50, 4, 100, 3])  => (batch_size, n_nodes, n_timesteps, n_dims)

test_data_loader statistics:
Number of batches: 10
torch.Size([50, 4, 100, 3]) 

val_data_loader statistics:
Number of batches: 10
torch.Size([50, 4, 100, 3]) 

---------------------------------------------------------------------------

Loading Relation Matrices...

Relation Matrices loaded successfully.

## Relation Matrices Summary 

**Adjacency matrix for input** => shape: (4, 4)
     n1   n2   n3   n4
n1  0.0  1.0  1.0  1.0
n2  1.0  0.0  1.0  1.0
n3  1.0  1.0  0.0  1.0
n4  1.0  1.0  1.0  0.0


**Receiver relation matrix** => shape: (12, 4)
      n1   n2   n3   n4
e12  0.0  1.0  0.0  0.0
e13  0.0  0.0  1.0  0.0
e14  0.0  0.0  0.0  1.0
e21  1.0  0.0  0.0  0.0
e23  0.0  0.0  1.0  0.0
e24  0.0  0.0  0.0  1.0
e31  1.0  0.0  0.0  0.0
e32  0.0  1.0  0.0  0.0
e34  0.0  0.0  0.0  1.0
e41  1.0  0.0  0.0  0.0
e42  0.0  1.0  0.0  0.0
e43  0.0  0.0  1.0  0.0


**Sender relation matrix:** => shape: (12, 4)
      n1   n2   n3   n4
e12  1.0  0.0  0.0  0.0
e13  1.0  0.0  0.0  0.0
e14  1.0  0.0  0.0  0.0
e21  0.0  1.0  0.0  0.0
e23  0.0  1.0  0.0  0.0
e24  0.0  1.0  0.0  0.0
e31  0.0  0.0  1.0  0.0
e32  0.0  0.0  1.0  0.0
e34  0.0  0.0  1.0  0.0
e41  0.0  0.0  0.0  1.0
e42  0.0  0.0  0.0  1.0
e43  0.0  0.0  0.0  1.0


---------------------------------------------------------------------------

<<<<<< ENCODER PARAMETERS >>>>>>
Encoder model parameters:
-------------------------
n_edge_types: 2
is_residual_connection: False
do_prob: {'mlp': 0.0, 'cnn': 0.0}
is_batch_norm: {'mlp': True, 'cnn': False}
is_xavier_weights: True
attention_output_size: 5
domain_config: {'type': 'time', 'cutoff_freq': 0}
raw_data_norm: min_max
feat_configs: []
reduc_config: None
feat_norm: None
pipeline: [['1/node_emd.1', 'mlp'], ['1/pairwise_op', 'concat'], ['1/edge_emd.1.@', 'mlp'], ['2/aggregate', 'mean'], ['2/node_emd.1', 'mlp'], ['2/pairwise_op', 'concat'], ['2/edge_emd.1', 'mlp']]
edge_emb_configs: {'mlp': [[256, 'elu'], [256, 'elu']], 'cnn': [[5, 2, 64], [8]]}
node_emb_configs: {'mlp': [[256, 'elu'], [256, 'elu']], 'cnn': [[5, 2, 64], [8]]}
n_comps: 100
n_dims: 3

<<<<<< DECODER PARAMETERS >>>>>>

Decoder model parameters:
-------------------------
n_edge_types: 2
msg_out_size: 64
edge_mlp_config: [[64, 'tanh'], [64, 'tanh']]
out_mlp_config: [[64, 'relu'], [64, 'relu']]
do_prob: 0
is_batch_norm: False
is_xavier_weights: False
recur_emb_type: gru
domain_config: {'type': 'time', 'cutoff_freq': 0}
raw_data_norm: min_max
feat_configs: []
feat_norm: None
reduc_config: None
n_dims: 3

Decoder run parameters:
-------------------------
is_hard: False
skip_first_edge_type: True
pred_steps: 10
is_burn_in: True
final_pred_steps: 30
is_dynamic_graph: False
show_conf_band: False
Model parameters saved to C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16.

Training environment set. Training will be logged at: C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16

---------------------------------------------------------------------------

Training parameters set to: 
lr_enc=1.5e-05, 
lr_dec=0.001, 
final_beta=0.0, 
warmup_frac=0.8, 
optimizer=adam, 
loss_type_encoder=kld, 
loss_type_decoder=mse, 
prior=tensor([0.5000, 0.5000]), 
add_const_kld=True
is_enc_warmup: True, 
warmup_acc_cutoff: 0.85, 
sustain_enc_warmup: True, 
final_gamma: 0.3, 
warmup_frac_gamma: 0.6, 
dec_loss_stabilize_steps: 80, 
dec_loss_bound_update_interval: 5, 
dec_loss_window_size: 200


---------------------------------------------------------------------------

NRI Model Initialized with the following configurations:
----- NRI Model Summary -----
-- Encoder Summary
Encoder(
  (emb_fn_dict): ModuleDict(
    (1/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=300, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=256, out_features=256, bias=True)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
    (1/edge_emd1@): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=256, out_features=256, bias=True)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
    (2/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=256, out_features=256, bias=True)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
    (2/edge_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ELU(alpha=1.0)
        (3): Dropout(p=0.0, inplace=False)
        (4): Linear(in_features=256, out_features=256, bias=True)
        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): ELU(alpha=1.0)
      )
    )
  )
  (attention_layer_dict): ModuleDict()
  (output_layer): Linear(in_features=256, out_features=2, bias=True)
)
-- Decoder Summary
Decoder(
  (edge_mlp_fn): ModuleList(
    (0-1): 2 x MLP(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): Tanh()
        (2): Dropout(p=0, inplace=False)
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): Tanh()
      )
    )
  )
  (recurrent_emb_fn): GRU(
    (input_u): Linear(in_features=3, out_features=64, bias=True)
    (hidden_u): Linear(in_features=64, out_features=64, bias=True)
    (input_r): Linear(in_features=3, out_features=64, bias=True)
    (hidden_r): Linear(in_features=64, out_features=64, bias=True)
    (input_h): Linear(in_features=3, out_features=64, bias=True)
    (hidden_h): Linear(in_features=64, out_features=64, bias=True)
  )
  (mean_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
      (2): Dropout(p=0, inplace=False)
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): ReLU()
    )
  )
  (var_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
      (2): Dropout(p=0, inplace=False)
      (3): Linear(in_features=64, out_features=64, bias=True)
      (4): ReLU()
    )
  )
  (mean_output_layer): Linear(in_features=64, out_features=3, bias=True)
  (var_output_layer): Linear(in_features=64, out_features=3, bias=True)
)

---------------------------------------------------------------------------
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.

Initializing input processors for encoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Initializing input processors for decoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Step 0, Epoch 1/50, Batch 1/80
temp: 0.9990, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.6934, enc_train_loss: 2.0912, enc_train_entropy: 0.5189, dec_train_loss: 0.6934, train_edge_accuracy: 0.5017, 

Step 5, Epoch 1/50, Batch 6/80
temp: 0.9940, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0797, enc_train_loss: 2.1018, enc_train_entropy: 0.5180, dec_train_loss: 0.0797, train_edge_accuracy: 0.4967, 

Step 10, Epoch 1/50, Batch 11/80
temp: 0.9891, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0424, enc_train_loss: 2.3406, enc_train_entropy: 0.4981, dec_train_loss: 0.0424, train_edge_accuracy: 0.5067, 

Step 15, Epoch 1/50, Batch 16/80
temp: 0.9841, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0343, enc_train_loss: 2.7629, enc_train_entropy: 0.4629, dec_train_loss: 0.0343, train_edge_accuracy: 0.5100, 

Step 20, Epoch 1/50, Batch 21/80
temp: 0.9792, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0346, enc_train_loss: 2.9344, enc_train_entropy: 0.4486, dec_train_loss: 0.0346, train_edge_accuracy: 0.5033, 

Step 25, Epoch 1/50, Batch 26/80
temp: 0.9743, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0254, enc_train_loss: 2.9861, enc_train_entropy: 0.4443, dec_train_loss: 0.0254, train_edge_accuracy: 0.4917, 

Step 30, Epoch 1/50, Batch 31/80
temp: 0.9695, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0255, enc_train_loss: 3.0509, enc_train_entropy: 0.4389, dec_train_loss: 0.0255, train_edge_accuracy: 0.4917, 

Step 35, Epoch 1/50, Batch 36/80
temp: 0.9646, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0233, enc_train_loss: 2.8505, enc_train_entropy: 0.4556, dec_train_loss: 0.0233, train_edge_accuracy: 0.4983, 

Step 40, Epoch 1/50, Batch 41/80
temp: 0.9598, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0220, enc_train_loss: 3.0338, enc_train_entropy: 0.4403, dec_train_loss: 0.0220, train_edge_accuracy: 0.4933, 

Step 45, Epoch 1/50, Batch 46/80
temp: 0.9550, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0215, enc_train_loss: 2.9864, enc_train_entropy: 0.4443, dec_train_loss: 0.0215, train_edge_accuracy: 0.5033, 

Step 50, Epoch 1/50, Batch 51/80
temp: 0.9503, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 3.1225, enc_train_entropy: 0.4329, dec_train_loss: 0.0208, train_edge_accuracy: 0.4850, 

Step 55, Epoch 1/50, Batch 56/80
temp: 0.9455, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0208, enc_train_loss: 3.2255, enc_train_entropy: 0.4244, dec_train_loss: 0.0208, train_edge_accuracy: 0.5133, 

Step 60, Epoch 1/50, Batch 61/80
temp: 0.9408, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0202, enc_train_loss: 3.5550, enc_train_entropy: 0.3969, dec_train_loss: 0.0202, train_edge_accuracy: 0.5100, 

Step 65, Epoch 1/50, Batch 66/80
temp: 0.9361, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0200, enc_train_loss: 3.6337, enc_train_entropy: 0.3903, dec_train_loss: 0.0200, train_edge_accuracy: 0.4867, 

Step 70, Epoch 1/50, Batch 71/80
temp: 0.9314, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0201, enc_train_loss: 4.1713, enc_train_entropy: 0.3455, dec_train_loss: 0.0201, train_edge_accuracy: 0.4933, 

Step 75, Epoch 1/50, Batch 76/80
temp: 0.9268, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0195, enc_train_loss: 4.1832, enc_train_entropy: 0.3445, dec_train_loss: 0.0195, train_edge_accuracy: 0.5017, 

Epoch 1/50 completed, Global Step: 79
nri_train_loss: 0.0195, enc_train_loss: 4.1832, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.3445, dec_train_loss: 0.0195, train_edge_accuracy: 0.5017
nri_val_loss: 0.0194, enc_val_loss: 4.8278, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.2908, dec_val_loss: 0.0194, val_edge_accuracy: 0.4988

---------------------------------------------------------------------------


Step 80, Epoch 2/50, Batch 1/80
temp: 0.9130, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0194, enc_train_loss: 4.4533, enc_train_entropy: 0.3220, dec_train_loss: 0.0194, train_edge_accuracy: 0.5017, 

Step 85, Epoch 2/50, Batch 6/80
temp: 0.9084, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0191, enc_train_loss: 4.3049, enc_train_entropy: 0.3344, dec_train_loss: 0.0191, train_edge_accuracy: 0.5017, 

Step 90, Epoch 2/50, Batch 11/80
temp: 0.9039, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0189, enc_train_loss: 4.8659, enc_train_entropy: 0.2877, dec_train_loss: 0.0189, train_edge_accuracy: 0.5000, 

Step 95, Epoch 2/50, Batch 16/80
temp: 0.8994, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0187, enc_train_loss: 4.3602, enc_train_entropy: 0.3298, dec_train_loss: 0.0187, train_edge_accuracy: 0.4967, 

Step 100, Epoch 2/50, Batch 21/80
temp: 0.8949, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0184, enc_train_loss: 5.1706, enc_train_entropy: 0.2623, dec_train_loss: 0.0184, train_edge_accuracy: 0.4983, 

Step 105, Epoch 2/50, Batch 26/80
temp: 0.8904, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 4.8276, enc_train_entropy: 0.2908, dec_train_loss: 0.0182, train_edge_accuracy: 0.5000, 

Step 110, Epoch 2/50, Batch 31/80
temp: 0.8860, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 4.5940, enc_train_entropy: 0.3103, dec_train_loss: 0.0182, train_edge_accuracy: 0.5100, 

Step 115, Epoch 2/50, Batch 36/80
temp: 0.8816, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0182, enc_train_loss: 5.1630, enc_train_entropy: 0.2629, dec_train_loss: 0.0182, train_edge_accuracy: 0.5033, 

Step 120, Epoch 2/50, Batch 41/80
temp: 0.8772, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0177, enc_train_loss: 5.3222, enc_train_entropy: 0.2496, dec_train_loss: 0.0177, train_edge_accuracy: 0.5067, 

Step 125, Epoch 2/50, Batch 46/80
temp: 0.8728, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0178, enc_train_loss: 5.2825, enc_train_entropy: 0.2529, dec_train_loss: 0.0178, train_edge_accuracy: 0.5033, 

Step 130, Epoch 2/50, Batch 51/80
temp: 0.8684, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0176, enc_train_loss: 5.0030, enc_train_entropy: 0.2762, dec_train_loss: 0.0176, train_edge_accuracy: 0.5233, 

Step 135, Epoch 2/50, Batch 56/80
temp: 0.8641, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0175, enc_train_loss: 5.0428, enc_train_entropy: 0.2729, dec_train_loss: 0.0175, train_edge_accuracy: 0.5400, 

Step 140, Epoch 2/50, Batch 61/80
temp: 0.8598, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0173, enc_train_loss: 5.3289, enc_train_entropy: 0.2491, dec_train_loss: 0.0173, train_edge_accuracy: 0.5233, 

Step 145, Epoch 2/50, Batch 66/80
temp: 0.8555, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0171, enc_train_loss: 5.3903, enc_train_entropy: 0.2440, dec_train_loss: 0.0171, train_edge_accuracy: 0.5133, 

Step 150, Epoch 2/50, Batch 71/80
temp: 0.8512, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0171, enc_train_loss: 5.1002, enc_train_entropy: 0.2681, dec_train_loss: 0.0171, train_edge_accuracy: 0.4950, 

Step 155, Epoch 2/50, Batch 76/80
temp: 0.8470, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0170, enc_train_loss: 5.3711, enc_train_entropy: 0.2456, dec_train_loss: 0.0170, train_edge_accuracy: 0.4917, 

Epoch 2/50 completed, Global Step: 159
nri_train_loss: 0.0170, enc_train_loss: 5.3711, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.2456, dec_train_loss: 0.0170, train_edge_accuracy: 0.4917
nri_val_loss: 0.0168, enc_val_loss: 5.2843, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.2528, dec_val_loss: 0.0168, val_edge_accuracy: 0.5028

---------------------------------------------------------------------------


Step 160, Epoch 3/50, Batch 1/80
temp: 0.8344, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0170, enc_train_loss: 5.0949, enc_train_entropy: 0.2686, dec_train_loss: 0.0170, train_edge_accuracy: 0.5100, 

Step 165, Epoch 3/50, Batch 6/80
temp: 0.8302, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0166, enc_train_loss: 5.4618, enc_train_entropy: 0.2380, dec_train_loss: 0.0166, train_edge_accuracy: 0.5017, 

Step 170, Epoch 3/50, Batch 11/80
temp: 0.8261, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0167, enc_train_loss: 5.5498, enc_train_entropy: 0.2307, dec_train_loss: 0.0167, train_edge_accuracy: 0.5083, 

Step 175, Epoch 3/50, Batch 16/80
temp: 0.8219, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0166, enc_train_loss: 5.2062, enc_train_entropy: 0.2593, dec_train_loss: 0.0166, train_edge_accuracy: 0.4983, 
Step 180: Decoder stabilization counter: 1/80

Step 180, Epoch 3/50, Batch 21/80
temp: 0.8178, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0163, enc_train_loss: 5.5168, enc_train_entropy: 0.2334, dec_train_loss: 0.0163, train_edge_accuracy: 0.5067, 
Step 181: Decoder stabilization counter: 2/80
Step 182: Decoder stabilization counter: 3/80
Step 183: Decoder stabilization counter: 4/80
Step 184: Decoder stabilization counter: 5/80
Step 185: Decoder stabilization counter: 6/80

Step 185, Epoch 3/50, Batch 26/80
temp: 0.8137, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0161, enc_train_loss: 5.4520, enc_train_entropy: 0.2388, dec_train_loss: 0.0161, train_edge_accuracy: 0.5033, 
Step 186: Decoder stabilization counter: 7/80
Step 187: Decoder stabilization counter: 8/80
Step 188: Decoder stabilization counter: 9/80
Step 190: Decoder stabilization counter: 1/80

Step 190, Epoch 3/50, Batch 31/80
temp: 0.8097, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0160, enc_train_loss: 5.4494, enc_train_entropy: 0.2390, dec_train_loss: 0.0160, train_edge_accuracy: 0.5067, 
Step 191: Decoder stabilization counter: 2/80
Step 192: Decoder stabilization counter: 3/80
Step 194: Decoder stabilization counter: 1/80
Step 195: Decoder stabilization counter: 2/80

Step 195, Epoch 3/50, Batch 36/80
temp: 0.8056, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0159, enc_train_loss: 5.6821, enc_train_entropy: 0.2196, dec_train_loss: 0.0159, train_edge_accuracy: 0.4867, 
Step 200: Decoder stabilization counter: 1/80

Step 200, Epoch 3/50, Batch 41/80
temp: 0.8016, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0158, enc_train_loss: 5.2680, enc_train_entropy: 0.2541, dec_train_loss: 0.0158, train_edge_accuracy: 0.5083, 
Step 201: Decoder stabilization counter: 2/80
Step 202: Decoder stabilization counter: 3/80
Step 203: Decoder stabilization counter: 4/80
Step 205: Decoder stabilization counter: 1/80

Step 205, Epoch 3/50, Batch 46/80
temp: 0.7976, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0158, enc_train_loss: 5.5273, enc_train_entropy: 0.2325, dec_train_loss: 0.0158, train_edge_accuracy: 0.5033, 
Step 206: Decoder stabilization counter: 2/80
Step 207: Decoder stabilization counter: 3/80
Step 208: Decoder stabilization counter: 4/80
Step 209: Decoder stabilization counter: 5/80
Step 210: Decoder stabilization counter: 6/80

Step 210, Epoch 3/50, Batch 51/80
temp: 0.7936, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0157, enc_train_loss: 5.4258, enc_train_entropy: 0.2410, dec_train_loss: 0.0157, train_edge_accuracy: 0.5100, 
Step 211: Decoder stabilization counter: 7/80
Step 215: Decoder stabilization counter: 1/80

Step 215, Epoch 3/50, Batch 56/80
temp: 0.7897, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0157, enc_train_loss: 5.4130, enc_train_entropy: 0.2421, dec_train_loss: 0.0157, train_edge_accuracy: 0.5083, 
Step 216: Decoder stabilization counter: 2/80
Step 220: Decoder stabilization counter: 1/80

Step 220, Epoch 3/50, Batch 61/80
temp: 0.7857, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0154, enc_train_loss: 5.8092, enc_train_entropy: 0.2090, dec_train_loss: 0.0154, train_edge_accuracy: 0.4700, 
Step 224: Decoder stabilization counter: 1/80
Step 225: Decoder stabilization counter: 2/80

Step 225, Epoch 3/50, Batch 66/80
temp: 0.7818, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0153, enc_train_loss: 5.7212, enc_train_entropy: 0.2164, dec_train_loss: 0.0153, train_edge_accuracy: 0.5033, 
Step 226: Decoder stabilization counter: 3/80
Step 227: Decoder stabilization counter: 4/80
Step 229: Decoder stabilization counter: 1/80
Step 230: Decoder stabilization counter: 2/80

Step 230, Epoch 3/50, Batch 71/80
temp: 0.7779, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0151, enc_train_loss: 5.6849, enc_train_entropy: 0.2194, dec_train_loss: 0.0151, train_edge_accuracy: 0.5017, 
Step 232: Decoder stabilization counter: 1/80
Step 233: Decoder stabilization counter: 2/80
Step 234: Decoder stabilization counter: 3/80
Step 235: Decoder stabilization counter: 4/80

Step 235, Epoch 3/50, Batch 76/80
temp: 0.7740, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0150, enc_train_loss: 5.5853, enc_train_entropy: 0.2277, dec_train_loss: 0.0150, train_edge_accuracy: 0.5050, 
Step 236: Decoder stabilization counter: 5/80
Step 237: Decoder stabilization counter: 6/80
Step 238: Decoder stabilization counter: 7/80
Step 239: Decoder stabilization counter: 8/80
Step 239: Decoder stabilization counter: 1/80
Step 239: Decoder stabilization counter: 2/80
Step 239: Decoder stabilization counter: 1/80
Step 239: Decoder stabilization counter: 2/80
Step 239: Decoder stabilization counter: 1/80

Epoch 3/50 completed, Global Step: 239
nri_train_loss: 0.0150, enc_train_loss: 5.5853, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.2277, dec_train_loss: 0.0150, train_edge_accuracy: 0.5050
nri_val_loss: 0.0150, enc_val_loss: 5.8198, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.2082, dec_val_loss: 0.0150, val_edge_accuracy: 0.4897

---------------------------------------------------------------------------

Step 240: Decoder stabilization counter: 2/80

Step 240, Epoch 4/50, Batch 1/80
temp: 0.7625, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0150, enc_train_loss: 5.8821, enc_train_entropy: 0.2030, dec_train_loss: 0.0150, train_edge_accuracy: 0.4933, 
Step 241: Decoder stabilization counter: 3/80
Step 242: Decoder stabilization counter: 4/80
Step 244: Decoder stabilization counter: 1/80
Step 245: Decoder stabilization counter: 2/80

Step 245, Epoch 4/50, Batch 6/80
temp: 0.7587, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0148, enc_train_loss: 5.5733, enc_train_entropy: 0.2287, dec_train_loss: 0.0148, train_edge_accuracy: 0.4833, 
Step 246: Decoder stabilization counter: 3/80
Step 247: Decoder stabilization counter: 4/80
Step 248: Decoder stabilization counter: 5/80
Step 249: Decoder stabilization counter: 6/80
Step 250: Decoder stabilization counter: 7/80

Step 250, Epoch 4/50, Batch 11/80
temp: 0.7549, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0147, enc_train_loss: 6.1372, enc_train_entropy: 0.1817, dec_train_loss: 0.0147, train_edge_accuracy: 0.4817, 
Step 251: Decoder stabilization counter: 8/80
Step 252: Decoder stabilization counter: 9/80
Step 253: Decoder stabilization counter: 10/80
Step 254: Decoder stabilization counter: 11/80
Step 255: Decoder stabilization counter: 12/80

Step 255, Epoch 4/50, Batch 16/80
temp: 0.7512, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0149, enc_train_loss: 5.6434, enc_train_entropy: 0.2229, dec_train_loss: 0.0149, train_edge_accuracy: 0.4933, 
Step 256: Decoder stabilization counter: 13/80
Step 258: Decoder stabilization counter: 1/80
Step 259: Decoder stabilization counter: 2/80
Step 260: Decoder stabilization counter: 3/80

Step 260, Epoch 4/50, Batch 21/80
temp: 0.7474, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0149, enc_train_loss: 6.0149, enc_train_entropy: 0.1919, dec_train_loss: 0.0149, train_edge_accuracy: 0.4767, 
Step 265: Decoder stabilization counter: 1/80

Step 265, Epoch 4/50, Batch 26/80
temp: 0.7437, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0147, enc_train_loss: 5.8933, enc_train_entropy: 0.2020, dec_train_loss: 0.0147, train_edge_accuracy: 0.4817, 
Step 267: Decoder stabilization counter: 1/80
Step 269: Decoder stabilization counter: 1/80
Step 270: Decoder stabilization counter: 2/80

Step 270, Epoch 4/50, Batch 31/80
temp: 0.7400, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0145, enc_train_loss: 5.8154, enc_train_entropy: 0.2085, dec_train_loss: 0.0145, train_edge_accuracy: 0.5100, 
Step 271: Decoder stabilization counter: 3/80
Step 272: Decoder stabilization counter: 4/80
Step 273: Decoder stabilization counter: 5/80
Step 274: Decoder stabilization counter: 6/80
Step 275: Decoder stabilization counter: 7/80

Step 275, Epoch 4/50, Batch 36/80
temp: 0.7363, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0145, enc_train_loss: 6.1594, enc_train_entropy: 0.1799, dec_train_loss: 0.0145, train_edge_accuracy: 0.4817, 
Step 276: Decoder stabilization counter: 8/80
Step 277: Decoder stabilization counter: 9/80
Step 279: Decoder stabilization counter: 1/80
Step 280: Decoder stabilization counter: 2/80

Step 280, Epoch 4/50, Batch 41/80
temp: 0.7326, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0143, enc_train_loss: 6.2757, enc_train_entropy: 0.1702, dec_train_loss: 0.0143, train_edge_accuracy: 0.4833, 
Step 281: Decoder stabilization counter: 3/80
Step 282: Decoder stabilization counter: 4/80
Step 283: Decoder stabilization counter: 5/80
Step 284: Decoder stabilization counter: 6/80
Step 285: Decoder stabilization counter: 7/80

Step 285, Epoch 4/50, Batch 46/80
temp: 0.7289, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0143, enc_train_loss: 6.1273, enc_train_entropy: 0.1825, dec_train_loss: 0.0143, train_edge_accuracy: 0.4817, 
Step 286: Decoder stabilization counter: 8/80
Step 288: Decoder stabilization counter: 1/80
Step 290: Decoder stabilization counter: 1/80

Step 290, Epoch 4/50, Batch 51/80
temp: 0.7253, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0142, enc_train_loss: 6.3116, enc_train_entropy: 0.1672, dec_train_loss: 0.0142, train_edge_accuracy: 0.4867, 
Step 291: Decoder stabilization counter: 2/80
Step 292: Decoder stabilization counter: 3/80
Step 294: Decoder stabilization counter: 1/80
Step 295: Decoder stabilization counter: 2/80

Step 295, Epoch 4/50, Batch 56/80
temp: 0.7217, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0141, enc_train_loss: 6.2415, enc_train_entropy: 0.1730, dec_train_loss: 0.0141, train_edge_accuracy: 0.4817, 
Step 296: Decoder stabilization counter: 3/80
Step 297: Decoder stabilization counter: 4/80
Step 298: Decoder stabilization counter: 5/80
Step 299: Decoder stabilization counter: 6/80
Step 300: Decoder stabilization counter: 7/80

Step 300, Epoch 4/50, Batch 61/80
temp: 0.7181, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0140, enc_train_loss: 6.3578, enc_train_entropy: 0.1633, dec_train_loss: 0.0140, train_edge_accuracy: 0.4917, 
Step 301: Decoder stabilization counter: 8/80
Step 303: Decoder stabilization counter: 1/80
Step 305: Decoder stabilization counter: 1/80

Step 305, Epoch 4/50, Batch 66/80
temp: 0.7145, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0141, enc_train_loss: 6.3302, enc_train_entropy: 0.1656, dec_train_loss: 0.0141, train_edge_accuracy: 0.4883, 
Step 306: Decoder stabilization counter: 2/80
Step 307: Decoder stabilization counter: 3/80
Step 310: Decoder stabilization counter: 1/80

Step 310, Epoch 4/50, Batch 71/80
temp: 0.7109, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0140, enc_train_loss: 6.1138, enc_train_entropy: 0.1837, dec_train_loss: 0.0140, train_edge_accuracy: 0.4950, 
Step 311: Decoder stabilization counter: 2/80
Step 312: Decoder stabilization counter: 3/80
Step 314: Decoder stabilization counter: 1/80
Step 315: Decoder stabilization counter: 2/80

Step 315, Epoch 4/50, Batch 76/80
temp: 0.7074, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0139, enc_train_loss: 6.3785, enc_train_entropy: 0.1616, dec_train_loss: 0.0139, train_edge_accuracy: 0.4817, 
Step 316: Decoder stabilization counter: 3/80
Step 317: Decoder stabilization counter: 4/80
Step 319: Decoder stabilization counter: 1/80
Step 319: Decoder stabilization counter: 1/80
Step 319: Decoder stabilization counter: 2/80
Step 319: Decoder stabilization counter: 1/80
Step 319: Decoder stabilization counter: 1/80

Epoch 4/50 completed, Global Step: 319
nri_train_loss: 0.0139, enc_train_loss: 6.3785, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1616, dec_train_loss: 0.0139, train_edge_accuracy: 0.4817
nri_val_loss: 0.0137, enc_val_loss: 6.4786, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1533, dec_val_loss: 0.0137, val_edge_accuracy: 0.4835

---------------------------------------------------------------------------

Step 320: Decoder stabilization counter: 2/80

Step 320, Epoch 5/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0135, enc_train_loss: 6.4561, enc_train_entropy: 0.1551, dec_train_loss: 0.0135, train_edge_accuracy: 0.5083, 
Step 321: Decoder stabilization counter: 3/80
Step 322: Decoder stabilization counter: 4/80
Step 323: Decoder stabilization counter: 5/80
Step 324: Decoder stabilization counter: 6/80
Step 325: Decoder stabilization counter: 7/80

Step 325, Epoch 5/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0137, enc_train_loss: 6.6713, enc_train_entropy: 0.1372, dec_train_loss: 0.0137, train_edge_accuracy: 0.4933, 
Step 327: Decoder stabilization counter: 1/80
Step 329: Decoder stabilization counter: 1/80
Step 330: Decoder stabilization counter: 2/80

Step 330, Epoch 5/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0138, enc_train_loss: 6.4051, enc_train_entropy: 0.1594, dec_train_loss: 0.0138, train_edge_accuracy: 0.4933, 
Step 331: Decoder stabilization counter: 3/80
Step 332: Decoder stabilization counter: 4/80
Step 333: Decoder stabilization counter: 5/80
Step 335: Decoder stabilization counter: 1/80

Step 335, Epoch 5/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0133, enc_train_loss: 6.5214, enc_train_entropy: 0.1497, dec_train_loss: 0.0133, train_edge_accuracy: 0.4983, 
Step 337: Decoder stabilization counter: 1/80
Step 340: Decoder stabilization counter: 1/80

Step 340, Epoch 5/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0130, enc_train_loss: 6.2655, enc_train_entropy: 0.1710, dec_train_loss: 0.0130, train_edge_accuracy: 0.5017, 
Step 341: Decoder stabilization counter: 2/80
Step 342: Decoder stabilization counter: 3/80
Step 343: Decoder stabilization counter: 4/80
Step 345: Decoder stabilization counter: 1/80

Step 345, Epoch 5/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0129, enc_train_loss: 6.5118, enc_train_entropy: 0.1505, dec_train_loss: 0.0129, train_edge_accuracy: 0.4867, 
Step 346: Decoder stabilization counter: 2/80
Step 347: Decoder stabilization counter: 3/80
Step 349: Decoder stabilization counter: 1/80
Step 350: Decoder stabilization counter: 2/80

Step 350, Epoch 5/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0127, enc_train_loss: 6.3976, enc_train_entropy: 0.1600, dec_train_loss: 0.0127, train_edge_accuracy: 0.4917, 
Step 351: Decoder stabilization counter: 3/80
Step 352: Decoder stabilization counter: 4/80
Step 353: Decoder stabilization counter: 5/80
Step 355: Decoder stabilization counter: 1/80

Step 355, Epoch 5/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0123, enc_train_loss: 6.2267, enc_train_entropy: 0.1743, dec_train_loss: 0.0123, train_edge_accuracy: 0.4883, 
Step 356: Decoder stabilization counter: 2/80
Step 357: Decoder stabilization counter: 3/80
Step 358: Decoder stabilization counter: 4/80
Step 359: Decoder stabilization counter: 5/80
Step 360: Decoder stabilization counter: 6/80

Step 360, Epoch 5/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0123, enc_train_loss: 6.1904, enc_train_entropy: 0.1773, dec_train_loss: 0.0123, train_edge_accuracy: 0.5100, 
Step 365: Decoder stabilization counter: 1/80

Step 365, Epoch 5/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0122, enc_train_loss: 6.4282, enc_train_entropy: 0.1575, dec_train_loss: 0.0122, train_edge_accuracy: 0.5167, 
Step 366: Decoder stabilization counter: 2/80
Step 369: Decoder stabilization counter: 1/80
Step 370: Decoder stabilization counter: 2/80

Step 370, Epoch 5/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0115, enc_train_loss: 6.2293, enc_train_entropy: 0.1740, dec_train_loss: 0.0115, train_edge_accuracy: 0.5133, 
Step 371: Decoder stabilization counter: 3/80
Step 375: Decoder stabilization counter: 1/80

Step 375, Epoch 5/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0112, enc_train_loss: 6.3131, enc_train_entropy: 0.1671, dec_train_loss: 0.0112, train_edge_accuracy: 0.5000, 
Step 376: Decoder stabilization counter: 2/80
Step 380: Decoder stabilization counter: 1/80

Step 380, Epoch 5/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0108, enc_train_loss: 6.1665, enc_train_entropy: 0.1793, dec_train_loss: 0.0108, train_edge_accuracy: 0.4850, 
Step 385: Decoder stabilization counter: 1/80

Step 385, Epoch 5/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0107, enc_train_loss: 6.2012, enc_train_entropy: 0.1764, dec_train_loss: 0.0107, train_edge_accuracy: 0.4917, 
Step 390: Decoder stabilization counter: 1/80

Step 390, Epoch 5/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0094, enc_train_loss: 6.3370, enc_train_entropy: 0.1651, dec_train_loss: 0.0094, train_edge_accuracy: 0.4850, 
Step 391: Decoder stabilization counter: 2/80
Step 392: Decoder stabilization counter: 3/80
Step 394: Decoder stabilization counter: 1/80
Step 395: Decoder stabilization counter: 2/80

Step 395, Epoch 5/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0089, enc_train_loss: 6.3509, enc_train_entropy: 0.1639, dec_train_loss: 0.0089, train_edge_accuracy: 0.4733, 
Step 396: Decoder stabilization counter: 3/80

Epoch 5/50 completed, Global Step: 399
nri_train_loss: 0.0089, enc_train_loss: 6.3509, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1639, dec_train_loss: 0.0089, train_edge_accuracy: 0.4733
nri_val_loss: 0.0078, enc_val_loss: 6.2176, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1750, dec_val_loss: 0.0078, val_edge_accuracy: 0.4832

---------------------------------------------------------------------------

Step 400: Decoder stabilization counter: 1/80

Step 400, Epoch 6/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0081, enc_train_loss: 6.3184, enc_train_entropy: 0.1666, dec_train_loss: 0.0081, train_edge_accuracy: 0.4833, 
Step 401: Decoder stabilization counter: 2/80
Step 405: Decoder stabilization counter: 1/80

Step 405, Epoch 6/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0069, enc_train_loss: 6.2971, enc_train_entropy: 0.1684, dec_train_loss: 0.0069, train_edge_accuracy: 0.4667, 
Step 410: Decoder stabilization counter: 1/80

Step 410, Epoch 6/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0062, enc_train_loss: 6.3400, enc_train_entropy: 0.1648, dec_train_loss: 0.0062, train_edge_accuracy: 0.4700, 
Step 411: Decoder stabilization counter: 2/80
Step 412: Decoder stabilization counter: 3/80
Step 413: Decoder stabilization counter: 4/80
Step 415: Decoder stabilization counter: 1/80

Step 415, Epoch 6/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0061, enc_train_loss: 6.3630, enc_train_entropy: 0.1629, dec_train_loss: 0.0061, train_edge_accuracy: 0.4617, 
Step 420: Decoder stabilization counter: 1/80

Step 420, Epoch 6/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0054, enc_train_loss: 6.4856, enc_train_entropy: 0.1527, dec_train_loss: 0.0054, train_edge_accuracy: 0.4617, 
Step 421: Decoder stabilization counter: 2/80
Step 425: Decoder stabilization counter: 1/80

Step 425, Epoch 6/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0052, enc_train_loss: 6.4436, enc_train_entropy: 0.1562, dec_train_loss: 0.0052, train_edge_accuracy: 0.4583, 
Step 430: Decoder stabilization counter: 1/80

Step 430, Epoch 6/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0048, enc_train_loss: 6.4552, enc_train_entropy: 0.1552, dec_train_loss: 0.0048, train_edge_accuracy: 0.4533, 
Step 431: Decoder stabilization counter: 2/80
Step 432: Decoder stabilization counter: 3/80
Step 433: Decoder stabilization counter: 4/80
Step 435: Decoder stabilization counter: 1/80

Step 435, Epoch 6/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.4364, enc_train_entropy: 0.1568, dec_train_loss: 0.0049, train_edge_accuracy: 0.4550, 
Step 436: Decoder stabilization counter: 2/80
Step 437: Decoder stabilization counter: 3/80
Step 439: Decoder stabilization counter: 1/80
Step 440: Decoder stabilization counter: 2/80

Step 440, Epoch 6/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.4668, enc_train_entropy: 0.1543, dec_train_loss: 0.0049, train_edge_accuracy: 0.4767, 
Step 442: Decoder stabilization counter: 1/80
Step 443: Decoder stabilization counter: 2/80
Step 444: Decoder stabilization counter: 3/80
Step 445: Decoder stabilization counter: 4/80

Step 445, Epoch 6/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0048, enc_train_loss: 6.4098, enc_train_entropy: 0.1590, dec_train_loss: 0.0048, train_edge_accuracy: 0.4683, 
Step 446: Decoder stabilization counter: 5/80
Step 448: Decoder stabilization counter: 1/80
Step 449: Decoder stabilization counter: 2/80
Step 450: Decoder stabilization counter: 3/80

Step 450, Epoch 6/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0048, enc_train_loss: 6.2572, enc_train_entropy: 0.1717, dec_train_loss: 0.0048, train_edge_accuracy: 0.4733, 
Step 451: Decoder stabilization counter: 4/80
Step 452: Decoder stabilization counter: 5/80
Step 453: Decoder stabilization counter: 6/80
Step 454: Decoder stabilization counter: 7/80
Step 455: Decoder stabilization counter: 8/80

Step 455, Epoch 6/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0046, enc_train_loss: 6.6191, enc_train_entropy: 0.1416, dec_train_loss: 0.0046, train_edge_accuracy: 0.4600, 
Step 456: Decoder stabilization counter: 9/80
Step 457: Decoder stabilization counter: 10/80
Step 458: Decoder stabilization counter: 11/80
Step 459: Decoder stabilization counter: 12/80
Step 460: Decoder stabilization counter: 13/80

Step 460, Epoch 6/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0046, enc_train_loss: 6.5144, enc_train_entropy: 0.1503, dec_train_loss: 0.0046, train_edge_accuracy: 0.4833, 
Step 461: Decoder stabilization counter: 14/80
Step 462: Decoder stabilization counter: 15/80
Step 463: Decoder stabilization counter: 16/80
Step 465: Decoder stabilization counter: 1/80

Step 465, Epoch 6/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.6591, enc_train_entropy: 0.1382, dec_train_loss: 0.0044, train_edge_accuracy: 0.4667, 
Step 467: Decoder stabilization counter: 1/80
Step 468: Decoder stabilization counter: 2/80
Step 469: Decoder stabilization counter: 3/80
Step 470: Decoder stabilization counter: 4/80

Step 470, Epoch 6/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.5744, enc_train_entropy: 0.1453, dec_train_loss: 0.0045, train_edge_accuracy: 0.4633, 
Step 472: Decoder stabilization counter: 1/80
Step 473: Decoder stabilization counter: 2/80
Step 474: Decoder stabilization counter: 3/80
Step 475: Decoder stabilization counter: 4/80

Step 475, Epoch 6/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.4501, enc_train_entropy: 0.1556, dec_train_loss: 0.0044, train_edge_accuracy: 0.4950, 
Step 476: Decoder stabilization counter: 5/80
Step 477: Decoder stabilization counter: 6/80
Step 478: Decoder stabilization counter: 7/80
Step 479: Decoder stabilization counter: 1/80
Step 479: Decoder stabilization counter: 2/80
Step 479: Decoder stabilization counter: 3/80
Step 479: Decoder stabilization counter: 4/80
Step 479: Decoder stabilization counter: 5/80
Step 479: Decoder stabilization counter: 6/80
Step 479: Decoder stabilization counter: 7/80
Step 479: Decoder stabilization counter: 1/80

Epoch 6/50 completed, Global Step: 479
nri_train_loss: 0.0044, enc_train_loss: 6.4501, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1556, dec_train_loss: 0.0044, train_edge_accuracy: 0.4950
nri_val_loss: 0.0044, enc_val_loss: 6.5517, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1472, dec_val_loss: 0.0044, val_edge_accuracy: 0.4795

---------------------------------------------------------------------------

Step 480: Decoder stabilization counter: 2/80

Step 480, Epoch 7/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.6422, enc_train_entropy: 0.1396, dec_train_loss: 0.0044, train_edge_accuracy: 0.4500, 
Step 481: Decoder stabilization counter: 3/80
Step 482: Decoder stabilization counter: 4/80
Step 483: Decoder stabilization counter: 5/80
Step 484: Decoder stabilization counter: 6/80
Step 485: Decoder stabilization counter: 7/80

Step 485, Epoch 7/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.6751, enc_train_entropy: 0.1369, dec_train_loss: 0.0044, train_edge_accuracy: 0.4883, 
Step 486: Decoder stabilization counter: 8/80
Step 487: Decoder stabilization counter: 9/80
Step 489: Decoder stabilization counter: 1/80
Step 490: Decoder stabilization counter: 2/80

Step 490, Epoch 7/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.6699, enc_train_entropy: 0.1373, dec_train_loss: 0.0043, train_edge_accuracy: 0.4733, 
Step 491: Decoder stabilization counter: 3/80
Step 492: Decoder stabilization counter: 4/80
Step 493: Decoder stabilization counter: 5/80
Step 494: Decoder stabilization counter: 6/80
Step 495: Decoder stabilization counter: 7/80

Step 495, Epoch 7/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.6168, enc_train_entropy: 0.1418, dec_train_loss: 0.0043, train_edge_accuracy: 0.4750, 
Step 496: Decoder stabilization counter: 8/80
Step 497: Decoder stabilization counter: 9/80
Step 498: Decoder stabilization counter: 10/80
Step 499: Decoder stabilization counter: 11/80
Step 500: Decoder stabilization counter: 12/80

Step 500, Epoch 7/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.6270, enc_train_entropy: 0.1409, dec_train_loss: 0.0042, train_edge_accuracy: 0.4783, 
Step 501: Decoder stabilization counter: 13/80
Step 504: Decoder stabilization counter: 1/80
Step 505: Decoder stabilization counter: 2/80

Step 505, Epoch 7/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.6431, enc_train_entropy: 0.1396, dec_train_loss: 0.0045, train_edge_accuracy: 0.4800, 
Step 507: Decoder stabilization counter: 1/80
Step 508: Decoder stabilization counter: 2/80
Step 509: Decoder stabilization counter: 3/80
Step 510: Decoder stabilization counter: 4/80

Step 510, Epoch 7/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.6201, enc_train_entropy: 0.1415, dec_train_loss: 0.0043, train_edge_accuracy: 0.5017, 
Step 511: Decoder stabilization counter: 5/80
Step 512: Decoder stabilization counter: 6/80
Step 513: Decoder stabilization counter: 7/80
Step 514: Decoder stabilization counter: 8/80
Step 515: Decoder stabilization counter: 9/80

Step 515, Epoch 7/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.6962, enc_train_entropy: 0.1351, dec_train_loss: 0.0043, train_edge_accuracy: 0.4833, 
Step 516: Decoder stabilization counter: 10/80
Step 517: Decoder stabilization counter: 11/80
Step 518: Decoder stabilization counter: 12/80
Step 519: Decoder stabilization counter: 13/80
Step 520: Decoder stabilization counter: 14/80

Step 520, Epoch 7/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.7123, enc_train_entropy: 0.1338, dec_train_loss: 0.0042, train_edge_accuracy: 0.5050, 
Step 521: Decoder stabilization counter: 15/80
Step 523: Decoder stabilization counter: 1/80
Step 525: Decoder stabilization counter: 1/80

Step 525, Epoch 7/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.8445, enc_train_entropy: 0.1228, dec_train_loss: 0.0040, train_edge_accuracy: 0.4817, 
Step 526: Decoder stabilization counter: 2/80
Step 527: Decoder stabilization counter: 3/80
Step 528: Decoder stabilization counter: 4/80
Step 529: Decoder stabilization counter: 5/80
Step 530: Decoder stabilization counter: 6/80

Step 530, Epoch 7/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.8160, enc_train_entropy: 0.1252, dec_train_loss: 0.0041, train_edge_accuracy: 0.4800, 
Step 531: Decoder stabilization counter: 7/80
Step 533: Decoder stabilization counter: 1/80
Step 534: Decoder stabilization counter: 2/80
Step 535: Decoder stabilization counter: 3/80

Step 535, Epoch 7/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0046, enc_train_loss: 6.6033, enc_train_entropy: 0.1429, dec_train_loss: 0.0046, train_edge_accuracy: 0.4833, 
Step 536: Decoder stabilization counter: 4/80
Step 537: Decoder stabilization counter: 5/80
Step 538: Decoder stabilization counter: 6/80
Step 539: Decoder stabilization counter: 7/80
Step 540: Decoder stabilization counter: 8/80

Step 540, Epoch 7/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.7966, enc_train_entropy: 0.1268, dec_train_loss: 0.0040, train_edge_accuracy: 0.4733, 
Step 541: Decoder stabilization counter: 9/80
Step 544: Decoder stabilization counter: 1/80
Step 545: Decoder stabilization counter: 2/80

Step 545, Epoch 7/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.8771, enc_train_entropy: 0.1201, dec_train_loss: 0.0040, train_edge_accuracy: 0.4717, 
Step 546: Decoder stabilization counter: 3/80
Step 547: Decoder stabilization counter: 4/80
Step 548: Decoder stabilization counter: 5/80
Step 549: Decoder stabilization counter: 6/80
Step 550: Decoder stabilization counter: 7/80

Step 550, Epoch 7/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.6380, enc_train_entropy: 0.1400, dec_train_loss: 0.0041, train_edge_accuracy: 0.4900, 
Step 551: Decoder stabilization counter: 8/80
Step 552: Decoder stabilization counter: 9/80
Step 553: Decoder stabilization counter: 10/80
Step 554: Decoder stabilization counter: 11/80
Step 555: Decoder stabilization counter: 12/80

Step 555, Epoch 7/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.8133, enc_train_entropy: 0.1254, dec_train_loss: 0.0040, train_edge_accuracy: 0.4917, 
Step 556: Decoder stabilization counter: 13/80
Step 557: Decoder stabilization counter: 14/80
Step 559: Decoder stabilization counter: 1/80
Step 559: Decoder stabilization counter: 2/80
Step 559: Decoder stabilization counter: 3/80
Step 559: Decoder stabilization counter: 4/80
Step 559: Decoder stabilization counter: 5/80
Step 559: Decoder stabilization counter: 6/80
Step 559: Decoder stabilization counter: 7/80
Step 559: Decoder stabilization counter: 8/80
Step 559: Decoder stabilization counter: 9/80
Step 559: Decoder stabilization counter: 10/80
Step 559: Decoder stabilization counter: 11/80

Epoch 7/50 completed, Global Step: 559
nri_train_loss: 0.0040, enc_train_loss: 6.8133, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1254, dec_train_loss: 0.0040, train_edge_accuracy: 0.4917
nri_val_loss: 0.0042, enc_val_loss: 6.8154, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1252, dec_val_loss: 0.0042, val_edge_accuracy: 0.4847

---------------------------------------------------------------------------

Step 560: Decoder stabilization counter: 12/80

Step 560, Epoch 8/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.7953, enc_train_entropy: 0.1269, dec_train_loss: 0.0043, train_edge_accuracy: 0.4800, 
Step 561: Decoder stabilization counter: 13/80
Step 562: Decoder stabilization counter: 14/80
Step 563: Decoder stabilization counter: 15/80
Step 564: Decoder stabilization counter: 16/80
Step 565: Decoder stabilization counter: 17/80

Step 565, Epoch 8/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0037, enc_train_loss: 6.7499, enc_train_entropy: 0.1307, dec_train_loss: 0.0037, train_edge_accuracy: 0.4900, 
Step 566: Decoder stabilization counter: 18/80
Step 567: Decoder stabilization counter: 19/80
Step 569: Decoder stabilization counter: 1/80
Step 570: Decoder stabilization counter: 2/80

Step 570, Epoch 8/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.8936, enc_train_entropy: 0.1187, dec_train_loss: 0.0041, train_edge_accuracy: 0.4800, 
Step 571: Decoder stabilization counter: 3/80
Step 572: Decoder stabilization counter: 4/80
Step 573: Decoder stabilization counter: 5/80
Step 574: Decoder stabilization counter: 6/80
Step 575: Decoder stabilization counter: 7/80

Step 575, Epoch 8/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.8502, enc_train_entropy: 0.1223, dec_train_loss: 0.0041, train_edge_accuracy: 0.4683, 
Step 576: Decoder stabilization counter: 8/80
Step 577: Decoder stabilization counter: 9/80
Step 578: Decoder stabilization counter: 10/80
Step 579: Decoder stabilization counter: 11/80
Step 580: Decoder stabilization counter: 12/80

Step 580, Epoch 8/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.9393, enc_train_entropy: 0.1149, dec_train_loss: 0.0039, train_edge_accuracy: 0.4783, 
Step 581: Decoder stabilization counter: 13/80
Step 582: Decoder stabilization counter: 14/80
Step 583: Decoder stabilization counter: 15/80
Step 584: Decoder stabilization counter: 16/80
Step 585: Decoder stabilization counter: 17/80

Step 585, Epoch 8/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.6869, enc_train_entropy: 0.1359, dec_train_loss: 0.0039, train_edge_accuracy: 0.4833, 
Step 586: Decoder stabilization counter: 18/80
Step 587: Decoder stabilization counter: 19/80
Step 588: Decoder stabilization counter: 20/80
Step 589: Decoder stabilization counter: 21/80
Step 590: Decoder stabilization counter: 22/80

Step 590, Epoch 8/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.8634, enc_train_entropy: 0.1212, dec_train_loss: 0.0039, train_edge_accuracy: 0.4800, 
Step 591: Decoder stabilization counter: 23/80
Step 592: Decoder stabilization counter: 24/80
Step 593: Decoder stabilization counter: 25/80
Step 594: Decoder stabilization counter: 26/80
Step 595: Decoder stabilization counter: 27/80

Step 595, Epoch 8/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.8226, enc_train_entropy: 0.1246, dec_train_loss: 0.0045, train_edge_accuracy: 0.4733, 
Step 596: Decoder stabilization counter: 28/80
Step 597: Decoder stabilization counter: 29/80
Step 598: Decoder stabilization counter: 30/80
Step 599: Decoder stabilization counter: 31/80
Step 600: Decoder stabilization counter: 32/80

Step 600, Epoch 8/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.9188, enc_train_entropy: 0.1166, dec_train_loss: 0.0038, train_edge_accuracy: 0.4783, 
Step 601: Decoder stabilization counter: 33/80
Step 602: Decoder stabilization counter: 34/80
Step 603: Decoder stabilization counter: 35/80
Step 604: Decoder stabilization counter: 36/80
Step 605: Decoder stabilization counter: 37/80

Step 605, Epoch 8/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.7871, enc_train_entropy: 0.1276, dec_train_loss: 0.0039, train_edge_accuracy: 0.4783, 
Step 606: Decoder stabilization counter: 38/80
Step 607: Decoder stabilization counter: 39/80
Step 608: Decoder stabilization counter: 40/80
Step 609: Decoder stabilization counter: 41/80
Step 610: Decoder stabilization counter: 42/80

Step 610, Epoch 8/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.8485, enc_train_entropy: 0.1224, dec_train_loss: 0.0040, train_edge_accuracy: 0.4733, 
Step 611: Decoder stabilization counter: 43/80
Step 612: Decoder stabilization counter: 44/80
Step 613: Decoder stabilization counter: 45/80
Step 614: Decoder stabilization counter: 46/80
Step 615: Decoder stabilization counter: 47/80

Step 615, Epoch 8/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.7945, enc_train_entropy: 0.1269, dec_train_loss: 0.0041, train_edge_accuracy: 0.4800, 
Step 616: Decoder stabilization counter: 48/80
Step 617: Decoder stabilization counter: 49/80
Step 618: Decoder stabilization counter: 50/80
Step 619: Decoder stabilization counter: 51/80
Step 620: Decoder stabilization counter: 52/80

Step 620, Epoch 8/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.7985, enc_train_entropy: 0.1266, dec_train_loss: 0.0041, train_edge_accuracy: 0.4833, 
Step 621: Decoder stabilization counter: 53/80
Step 622: Decoder stabilization counter: 54/80
Step 623: Decoder stabilization counter: 55/80
Step 624: Decoder stabilization counter: 56/80
Step 625: Decoder stabilization counter: 57/80

Step 625, Epoch 8/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.8136, enc_train_entropy: 0.1254, dec_train_loss: 0.0039, train_edge_accuracy: 0.4850, 
Step 626: Decoder stabilization counter: 58/80
Step 628: Decoder stabilization counter: 1/80
Step 629: Decoder stabilization counter: 2/80
Step 630: Decoder stabilization counter: 3/80

Step 630, Epoch 8/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.7797, enc_train_entropy: 0.1282, dec_train_loss: 0.0038, train_edge_accuracy: 0.4883, 
Step 631: Decoder stabilization counter: 4/80
Step 632: Decoder stabilization counter: 5/80
Step 633: Decoder stabilization counter: 6/80
Step 635: Decoder stabilization counter: 1/80

Step 635, Epoch 8/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0036, enc_train_loss: 6.8069, enc_train_entropy: 0.1259, dec_train_loss: 0.0036, train_edge_accuracy: 0.4717, 
Step 636: Decoder stabilization counter: 2/80
Step 637: Decoder stabilization counter: 3/80
Step 638: Decoder stabilization counter: 4/80
Step 639: Decoder stabilization counter: 5/80
Step 639: Decoder stabilization counter: 6/80
Step 639: Decoder stabilization counter: 7/80
Step 639: Decoder stabilization counter: 8/80
Step 639: Decoder stabilization counter: 9/80
Step 639: Decoder stabilization counter: 10/80
Step 639: Decoder stabilization counter: 11/80
Step 639: Decoder stabilization counter: 12/80
Step 639: Decoder stabilization counter: 13/80
Step 639: Decoder stabilization counter: 14/80
Step 639: Decoder stabilization counter: 15/80

Epoch 8/50 completed, Global Step: 639
nri_train_loss: 0.0036, enc_train_loss: 6.8069, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1259, dec_train_loss: 0.0036, train_edge_accuracy: 0.4717
nri_val_loss: 0.0039, enc_val_loss: 6.8133, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1254, dec_val_loss: 0.0039, val_edge_accuracy: 0.4835

---------------------------------------------------------------------------

Step 640: Decoder stabilization counter: 16/80

Step 640, Epoch 9/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.7971, enc_train_entropy: 0.1267, dec_train_loss: 0.0041, train_edge_accuracy: 0.4783, 
Step 641: Decoder stabilization counter: 17/80
Step 642: Decoder stabilization counter: 18/80
Step 643: Decoder stabilization counter: 19/80
Step 644: Decoder stabilization counter: 20/80
Step 645: Decoder stabilization counter: 21/80

Step 645, Epoch 9/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.9215, enc_train_entropy: 0.1164, dec_train_loss: 0.0040, train_edge_accuracy: 0.4833, 
Step 646: Decoder stabilization counter: 22/80
Step 647: Decoder stabilization counter: 23/80
Step 648: Decoder stabilization counter: 24/80
Step 649: Decoder stabilization counter: 25/80
Step 650: Decoder stabilization counter: 26/80

Step 650, Epoch 9/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.9476, enc_train_entropy: 0.1142, dec_train_loss: 0.0039, train_edge_accuracy: 0.4717, 
Step 651: Decoder stabilization counter: 27/80
Step 652: Decoder stabilization counter: 28/80
Step 653: Decoder stabilization counter: 29/80
Step 654: Decoder stabilization counter: 30/80
Step 655: Decoder stabilization counter: 31/80

Step 655, Epoch 9/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.9750, enc_train_entropy: 0.1119, dec_train_loss: 0.0038, train_edge_accuracy: 0.4900, 
Step 656: Decoder stabilization counter: 32/80
Step 657: Decoder stabilization counter: 33/80
Step 658: Decoder stabilization counter: 34/80
Step 659: Decoder stabilization counter: 35/80
Step 660: Decoder stabilization counter: 36/80

Step 660, Epoch 9/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.8870, enc_train_entropy: 0.1192, dec_train_loss: 0.0040, train_edge_accuracy: 0.4667, 
Step 661: Decoder stabilization counter: 37/80
Step 662: Decoder stabilization counter: 38/80
Step 663: Decoder stabilization counter: 39/80
Step 664: Decoder stabilization counter: 40/80
Step 665: Decoder stabilization counter: 41/80

Step 665, Epoch 9/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.8555, enc_train_entropy: 0.1219, dec_train_loss: 0.0044, train_edge_accuracy: 0.4667, 
Step 666: Decoder stabilization counter: 42/80
Step 667: Decoder stabilization counter: 43/80
Step 668: Decoder stabilization counter: 44/80
Step 669: Decoder stabilization counter: 45/80
Step 670: Decoder stabilization counter: 46/80

Step 670, Epoch 9/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 7.0867, enc_train_entropy: 0.1026, dec_train_loss: 0.0039, train_edge_accuracy: 0.4783, 
Step 671: Decoder stabilization counter: 47/80
Step 672: Decoder stabilization counter: 48/80
Step 673: Decoder stabilization counter: 49/80
Step 674: Decoder stabilization counter: 50/80
Step 675: Decoder stabilization counter: 51/80

Step 675, Epoch 9/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 7.0462, enc_train_entropy: 0.1060, dec_train_loss: 0.0040, train_edge_accuracy: 0.4767, 
Step 676: Decoder stabilization counter: 52/80
Step 677: Decoder stabilization counter: 53/80
Step 678: Decoder stabilization counter: 54/80
Step 679: Decoder stabilization counter: 55/80
Step 680: Decoder stabilization counter: 56/80

Step 680, Epoch 9/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 7.1571, enc_train_entropy: 0.0967, dec_train_loss: 0.0038, train_edge_accuracy: 0.4617, 
Step 681: Decoder stabilization counter: 57/80
Step 682: Decoder stabilization counter: 58/80
Step 683: Decoder stabilization counter: 59/80
Step 684: Decoder stabilization counter: 60/80
Step 685: Decoder stabilization counter: 61/80

Step 685, Epoch 9/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.9829, enc_train_entropy: 0.1112, dec_train_loss: 0.0041, train_edge_accuracy: 0.4783, 
Step 686: Decoder stabilization counter: 62/80
Step 687: Decoder stabilization counter: 63/80
Step 688: Decoder stabilization counter: 64/80
Step 689: Decoder stabilization counter: 65/80
Step 690: Decoder stabilization counter: 66/80

Step 690, Epoch 9/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0037, enc_train_loss: 7.0726, enc_train_entropy: 0.1038, dec_train_loss: 0.0037, train_edge_accuracy: 0.4717, 
Step 691: Decoder stabilization counter: 67/80
Step 692: Decoder stabilization counter: 68/80
Step 693: Decoder stabilization counter: 69/80
Step 694: Decoder stabilization counter: 70/80
Step 695: Decoder stabilization counter: 71/80

Step 695, Epoch 9/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.9828, enc_train_entropy: 0.1112, dec_train_loss: 0.0038, train_edge_accuracy: 0.4800, 
Step 696: Decoder stabilization counter: 72/80
Step 697: Decoder stabilization counter: 73/80
Step 698: Decoder stabilization counter: 74/80
Step 699: Decoder stabilization counter: 75/80
Step 700: Decoder stabilization counter: 76/80

Step 700, Epoch 9/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 7.0310, enc_train_entropy: 0.1072, dec_train_loss: 0.0038, train_edge_accuracy: 0.4817, 
Step 701: Decoder stabilization counter: 77/80
Step 702: Decoder stabilization counter: 78/80
Step 703: Decoder stabilization counter: 79/80
Step 704: Decoder stabilization counter: 80/80

Decoder stabilized at step 704. Starting encoder warmup.


Step 705, Epoch 9/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0881, 
enc_train_warmup_loss: 0.8249, 
nri_train_loss: 0.0763, enc_train_loss: 6.9968, enc_train_entropy: 0.1101, dec_train_loss: 0.0036, train_edge_accuracy: 0.4700, 

Step 710, Epoch 9/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0887, 
enc_train_warmup_loss: 0.8126, 
nri_train_loss: 0.0759, enc_train_loss: 7.1632, enc_train_entropy: 0.0962, dec_train_loss: 0.0038, train_edge_accuracy: 0.4883, 

Step 715, Epoch 9/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0894, 
enc_train_warmup_loss: 0.7897, 
nri_train_loss: 0.0747, enc_train_loss: 7.0479, enc_train_entropy: 0.1058, dec_train_loss: 0.0041, train_edge_accuracy: 0.5167, 

Epoch 9/50 completed, Global Step: 719
nri_train_loss: 0.0747, enc_train_loss: 7.0479, enc_train_warmup_loss: 0.7897, enc_train_entropy: 0.1058, dec_train_loss: 0.0041, train_edge_accuracy: 0.5167
nri_val_loss: 0.0727, enc_val_loss: 6.9051, enc_val_warmup_loss: 0.7616, enc_val_entropy: 0.1177, dec_val_loss: 0.0043, val_edge_accuracy: 0.5368

---------------------------------------------------------------------------


Step 720, Epoch 10/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0900, 
enc_train_warmup_loss: 0.7617, 
nri_train_loss: 0.0727, enc_train_loss: 6.8318, enc_train_entropy: 0.1238, dec_train_loss: 0.0041, train_edge_accuracy: 0.5450, 

Step 725, Epoch 10/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0906, 
enc_train_warmup_loss: 0.7281, 
nri_train_loss: 0.0713, enc_train_loss: 6.5671, enc_train_entropy: 0.1459, dec_train_loss: 0.0053, train_edge_accuracy: 0.5800, 

Step 730, Epoch 10/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0912, 
enc_train_warmup_loss: 0.7120, 
nri_train_loss: 0.0700, enc_train_loss: 6.7006, enc_train_entropy: 0.1348, dec_train_loss: 0.0050, train_edge_accuracy: 0.5900, 

Step 735, Epoch 10/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0919, 
enc_train_warmup_loss: 0.6927, 
nri_train_loss: 0.0696, enc_train_loss: 6.7536, enc_train_entropy: 0.1304, dec_train_loss: 0.0060, train_edge_accuracy: 0.6183, 

Step 740, Epoch 10/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0925, 
enc_train_warmup_loss: 0.6723, 
nri_train_loss: 0.0696, enc_train_loss: 6.7195, enc_train_entropy: 0.1332, dec_train_loss: 0.0074, train_edge_accuracy: 0.6400, 

Step 745, Epoch 10/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0931, 
enc_train_warmup_loss: 0.6620, 
nri_train_loss: 0.0684, enc_train_loss: 6.7174, enc_train_entropy: 0.1334, dec_train_loss: 0.0067, train_edge_accuracy: 0.6550, 

Step 750, Epoch 10/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0938, 
enc_train_warmup_loss: 0.6381, 
nri_train_loss: 0.0681, enc_train_loss: 6.6320, enc_train_entropy: 0.1405, dec_train_loss: 0.0082, train_edge_accuracy: 0.6867, 

Step 755, Epoch 10/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0944, 
enc_train_warmup_loss: 0.6444, 
nri_train_loss: 0.0681, enc_train_loss: 6.7149, enc_train_entropy: 0.1336, dec_train_loss: 0.0073, train_edge_accuracy: 0.6733, 

Step 760, Epoch 10/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0950, 
enc_train_warmup_loss: 0.6212, 
nri_train_loss: 0.0681, enc_train_loss: 6.6477, enc_train_entropy: 0.1392, dec_train_loss: 0.0090, train_edge_accuracy: 0.6917, 

Step 765, Epoch 10/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0956, 
enc_train_warmup_loss: 0.6210, 
nri_train_loss: 0.0682, enc_train_loss: 6.5457, enc_train_entropy: 0.1477, dec_train_loss: 0.0089, train_edge_accuracy: 0.6900, 

Step 770, Epoch 10/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0963, 
enc_train_warmup_loss: 0.5931, 
nri_train_loss: 0.0669, enc_train_loss: 6.5312, enc_train_entropy: 0.1489, dec_train_loss: 0.0099, train_edge_accuracy: 0.7267, 

Step 775, Epoch 10/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0969, 
enc_train_warmup_loss: 0.5865, 
nri_train_loss: 0.0670, enc_train_loss: 6.7163, enc_train_entropy: 0.1335, dec_train_loss: 0.0101, train_edge_accuracy: 0.7383, 

Step 780, Epoch 10/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0975, 
enc_train_warmup_loss: 0.5781, 
nri_train_loss: 0.0671, enc_train_loss: 6.7408, enc_train_entropy: 0.1314, dec_train_loss: 0.0107, train_edge_accuracy: 0.7417, 

Step 785, Epoch 10/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0981, 
enc_train_warmup_loss: 0.5687, 
nri_train_loss: 0.0668, enc_train_loss: 6.7546, enc_train_entropy: 0.1303, dec_train_loss: 0.0110, train_edge_accuracy: 0.7500, 

Step 790, Epoch 10/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0987, 
enc_train_warmup_loss: 0.5679, 
nri_train_loss: 0.0665, enc_train_loss: 6.7377, enc_train_entropy: 0.1317, dec_train_loss: 0.0105, train_edge_accuracy: 0.7600, 

Step 795, Epoch 10/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0994, 
enc_train_warmup_loss: 0.5708, 
nri_train_loss: 0.0671, enc_train_loss: 6.6598, enc_train_entropy: 0.1382, dec_train_loss: 0.0103, train_edge_accuracy: 0.7500, 

Epoch 10/50 completed, Global Step: 799
nri_train_loss: 0.0671, enc_train_loss: 6.6598, enc_train_warmup_loss: 0.5708, enc_train_entropy: 0.1382, dec_train_loss: 0.0103, train_edge_accuracy: 0.7500
nri_val_loss: 0.0657, enc_val_loss: 6.5724, enc_val_warmup_loss: 0.5439, enc_val_entropy: 0.1454, dec_val_loss: 0.0114, val_edge_accuracy: 0.7803

---------------------------------------------------------------------------


Step 800, Epoch 11/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.1000, 
enc_train_warmup_loss: 0.5465, 
nri_train_loss: 0.0657, enc_train_loss: 6.8248, enc_train_entropy: 0.1244, dec_train_loss: 0.0110, train_edge_accuracy: 0.7750, 

Step 805, Epoch 11/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.1006, 
enc_train_warmup_loss: 0.5249, 
nri_train_loss: 0.0644, enc_train_loss: 6.6640, enc_train_entropy: 0.1378, dec_train_loss: 0.0116, train_edge_accuracy: 0.8033, 

Step 810, Epoch 11/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.1013, 
enc_train_warmup_loss: 0.5389, 
nri_train_loss: 0.0655, enc_train_loss: 6.5333, enc_train_entropy: 0.1487, dec_train_loss: 0.0110, train_edge_accuracy: 0.7733, 

Step 815, Epoch 11/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.1019, 
enc_train_warmup_loss: 0.5230, 
nri_train_loss: 0.0650, enc_train_loss: 6.3861, enc_train_entropy: 0.1610, dec_train_loss: 0.0117, train_edge_accuracy: 0.8033, 

Step 820, Epoch 11/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.1025, 
enc_train_warmup_loss: 0.4944, 
nri_train_loss: 0.0634, enc_train_loss: 6.1890, enc_train_entropy: 0.1774, dec_train_loss: 0.0127, train_edge_accuracy: 0.8250, 

Step 825, Epoch 11/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.1031, 
enc_train_warmup_loss: 0.4755, 
nri_train_loss: 0.0617, enc_train_loss: 5.8886, enc_train_entropy: 0.2024, dec_train_loss: 0.0127, train_edge_accuracy: 0.8417, 

Encoder warmup completed at step 826. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 830, Epoch 11/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0119, enc_train_loss: 5.8707, enc_train_entropy: 0.2039, dec_train_loss: 0.0119, train_edge_accuracy: 0.8583, 
Encoder warmup re-enabled at step 832 as edge accuracy dropped below cutoff 0.85.

Step 835, Epoch 11/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.1044, 
enc_train_warmup_loss: 0.4662, 
nri_train_loss: 0.0597, enc_train_loss: 5.8472, enc_train_entropy: 0.2059, dec_train_loss: 0.0110, train_edge_accuracy: 0.8500, 

Encoder warmup completed at step 837. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 840, Epoch 11/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0119, enc_train_loss: 5.8773, enc_train_entropy: 0.2034, dec_train_loss: 0.0119, train_edge_accuracy: 0.8617, 
Encoder warmup re-enabled at step 845 as edge accuracy dropped below cutoff 0.85.

Step 845, Epoch 11/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.1056, 
enc_train_warmup_loss: 0.4760, 
nri_train_loss: 0.0617, enc_train_loss: 5.9914, enc_train_entropy: 0.1939, dec_train_loss: 0.0114, train_edge_accuracy: 0.8383, 

Encoder warmup completed at step 848. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 850, Epoch 11/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0112, enc_train_loss: 5.8700, enc_train_entropy: 0.2040, dec_train_loss: 0.0112, train_edge_accuracy: 0.8650, 
Encoder warmup re-enabled at step 855 as edge accuracy dropped below cutoff 0.85.

Step 855, Epoch 11/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.1069, 
enc_train_warmup_loss: 0.4875, 
nri_train_loss: 0.0615, enc_train_loss: 5.7329, enc_train_entropy: 0.2154, dec_train_loss: 0.0094, train_edge_accuracy: 0.8267, 

Encoder warmup completed at step 858. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 860, Epoch 11/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0098, enc_train_loss: 5.7871, enc_train_entropy: 0.2109, dec_train_loss: 0.0098, train_edge_accuracy: 0.8550, 
Encoder warmup re-enabled at step 862 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 863. Warmup may re-enable if edge accuracy drops below cutoff 0.85.

Encoder warmup re-enabled at step 865 as edge accuracy dropped below cutoff 0.85.

Step 865, Epoch 11/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.1081, 
enc_train_warmup_loss: 0.4795, 
nri_train_loss: 0.0607, enc_train_loss: 5.6368, enc_train_entropy: 0.2234, dec_train_loss: 0.0089, train_edge_accuracy: 0.8450, 

Encoder warmup completed at step 866. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 870, Epoch 11/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0087, enc_train_loss: 5.5319, enc_train_entropy: 0.2322, dec_train_loss: 0.0087, train_edge_accuracy: 0.8517, 
Encoder warmup re-enabled at step 871 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 872. Warmup may re-enable if edge accuracy drops below cutoff 0.85.

Encoder warmup re-enabled at step 873 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 875. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 875, Epoch 11/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0087, enc_train_loss: 5.6383, enc_train_entropy: 0.2233, dec_train_loss: 0.0087, train_edge_accuracy: 0.8583, 
Encoder warmup re-enabled at step 877 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 878. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Epoch 11/50 completed, Global Step: 879
nri_train_loss: 0.0087, enc_train_loss: 5.6383, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.2233, dec_train_loss: 0.0087, train_edge_accuracy: 0.8583
nri_val_loss: 0.0085, enc_val_loss: 5.7571, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.2134, dec_val_loss: 0.0085, val_edge_accuracy: 0.8745

---------------------------------------------------------------------------


Step 880, Epoch 12/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0082, enc_train_loss: 5.7913, enc_train_entropy: 0.2105, dec_train_loss: 0.0082, train_edge_accuracy: 0.8717, 
Encoder warmup re-enabled at step 883 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 884. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 885, Epoch 12/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0070, enc_train_loss: 5.7365, enc_train_entropy: 0.2151, dec_train_loss: 0.0070, train_edge_accuracy: 0.8600, 
Encoder warmup re-enabled at step 890 as edge accuracy dropped below cutoff 0.85.

Step 890, Epoch 12/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.1113, 
enc_train_warmup_loss: 0.4809, 
nri_train_loss: 0.0704, enc_train_loss: 5.6884, enc_train_entropy: 0.2191, dec_train_loss: 0.0169, train_edge_accuracy: 0.8433, 

Encoder warmup completed at step 891. Warmup may re-enable if edge accuracy drops below cutoff 0.85.

Encoder warmup re-enabled at step 893 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 894. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 895, Epoch 12/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0088, enc_train_loss: 6.0366, enc_train_entropy: 0.1901, dec_train_loss: 0.0088, train_edge_accuracy: 0.8700, 
Encoder warmup re-enabled at step 897 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 898. Warmup may re-enable if edge accuracy drops below cutoff 0.85.

Encoder warmup re-enabled at step 899 as edge accuracy dropped below cutoff 0.85.

Step 900, Epoch 12/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.1125, 
enc_train_warmup_loss: 0.4768, 
nri_train_loss: 0.0626, enc_train_loss: 5.9026, enc_train_entropy: 0.2013, dec_train_loss: 0.0090, train_edge_accuracy: 0.8467, 

Encoder warmup completed at step 901. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 905, Epoch 12/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0083, enc_train_loss: 6.0253, enc_train_entropy: 0.1910, dec_train_loss: 0.0083, train_edge_accuracy: 0.8717, 
Encoder warmup re-enabled at step 910 as edge accuracy dropped below cutoff 0.85.

Step 910, Epoch 12/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.1137, 
enc_train_warmup_loss: 0.4679, 
nri_train_loss: 0.0603, enc_train_loss: 6.0469, enc_train_entropy: 0.1892, dec_train_loss: 0.0071, train_edge_accuracy: 0.8433, 

Encoder warmup completed at step 911. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 915, Epoch 12/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0074, enc_train_loss: 6.1500, enc_train_entropy: 0.1806, dec_train_loss: 0.0074, train_edge_accuracy: 0.8667, 

Step 920, Epoch 12/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0064, enc_train_loss: 6.1734, enc_train_entropy: 0.1787, dec_train_loss: 0.0064, train_edge_accuracy: 0.8533, 
Encoder warmup re-enabled at step 921 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 925. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 925, Epoch 12/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0060, enc_train_loss: 6.1869, enc_train_entropy: 0.1776, dec_train_loss: 0.0060, train_edge_accuracy: 0.8650, 

Step 930, Epoch 12/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0059, enc_train_loss: 6.2963, enc_train_entropy: 0.1685, dec_train_loss: 0.0059, train_edge_accuracy: 0.8833, 

Step 935, Epoch 12/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0052, enc_train_loss: 6.3453, enc_train_entropy: 0.1644, dec_train_loss: 0.0052, train_edge_accuracy: 0.8783, 

Step 940, Epoch 12/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0053, enc_train_loss: 6.3964, enc_train_entropy: 0.1601, dec_train_loss: 0.0053, train_edge_accuracy: 0.8683, 

Step 945, Epoch 12/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0052, enc_train_loss: 6.2893, enc_train_entropy: 0.1690, dec_train_loss: 0.0052, train_edge_accuracy: 0.8650, 
Encoder warmup re-enabled at step 949 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 950. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 950, Epoch 12/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.3824, enc_train_entropy: 0.1613, dec_train_loss: 0.0049, train_edge_accuracy: 0.8583, 

Step 955, Epoch 12/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0048, enc_train_loss: 6.4233, enc_train_entropy: 0.1579, dec_train_loss: 0.0048, train_edge_accuracy: 0.8617, 
Encoder warmup re-enabled at step 959 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 959. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Epoch 12/50 completed, Global Step: 959
nri_train_loss: 0.0048, enc_train_loss: 6.4233, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1579, dec_train_loss: 0.0048, train_edge_accuracy: 0.8617
nri_val_loss: 0.0110, enc_val_loss: 6.3859, enc_val_warmup_loss: 0.0480, enc_val_entropy: 0.1610, dec_val_loss: 0.0053, val_edge_accuracy: 0.8643

---------------------------------------------------------------------------


Step 960, Epoch 13/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.4748, enc_train_entropy: 0.1536, dec_train_loss: 0.0049, train_edge_accuracy: 0.8567, 
Encoder warmup re-enabled at step 965 as edge accuracy dropped below cutoff 0.85.

Step 965, Epoch 13/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.1206, 
enc_train_warmup_loss: 0.4742, 
nri_train_loss: 0.0625, enc_train_loss: 6.3205, enc_train_entropy: 0.1664, dec_train_loss: 0.0053, train_edge_accuracy: 0.8500, 

Encoder warmup completed at step 966. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 970, Epoch 13/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0050, enc_train_loss: 6.5040, enc_train_entropy: 0.1511, dec_train_loss: 0.0050, train_edge_accuracy: 0.8650, 
Encoder warmup re-enabled at step 974 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 975. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 975, Epoch 13/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0056, enc_train_loss: 6.3309, enc_train_entropy: 0.1656, dec_train_loss: 0.0056, train_edge_accuracy: 0.8517, 
Encoder warmup re-enabled at step 976 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 977. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 980, Epoch 13/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0062, enc_train_loss: 6.5365, enc_train_entropy: 0.1484, dec_train_loss: 0.0062, train_edge_accuracy: 0.8717, 

Step 985, Epoch 13/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0046, enc_train_loss: 6.5033, enc_train_entropy: 0.1512, dec_train_loss: 0.0046, train_edge_accuracy: 0.8750, 

Step 990, Epoch 13/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0050, enc_train_loss: 6.4675, enc_train_entropy: 0.1542, dec_train_loss: 0.0050, train_edge_accuracy: 0.8600, 

Step 995, Epoch 13/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0048, enc_train_loss: 6.5199, enc_train_entropy: 0.1498, dec_train_loss: 0.0048, train_edge_accuracy: 0.8667, 

Step 1000, Epoch 13/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.4108, enc_train_entropy: 0.1589, dec_train_loss: 0.0044, train_edge_accuracy: 0.8550, 
Encoder warmup re-enabled at step 1004 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1005. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 1005, Epoch 13/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.5584, enc_train_entropy: 0.1466, dec_train_loss: 0.0044, train_edge_accuracy: 0.8617, 

Step 1010, Epoch 13/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0047, enc_train_loss: 6.6004, enc_train_entropy: 0.1431, dec_train_loss: 0.0047, train_edge_accuracy: 0.8683, 

Step 1015, Epoch 13/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.5860, enc_train_entropy: 0.1443, dec_train_loss: 0.0045, train_edge_accuracy: 0.8583, 

Step 1020, Epoch 13/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0047, enc_train_loss: 6.5659, enc_train_entropy: 0.1460, dec_train_loss: 0.0047, train_edge_accuracy: 0.8683, 

Step 1025, Epoch 13/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.5775, enc_train_entropy: 0.1450, dec_train_loss: 0.0043, train_edge_accuracy: 0.8700, 

Step 1030, Epoch 13/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0046, enc_train_loss: 6.6028, enc_train_entropy: 0.1429, dec_train_loss: 0.0046, train_edge_accuracy: 0.8617, 
Encoder warmup re-enabled at step 1031 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1032. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 1035, Epoch 13/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.6268, enc_train_entropy: 0.1409, dec_train_loss: 0.0042, train_edge_accuracy: 0.8700, 

Epoch 13/50 completed, Global Step: 1039
nri_train_loss: 0.0042, enc_train_loss: 6.6268, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1409, dec_train_loss: 0.0042, train_edge_accuracy: 0.8700
nri_val_loss: 0.0046, enc_val_loss: 6.5542, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1470, dec_val_loss: 0.0046, val_edge_accuracy: 0.8720

---------------------------------------------------------------------------


Step 1040, Epoch 14/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.5816, enc_train_entropy: 0.1447, dec_train_loss: 0.0045, train_edge_accuracy: 0.8650, 

Step 1045, Epoch 14/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0056, enc_train_loss: 6.5328, enc_train_entropy: 0.1487, dec_train_loss: 0.0056, train_edge_accuracy: 0.8600, 
Encoder warmup re-enabled at step 1050 as edge accuracy dropped below cutoff 0.85.

Step 1050, Epoch 14/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.1313, 
enc_train_warmup_loss: 0.4766, 
nri_train_loss: 0.0677, enc_train_loss: 6.5280, enc_train_entropy: 0.1491, dec_train_loss: 0.0051, train_edge_accuracy: 0.8400, 

Encoder warmup completed at step 1051. Warmup may re-enable if edge accuracy drops below cutoff 0.85.

Encoder warmup re-enabled at step 1054 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1055. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 1055, Epoch 14/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0051, enc_train_loss: 6.4179, enc_train_entropy: 0.1583, dec_train_loss: 0.0051, train_edge_accuracy: 0.8550, 

Step 1060, Epoch 14/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0052, enc_train_loss: 6.5874, enc_train_entropy: 0.1442, dec_train_loss: 0.0052, train_edge_accuracy: 0.8750, 

Step 1065, Epoch 14/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.6594, enc_train_entropy: 0.1382, dec_train_loss: 0.0041, train_edge_accuracy: 0.8767, 

Step 1070, Epoch 14/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.5623, enc_train_entropy: 0.1463, dec_train_loss: 0.0045, train_edge_accuracy: 0.8617, 

Step 1075, Epoch 14/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.6694, enc_train_entropy: 0.1374, dec_train_loss: 0.0043, train_edge_accuracy: 0.8667, 

Step 1080, Epoch 14/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.5927, enc_train_entropy: 0.1438, dec_train_loss: 0.0043, train_edge_accuracy: 0.8783, 

Step 1085, Epoch 14/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0048, enc_train_loss: 6.5708, enc_train_entropy: 0.1456, dec_train_loss: 0.0048, train_edge_accuracy: 0.8683, 

Step 1090, Epoch 14/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.5972, enc_train_entropy: 0.1434, dec_train_loss: 0.0041, train_edge_accuracy: 0.8583, 
Encoder warmup re-enabled at step 1091 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1092. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 1095, Epoch 14/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.5292, enc_train_entropy: 0.1490, dec_train_loss: 0.0043, train_edge_accuracy: 0.8700, 

Step 1100, Epoch 14/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.5539, enc_train_entropy: 0.1470, dec_train_loss: 0.0040, train_edge_accuracy: 0.8833, 

Step 1105, Epoch 14/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.3917, enc_train_entropy: 0.1605, dec_train_loss: 0.0042, train_edge_accuracy: 0.8667, 
Encoder warmup re-enabled at step 1109 as edge accuracy dropped below cutoff 0.85.

Step 1110, Epoch 14/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.1388, 
enc_train_warmup_loss: 0.4707, 
nri_train_loss: 0.0704, enc_train_loss: 6.2983, enc_train_entropy: 0.1683, dec_train_loss: 0.0051, train_edge_accuracy: 0.8483, 

Encoder warmup completed at step 1111. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 1115, Epoch 14/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.4738, enc_train_entropy: 0.1537, dec_train_loss: 0.0049, train_edge_accuracy: 0.8667, 
Encoder warmup re-enabled at step 1119 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1119. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Epoch 14/50 completed, Global Step: 1119
nri_train_loss: 0.0049, enc_train_loss: 6.4738, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1537, dec_train_loss: 0.0049, train_edge_accuracy: 0.8667
nri_val_loss: 0.0110, enc_val_loss: 6.4565, enc_val_warmup_loss: 0.0474, enc_val_entropy: 0.1551, dec_val_loss: 0.0044, val_edge_accuracy: 0.8677

---------------------------------------------------------------------------


Step 1120, Epoch 15/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.5514, enc_train_entropy: 0.1472, dec_train_loss: 0.0042, train_edge_accuracy: 0.8583, 
Encoder warmup re-enabled at step 1123 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1124. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Step 1125, Epoch 15/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.5703, enc_train_entropy: 0.1456, dec_train_loss: 0.0041, train_edge_accuracy: 0.8683, 

Step 1130, Epoch 15/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0047, enc_train_loss: 6.7138, enc_train_entropy: 0.1337, dec_train_loss: 0.0047, train_edge_accuracy: 0.8717, 

Step 1135, Epoch 15/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.7320, enc_train_entropy: 0.1321, dec_train_loss: 0.0043, train_edge_accuracy: 0.8833, 

Step 1140, Epoch 15/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.6301, enc_train_entropy: 0.1406, dec_train_loss: 0.0041, train_edge_accuracy: 0.8617, 

Step 1145, Epoch 15/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0053, enc_train_loss: 6.7119, enc_train_entropy: 0.1338, dec_train_loss: 0.0053, train_edge_accuracy: 0.8667, 

Step 1150, Epoch 15/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0054, enc_train_loss: 6.6996, enc_train_entropy: 0.1348, dec_train_loss: 0.0054, train_edge_accuracy: 0.8667, 

Step 1155, Epoch 15/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0043, enc_train_loss: 6.6850, enc_train_entropy: 0.1361, dec_train_loss: 0.0043, train_edge_accuracy: 0.8783, 

Step 1160, Epoch 15/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.7578, enc_train_entropy: 0.1300, dec_train_loss: 0.0049, train_edge_accuracy: 0.8767, 

Step 1165, Epoch 15/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.7259, enc_train_entropy: 0.1327, dec_train_loss: 0.0038, train_edge_accuracy: 0.8733, 

Step 1170, Epoch 15/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.7843, enc_train_entropy: 0.1278, dec_train_loss: 0.0042, train_edge_accuracy: 0.8733, 

Step 1175, Epoch 15/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0041, enc_train_loss: 6.7226, enc_train_entropy: 0.1329, dec_train_loss: 0.0041, train_edge_accuracy: 0.8700, 

Step 1180, Epoch 15/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.7212, enc_train_entropy: 0.1330, dec_train_loss: 0.0042, train_edge_accuracy: 0.8650, 

Step 1185, Epoch 15/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0037, enc_train_loss: 6.7591, enc_train_entropy: 0.1299, dec_train_loss: 0.0037, train_edge_accuracy: 0.8600, 

Step 1190, Epoch 15/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0037, enc_train_loss: 6.8130, enc_train_entropy: 0.1254, dec_train_loss: 0.0037, train_edge_accuracy: 0.8783, 

Step 1195, Epoch 15/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.8888, enc_train_entropy: 0.1191, dec_train_loss: 0.0039, train_edge_accuracy: 0.8783, 
Encoder warmup re-enabled at step 1199 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1199. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Epoch 15/50 completed, Global Step: 1199
nri_train_loss: 0.0039, enc_train_loss: 6.8888, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1191, dec_train_loss: 0.0039, train_edge_accuracy: 0.8783
nri_val_loss: 0.0109, enc_val_loss: 6.8095, enc_val_warmup_loss: 0.0468, enc_val_entropy: 0.1257, dec_val_loss: 0.0039, val_edge_accuracy: 0.8725

---------------------------------------------------------------------------


Step 1200, Epoch 16/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.7722, enc_train_entropy: 0.1288, dec_train_loss: 0.0038, train_edge_accuracy: 0.8667, 

Step 1205, Epoch 16/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.8128, enc_train_entropy: 0.1254, dec_train_loss: 0.0039, train_edge_accuracy: 0.8683, 

Step 1210, Epoch 16/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.7351, enc_train_entropy: 0.1319, dec_train_loss: 0.0040, train_edge_accuracy: 0.8733, 

Step 1215, Epoch 16/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.8476, enc_train_entropy: 0.1225, dec_train_loss: 0.0038, train_edge_accuracy: 0.8617, 

Step 1220, Epoch 16/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.8069, enc_train_entropy: 0.1259, dec_train_loss: 0.0045, train_edge_accuracy: 0.8750, 

Step 1225, Epoch 16/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0035, enc_train_loss: 6.8327, enc_train_entropy: 0.1238, dec_train_loss: 0.0035, train_edge_accuracy: 0.8700, 

Step 1230, Epoch 16/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.5668, enc_train_entropy: 0.1459, dec_train_loss: 0.0038, train_edge_accuracy: 0.8683, 

Step 1235, Epoch 16/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0036, enc_train_loss: 6.7149, enc_train_entropy: 0.1336, dec_train_loss: 0.0036, train_edge_accuracy: 0.8700, 

Step 1240, Epoch 16/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0035, enc_train_loss: 6.7267, enc_train_entropy: 0.1326, dec_train_loss: 0.0035, train_edge_accuracy: 0.8750, 

Step 1245, Epoch 16/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0036, enc_train_loss: 6.7639, enc_train_entropy: 0.1295, dec_train_loss: 0.0036, train_edge_accuracy: 0.8683, 

Step 1250, Epoch 16/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0036, enc_train_loss: 6.7015, enc_train_entropy: 0.1347, dec_train_loss: 0.0036, train_edge_accuracy: 0.8650, 

Step 1255, Epoch 16/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0040, enc_train_loss: 6.6468, enc_train_entropy: 0.1392, dec_train_loss: 0.0040, train_edge_accuracy: 0.8600, 

Step 1260, Epoch 16/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0045, enc_train_loss: 6.7440, enc_train_entropy: 0.1311, dec_train_loss: 0.0045, train_edge_accuracy: 0.8650, 

Step 1265, Epoch 16/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.7461, enc_train_entropy: 0.1310, dec_train_loss: 0.0042, train_edge_accuracy: 0.8667, 

Step 1270, Epoch 16/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.7463, enc_train_entropy: 0.1310, dec_train_loss: 0.0038, train_edge_accuracy: 0.8800, 

Step 1275, Epoch 16/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.8130, enc_train_entropy: 0.1254, dec_train_loss: 0.0034, train_edge_accuracy: 0.8667, 
Encoder warmup re-enabled at step 1279 as edge accuracy dropped below cutoff 0.85.

Encoder warmup completed at step 1279. Warmup may re-enable if edge accuracy drops below cutoff 0.85.


Epoch 16/50 completed, Global Step: 1279
nri_train_loss: 0.0034, enc_train_loss: 6.8130, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1254, dec_train_loss: 0.0034, train_edge_accuracy: 0.8667
nri_val_loss: 0.0111, enc_val_loss: 6.7828, enc_val_warmup_loss: 0.0469, enc_val_entropy: 0.1279, dec_val_loss: 0.0036, val_edge_accuracy: 0.8720

---------------------------------------------------------------------------


Step 1280, Epoch 17/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.7541, enc_train_entropy: 0.1303, dec_train_loss: 0.0034, train_edge_accuracy: 0.8667, 

Step 1285, Epoch 17/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0036, enc_train_loss: 6.8617, enc_train_entropy: 0.1213, dec_train_loss: 0.0036, train_edge_accuracy: 0.8717, 

Step 1290, Epoch 17/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0051, enc_train_loss: 6.7314, enc_train_entropy: 0.1322, dec_train_loss: 0.0051, train_edge_accuracy: 0.8733, 

Step 1295, Epoch 17/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0037, enc_train_loss: 6.7467, enc_train_entropy: 0.1309, dec_train_loss: 0.0037, train_edge_accuracy: 0.8767, 

Step 1300, Epoch 17/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0044, enc_train_loss: 6.8474, enc_train_entropy: 0.1225, dec_train_loss: 0.0044, train_edge_accuracy: 0.8867, 

Step 1305, Epoch 17/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0039, enc_train_loss: 6.7667, enc_train_entropy: 0.1293, dec_train_loss: 0.0039, train_edge_accuracy: 0.8817, 

Step 1310, Epoch 17/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.8121, enc_train_entropy: 0.1255, dec_train_loss: 0.0034, train_edge_accuracy: 0.8817, 

Step 1315, Epoch 17/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0035, enc_train_loss: 6.7295, enc_train_entropy: 0.1324, dec_train_loss: 0.0035, train_edge_accuracy: 0.8817, 

Step 1320, Epoch 17/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.8745, enc_train_entropy: 0.1203, dec_train_loss: 0.0034, train_edge_accuracy: 0.8717, 

Step 1325, Epoch 17/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0033, enc_train_loss: 6.6959, enc_train_entropy: 0.1352, dec_train_loss: 0.0033, train_edge_accuracy: 0.8750, 

Step 1330, Epoch 17/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.7783, enc_train_entropy: 0.1283, dec_train_loss: 0.0034, train_edge_accuracy: 0.8867, 

Step 1335, Epoch 17/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.8300, enc_train_entropy: 0.1240, dec_train_loss: 0.0034, train_edge_accuracy: 0.8883, 

Step 1340, Epoch 17/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0033, enc_train_loss: 6.7993, enc_train_entropy: 0.1265, dec_train_loss: 0.0033, train_edge_accuracy: 0.8850, 

Step 1345, Epoch 17/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.7247, enc_train_entropy: 0.1328, dec_train_loss: 0.0034, train_edge_accuracy: 0.8767, 

Step 1350, Epoch 17/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0037, enc_train_loss: 6.7776, enc_train_entropy: 0.1283, dec_train_loss: 0.0037, train_edge_accuracy: 0.8833, 

Step 1355, Epoch 17/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0042, enc_train_loss: 6.6301, enc_train_entropy: 0.1406, dec_train_loss: 0.0042, train_edge_accuracy: 0.8733, 

Epoch 17/50 completed, Global Step: 1359
nri_train_loss: 0.0042, enc_train_loss: 6.6301, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1406, dec_train_loss: 0.0042, train_edge_accuracy: 0.8733
nri_val_loss: 0.0032, enc_val_loss: 6.7851, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1277, dec_val_loss: 0.0032, val_edge_accuracy: 0.8880

---------------------------------------------------------------------------


Step 1360, Epoch 18/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0031, enc_train_loss: 6.7621, enc_train_entropy: 0.1296, dec_train_loss: 0.0031, train_edge_accuracy: 0.8850, 

Step 1365, Epoch 18/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0030, enc_train_loss: 6.7804, enc_train_entropy: 0.1281, dec_train_loss: 0.0030, train_edge_accuracy: 0.8933, 

Step 1370, Epoch 18/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0031, enc_train_loss: 6.8690, enc_train_entropy: 0.1207, dec_train_loss: 0.0031, train_edge_accuracy: 0.8883, 

Step 1375, Epoch 18/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0030, enc_train_loss: 6.8041, enc_train_entropy: 0.1261, dec_train_loss: 0.0030, train_edge_accuracy: 0.8900, 

Step 1380, Epoch 18/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0049, enc_train_loss: 6.8094, enc_train_entropy: 0.1257, dec_train_loss: 0.0049, train_edge_accuracy: 0.8950, 

Step 1385, Epoch 18/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0032, enc_train_loss: 6.8349, enc_train_entropy: 0.1236, dec_train_loss: 0.0032, train_edge_accuracy: 0.8833, 

Step 1390, Epoch 18/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0034, enc_train_loss: 6.8752, enc_train_entropy: 0.1202, dec_train_loss: 0.0034, train_edge_accuracy: 0.8933, 

Step 1395, Epoch 18/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0036, enc_train_loss: 6.8913, enc_train_entropy: 0.1189, dec_train_loss: 0.0036, train_edge_accuracy: 0.8883, 

Step 1400, Epoch 18/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0032, enc_train_loss: 6.7831, enc_train_entropy: 0.1279, dec_train_loss: 0.0032, train_edge_accuracy: 0.8883, 

Step 1405, Epoch 18/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0030, enc_train_loss: 6.8137, enc_train_entropy: 0.1253, dec_train_loss: 0.0030, train_edge_accuracy: 0.8967, 

Step 1410, Epoch 18/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0031, enc_train_loss: 6.8054, enc_train_entropy: 0.1260, dec_train_loss: 0.0031, train_edge_accuracy: 0.8967, 

Step 1415, Epoch 18/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0024, enc_train_loss: 6.8836, enc_train_entropy: 0.1195, dec_train_loss: 0.0024, train_edge_accuracy: 0.8900, 

Step 1420, Epoch 18/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0026, enc_train_loss: 6.7745, enc_train_entropy: 0.1286, dec_train_loss: 0.0026, train_edge_accuracy: 0.8967, 

Step 1425, Epoch 18/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0027, enc_train_loss: 6.9007, enc_train_entropy: 0.1181, dec_train_loss: 0.0027, train_edge_accuracy: 0.8950, 

Step 1430, Epoch 18/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0024, enc_train_loss: 6.9173, enc_train_entropy: 0.1167, dec_train_loss: 0.0024, train_edge_accuracy: 0.9000, 

Step 1435, Epoch 18/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0027, enc_train_loss: 6.8431, enc_train_entropy: 0.1229, dec_train_loss: 0.0027, train_edge_accuracy: 0.9067, 

Epoch 18/50 completed, Global Step: 1439
nri_train_loss: 0.0027, enc_train_loss: 6.8431, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1229, dec_train_loss: 0.0027, train_edge_accuracy: 0.9067
nri_val_loss: 0.0031, enc_val_loss: 6.9143, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.1170, dec_val_loss: 0.0031, val_edge_accuracy: 0.9010

---------------------------------------------------------------------------


Step 1440, Epoch 19/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0028, enc_train_loss: 6.9634, enc_train_entropy: 0.1129, dec_train_loss: 0.0028, train_edge_accuracy: 0.8983, 

Step 1445, Epoch 19/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0035, enc_train_loss: 6.8930, enc_train_entropy: 0.1187, dec_train_loss: 0.0035, train_edge_accuracy: 0.9000, 

Step 1450, Epoch 19/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0025, enc_train_loss: 6.8973, enc_train_entropy: 0.1184, dec_train_loss: 0.0025, train_edge_accuracy: 0.9017, 

Step 1455, Epoch 19/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0038, enc_train_loss: 6.9361, enc_train_entropy: 0.1151, dec_train_loss: 0.0038, train_edge_accuracy: 0.9100, 

Step 1460, Epoch 19/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0028, enc_train_loss: 6.9346, enc_train_entropy: 0.1153, dec_train_loss: 0.0028, train_edge_accuracy: 0.9000, 

Step 1465, Epoch 19/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0024, enc_train_loss: 6.9480, enc_train_entropy: 0.1141, dec_train_loss: 0.0024, train_edge_accuracy: 0.9050, 

Step 1470, Epoch 19/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0028, enc_train_loss: 6.8805, enc_train_entropy: 0.1198, dec_train_loss: 0.0028, train_edge_accuracy: 0.8983, 

Step 1475, Epoch 19/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0023, enc_train_loss: 6.9440, enc_train_entropy: 0.1145, dec_train_loss: 0.0023, train_edge_accuracy: 0.8983, 

Step 1480, Epoch 19/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0027, enc_train_loss: 6.9403, enc_train_entropy: 0.1148, dec_train_loss: 0.0027, train_edge_accuracy: 0.9050, 

Step 1485, Epoch 19/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0020, enc_train_loss: 6.9438, enc_train_entropy: 0.1145, dec_train_loss: 0.0020, train_edge_accuracy: 0.9100, 

Step 1490, Epoch 19/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0021, enc_train_loss: 6.9952, enc_train_entropy: 0.1102, dec_train_loss: 0.0021, train_edge_accuracy: 0.9100, 

Step 1495, Epoch 19/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0020, enc_train_loss: 6.9934, enc_train_entropy: 0.1104, dec_train_loss: 0.0020, train_edge_accuracy: 0.9083, 

Step 1500, Epoch 19/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0021, enc_train_loss: 7.0662, enc_train_entropy: 0.1043, dec_train_loss: 0.0021, train_edge_accuracy: 0.9067, 

Step 1505, Epoch 19/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0028, enc_train_loss: 6.9539, enc_train_entropy: 0.1137, dec_train_loss: 0.0028, train_edge_accuracy: 0.9083, 

Step 1510, Epoch 19/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0020, enc_train_loss: 6.9808, enc_train_entropy: 0.1114, dec_train_loss: 0.0020, train_edge_accuracy: 0.9033, 

Step 1515, Epoch 19/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0022, enc_train_loss: 7.1124, enc_train_entropy: 0.1005, dec_train_loss: 0.0022, train_edge_accuracy: 0.9117, 

Epoch 19/50 completed, Global Step: 1519
nri_train_loss: 0.0022, enc_train_loss: 7.1124, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.1005, dec_train_loss: 0.0022, train_edge_accuracy: 0.9117
nri_val_loss: 0.0019, enc_val_loss: 7.1279, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0992, dec_val_loss: 0.0019, val_edge_accuracy: 0.9113

---------------------------------------------------------------------------


Step 1520, Epoch 20/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0021, enc_train_loss: 7.0888, enc_train_entropy: 0.1024, dec_train_loss: 0.0021, train_edge_accuracy: 0.9083, 

Step 1525, Epoch 20/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0021, enc_train_loss: 7.0461, enc_train_entropy: 0.1060, dec_train_loss: 0.0021, train_edge_accuracy: 0.9067, 

Step 1530, Epoch 20/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0020, enc_train_loss: 7.1211, enc_train_entropy: 0.0997, dec_train_loss: 0.0020, train_edge_accuracy: 0.9100, 

Step 1535, Epoch 20/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0021, enc_train_loss: 7.1034, enc_train_entropy: 0.1012, dec_train_loss: 0.0021, train_edge_accuracy: 0.9083, 

Step 1540, Epoch 20/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0017, enc_train_loss: 7.1893, enc_train_entropy: 0.0940, dec_train_loss: 0.0017, train_edge_accuracy: 0.9083, 

Step 1545, Epoch 20/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.1499, enc_train_entropy: 0.0973, dec_train_loss: 0.0016, train_edge_accuracy: 0.9067, 

Step 1550, Epoch 20/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0018, enc_train_loss: 7.0510, enc_train_entropy: 0.1056, dec_train_loss: 0.0018, train_edge_accuracy: 0.9117, 

Step 1555, Epoch 20/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0018, enc_train_loss: 7.0441, enc_train_entropy: 0.1061, dec_train_loss: 0.0018, train_edge_accuracy: 0.9117, 

Step 1560, Epoch 20/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0017, enc_train_loss: 6.9744, enc_train_entropy: 0.1119, dec_train_loss: 0.0017, train_edge_accuracy: 0.9083, 

Step 1565, Epoch 20/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0018, enc_train_loss: 7.1915, enc_train_entropy: 0.0939, dec_train_loss: 0.0018, train_edge_accuracy: 0.9067, 

Step 1570, Epoch 20/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.0130, enc_train_entropy: 0.1087, dec_train_loss: 0.0016, train_edge_accuracy: 0.9133, 

Step 1575, Epoch 20/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0017, enc_train_loss: 7.2811, enc_train_entropy: 0.0864, dec_train_loss: 0.0017, train_edge_accuracy: 0.9100, 

Step 1580, Epoch 20/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0015, enc_train_loss: 7.2531, enc_train_entropy: 0.0887, dec_train_loss: 0.0015, train_edge_accuracy: 0.9167, 

Step 1585, Epoch 20/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0019, enc_train_loss: 7.2353, enc_train_entropy: 0.0902, dec_train_loss: 0.0019, train_edge_accuracy: 0.9083, 

Step 1590, Epoch 20/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0023, enc_train_loss: 7.1626, enc_train_entropy: 0.0963, dec_train_loss: 0.0023, train_edge_accuracy: 0.9150, 

Step 1595, Epoch 20/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0020, enc_train_loss: 7.1851, enc_train_entropy: 0.0944, dec_train_loss: 0.0020, train_edge_accuracy: 0.9100, 

Epoch 20/50 completed, Global Step: 1599
nri_train_loss: 0.0020, enc_train_loss: 7.1851, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0944, dec_train_loss: 0.0020, train_edge_accuracy: 0.9100
nri_val_loss: 0.0020, enc_val_loss: 7.2653, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0877, dec_val_loss: 0.0020, val_edge_accuracy: 0.9133

---------------------------------------------------------------------------


Step 1600, Epoch 21/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0021, enc_train_loss: 7.2028, enc_train_entropy: 0.0929, dec_train_loss: 0.0021, train_edge_accuracy: 0.9100, 

Step 1605, Epoch 21/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0019, enc_train_loss: 7.1192, enc_train_entropy: 0.0999, dec_train_loss: 0.0019, train_edge_accuracy: 0.9150, 

Step 1610, Epoch 21/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0018, enc_train_loss: 7.1959, enc_train_entropy: 0.0935, dec_train_loss: 0.0018, train_edge_accuracy: 0.9150, 

Step 1615, Epoch 21/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0015, enc_train_loss: 7.1717, enc_train_entropy: 0.0955, dec_train_loss: 0.0015, train_edge_accuracy: 0.9133, 

Step 1620, Epoch 21/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0017, enc_train_loss: 7.2266, enc_train_entropy: 0.0909, dec_train_loss: 0.0017, train_edge_accuracy: 0.9133, 

Step 1625, Epoch 21/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0015, enc_train_loss: 7.2477, enc_train_entropy: 0.0892, dec_train_loss: 0.0015, train_edge_accuracy: 0.9117, 

Step 1630, Epoch 21/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.3446, enc_train_entropy: 0.0811, dec_train_loss: 0.0013, train_edge_accuracy: 0.9133, 

Step 1635, Epoch 21/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0015, enc_train_loss: 7.2522, enc_train_entropy: 0.0888, dec_train_loss: 0.0015, train_edge_accuracy: 0.9167, 

Step 1640, Epoch 21/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.2794, enc_train_entropy: 0.0865, dec_train_loss: 0.0016, train_edge_accuracy: 0.9117, 

Step 1645, Epoch 21/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.3048, enc_train_entropy: 0.0844, dec_train_loss: 0.0013, train_edge_accuracy: 0.9083, 

Step 1650, Epoch 21/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.2861, enc_train_entropy: 0.0860, dec_train_loss: 0.0013, train_edge_accuracy: 0.9100, 

Step 1655, Epoch 21/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0019, enc_train_loss: 7.3765, enc_train_entropy: 0.0784, dec_train_loss: 0.0019, train_edge_accuracy: 0.9117, 

Step 1660, Epoch 21/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.3232, enc_train_entropy: 0.0829, dec_train_loss: 0.0016, train_edge_accuracy: 0.9067, 

Step 1665, Epoch 21/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.3215, enc_train_entropy: 0.0830, dec_train_loss: 0.0013, train_edge_accuracy: 0.9083, 

Step 1670, Epoch 21/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.3966, enc_train_entropy: 0.0768, dec_train_loss: 0.0014, train_edge_accuracy: 0.9133, 

Step 1675, Epoch 21/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.3046, enc_train_entropy: 0.0844, dec_train_loss: 0.0016, train_edge_accuracy: 0.9167, 

Epoch 21/50 completed, Global Step: 1679
nri_train_loss: 0.0016, enc_train_loss: 7.3046, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0844, dec_train_loss: 0.0016, train_edge_accuracy: 0.9167
nri_val_loss: 0.0015, enc_val_loss: 7.2495, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0890, dec_val_loss: 0.0015, val_edge_accuracy: 0.9123

---------------------------------------------------------------------------


Step 1680, Epoch 22/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.2722, enc_train_entropy: 0.0871, dec_train_loss: 0.0014, train_edge_accuracy: 0.9117, 

Step 1685, Epoch 22/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0017, enc_train_loss: 7.3738, enc_train_entropy: 0.0787, dec_train_loss: 0.0017, train_edge_accuracy: 0.9150, 

Step 1690, Epoch 22/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0017, enc_train_loss: 7.2536, enc_train_entropy: 0.0887, dec_train_loss: 0.0017, train_edge_accuracy: 0.9100, 

Step 1695, Epoch 22/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.3565, enc_train_entropy: 0.0801, dec_train_loss: 0.0014, train_edge_accuracy: 0.9117, 

Step 1700, Epoch 22/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.2212, enc_train_entropy: 0.0914, dec_train_loss: 0.0016, train_edge_accuracy: 0.9083, 

Step 1705, Epoch 22/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.3645, enc_train_entropy: 0.0794, dec_train_loss: 0.0014, train_edge_accuracy: 0.9133, 

Step 1710, Epoch 22/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.4423, enc_train_entropy: 0.0730, dec_train_loss: 0.0012, train_edge_accuracy: 0.9117, 

Step 1715, Epoch 22/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.3858, enc_train_entropy: 0.0777, dec_train_loss: 0.0010, train_edge_accuracy: 0.9117, 

Step 1720, Epoch 22/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.4440, enc_train_entropy: 0.0728, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167, 

Step 1725, Epoch 22/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.2815, enc_train_entropy: 0.0864, dec_train_loss: 0.0016, train_edge_accuracy: 0.9100, 

Step 1730, Epoch 22/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.4273, enc_train_entropy: 0.0742, dec_train_loss: 0.0013, train_edge_accuracy: 0.9133, 

Step 1735, Epoch 22/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.4520, enc_train_entropy: 0.0721, dec_train_loss: 0.0013, train_edge_accuracy: 0.9150, 

Step 1740, Epoch 22/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.5093, enc_train_entropy: 0.0674, dec_train_loss: 0.0014, train_edge_accuracy: 0.9167, 

Step 1745, Epoch 22/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.4624, enc_train_entropy: 0.0713, dec_train_loss: 0.0014, train_edge_accuracy: 0.9150, 

Step 1750, Epoch 22/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.4808, enc_train_entropy: 0.0697, dec_train_loss: 0.0011, train_edge_accuracy: 0.9167, 

Step 1755, Epoch 22/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.5645, enc_train_entropy: 0.0628, dec_train_loss: 0.0011, train_edge_accuracy: 0.9117, 

Epoch 22/50 completed, Global Step: 1759
nri_train_loss: 0.0011, enc_train_loss: 7.5645, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0628, dec_train_loss: 0.0011, train_edge_accuracy: 0.9117
nri_val_loss: 0.0012, enc_val_loss: 7.5252, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0660, dec_val_loss: 0.0012, val_edge_accuracy: 0.9150

---------------------------------------------------------------------------


Step 1760, Epoch 23/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.3964, enc_train_entropy: 0.0768, dec_train_loss: 0.0013, train_edge_accuracy: 0.9100, 

Step 1765, Epoch 23/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.5634, enc_train_entropy: 0.0629, dec_train_loss: 0.0013, train_edge_accuracy: 0.9167, 

Step 1770, Epoch 23/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0015, enc_train_loss: 7.5163, enc_train_entropy: 0.0668, dec_train_loss: 0.0015, train_edge_accuracy: 0.9167, 

Step 1775, Epoch 23/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.6016, enc_train_entropy: 0.0597, dec_train_loss: 0.0014, train_edge_accuracy: 0.9167, 

Step 1780, Epoch 23/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.4938, enc_train_entropy: 0.0687, dec_train_loss: 0.0012, train_edge_accuracy: 0.9133, 

Step 1785, Epoch 23/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.5135, enc_train_entropy: 0.0670, dec_train_loss: 0.0012, train_edge_accuracy: 0.9117, 

Step 1790, Epoch 23/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.5610, enc_train_entropy: 0.0631, dec_train_loss: 0.0014, train_edge_accuracy: 0.9133, 

Step 1795, Epoch 23/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.4657, enc_train_entropy: 0.0710, dec_train_loss: 0.0012, train_edge_accuracy: 0.9100, 

Step 1800, Epoch 23/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0015, enc_train_loss: 7.5857, enc_train_entropy: 0.0610, dec_train_loss: 0.0015, train_edge_accuracy: 0.9150, 

Step 1805, Epoch 23/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.5776, enc_train_entropy: 0.0617, dec_train_loss: 0.0011, train_edge_accuracy: 0.9150, 

Step 1810, Epoch 23/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.6323, enc_train_entropy: 0.0571, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167, 

Step 1815, Epoch 23/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.5700, enc_train_entropy: 0.0623, dec_train_loss: 0.0012, train_edge_accuracy: 0.9133, 

Step 1820, Epoch 23/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.5805, enc_train_entropy: 0.0614, dec_train_loss: 0.0011, train_edge_accuracy: 0.9083, 

Step 1825, Epoch 23/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.6455, enc_train_entropy: 0.0560, dec_train_loss: 0.0016, train_edge_accuracy: 0.9167, 

Step 1830, Epoch 23/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.5379, enc_train_entropy: 0.0650, dec_train_loss: 0.0009, train_edge_accuracy: 0.9117, 

Step 1835, Epoch 23/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.5979, enc_train_entropy: 0.0600, dec_train_loss: 0.0011, train_edge_accuracy: 0.9133, 

Epoch 23/50 completed, Global Step: 1839
nri_train_loss: 0.0011, enc_train_loss: 7.5979, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0600, dec_train_loss: 0.0011, train_edge_accuracy: 0.9133
nri_val_loss: 0.0010, enc_val_loss: 7.6474, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0559, dec_val_loss: 0.0010, val_edge_accuracy: 0.9153

---------------------------------------------------------------------------


Step 1840, Epoch 24/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.6622, enc_train_entropy: 0.0546, dec_train_loss: 0.0011, train_edge_accuracy: 0.9150, 

Step 1845, Epoch 24/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.6064, enc_train_entropy: 0.0593, dec_train_loss: 0.0011, train_edge_accuracy: 0.9167, 

Step 1850, Epoch 24/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.6276, enc_train_entropy: 0.0575, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 1855, Epoch 24/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.6409, enc_train_entropy: 0.0564, dec_train_loss: 0.0016, train_edge_accuracy: 0.9167, 

Step 1860, Epoch 24/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0016, enc_train_loss: 7.6453, enc_train_entropy: 0.0560, dec_train_loss: 0.0016, train_edge_accuracy: 0.9167, 

Step 1865, Epoch 24/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6586, enc_train_entropy: 0.0549, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 1870, Epoch 24/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6145, enc_train_entropy: 0.0586, dec_train_loss: 0.0009, train_edge_accuracy: 0.9150, 

Step 1875, Epoch 24/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.6526, enc_train_entropy: 0.0554, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167, 

Step 1880, Epoch 24/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6900, enc_train_entropy: 0.0523, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 1885, Epoch 24/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.7262, enc_train_entropy: 0.0493, dec_train_loss: 0.0009, train_edge_accuracy: 0.9150, 

Step 1890, Epoch 24/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.6343, enc_train_entropy: 0.0570, dec_train_loss: 0.0008, train_edge_accuracy: 0.9150, 

Step 1895, Epoch 24/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6889, enc_train_entropy: 0.0524, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 1900, Epoch 24/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.6687, enc_train_entropy: 0.0541, dec_train_loss: 0.0012, train_edge_accuracy: 0.9133, 

Step 1905, Epoch 24/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.6884, enc_train_entropy: 0.0525, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 1910, Epoch 24/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.3720, enc_train_entropy: 0.0788, dec_train_loss: 0.0010, train_edge_accuracy: 0.9083, 

Step 1915, Epoch 24/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6599, enc_train_entropy: 0.0548, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Epoch 24/50 completed, Global Step: 1919
nri_train_loss: 0.0009, enc_train_loss: 7.6599, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0548, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167
nri_val_loss: 0.0010, enc_val_loss: 7.7000, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0515, dec_val_loss: 0.0010, val_edge_accuracy: 0.9162

---------------------------------------------------------------------------


Step 1920, Epoch 25/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.6649, enc_train_entropy: 0.0544, dec_train_loss: 0.0011, train_edge_accuracy: 0.9167, 

Step 1925, Epoch 25/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6494, enc_train_entropy: 0.0557, dec_train_loss: 0.0009, train_edge_accuracy: 0.9133, 

Step 1930, Epoch 25/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.6605, enc_train_entropy: 0.0548, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 1935, Epoch 25/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.7327, enc_train_entropy: 0.0488, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 1940, Epoch 25/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.7121, enc_train_entropy: 0.0505, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 1945, Epoch 25/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.6840, enc_train_entropy: 0.0528, dec_train_loss: 0.0008, train_edge_accuracy: 0.9150, 

Step 1950, Epoch 25/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.6582, enc_train_entropy: 0.0550, dec_train_loss: 0.0009, train_edge_accuracy: 0.9150, 

Step 1955, Epoch 25/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.7166, enc_train_entropy: 0.0501, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 1960, Epoch 25/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.7504, enc_train_entropy: 0.0473, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 1965, Epoch 25/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.6813, enc_train_entropy: 0.0530, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 1970, Epoch 25/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 7.7213, enc_train_entropy: 0.0497, dec_train_loss: 0.0014, train_edge_accuracy: 0.9150, 

Step 1975, Epoch 25/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.7922, enc_train_entropy: 0.0438, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 1980, Epoch 25/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.7746, enc_train_entropy: 0.0453, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 1985, Epoch 25/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 7.7750, enc_train_entropy: 0.0452, dec_train_loss: 0.0013, train_edge_accuracy: 0.9167, 

Step 1990, Epoch 25/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.7740, enc_train_entropy: 0.0453, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 1995, Epoch 25/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.7760, enc_train_entropy: 0.0451, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Epoch 25/50 completed, Global Step: 1999
nri_train_loss: 0.0010, enc_train_loss: 7.7760, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0451, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167
nri_val_loss: 0.0009, enc_val_loss: 7.8302, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0406, dec_val_loss: 0.0009, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2000, Epoch 26/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.7344, enc_train_entropy: 0.0486, dec_train_loss: 0.0010, train_edge_accuracy: 0.9117, 

Step 2005, Epoch 26/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.8206, enc_train_entropy: 0.0414, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 2010, Epoch 26/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.7874, enc_train_entropy: 0.0442, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2015, Epoch 26/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.7661, enc_train_entropy: 0.0460, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2020, Epoch 26/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8089, enc_train_entropy: 0.0424, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2025, Epoch 26/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.7801, enc_train_entropy: 0.0448, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2030, Epoch 26/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.7498, enc_train_entropy: 0.0473, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2035, Epoch 26/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8240, enc_train_entropy: 0.0411, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2040, Epoch 26/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.7225, enc_train_entropy: 0.0496, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2045, Epoch 26/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.7974, enc_train_entropy: 0.0434, dec_train_loss: 0.0006, train_edge_accuracy: 0.9150, 

Step 2050, Epoch 26/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.8474, enc_train_entropy: 0.0392, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2055, Epoch 26/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.8244, enc_train_entropy: 0.0411, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2060, Epoch 26/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8908, enc_train_entropy: 0.0356, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2065, Epoch 26/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8376, enc_train_entropy: 0.0400, dec_train_loss: 0.0006, train_edge_accuracy: 0.9150, 

Step 2070, Epoch 26/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.8482, enc_train_entropy: 0.0391, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2075, Epoch 26/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8551, enc_train_entropy: 0.0386, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Epoch 26/50 completed, Global Step: 2079
nri_train_loss: 0.0006, enc_train_loss: 7.8551, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0386, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167
nri_val_loss: 0.0007, enc_val_loss: 7.8572, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0384, dec_val_loss: 0.0007, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2080, Epoch 27/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8730, enc_train_entropy: 0.0371, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2085, Epoch 27/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8845, enc_train_entropy: 0.0361, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2090, Epoch 27/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.7638, enc_train_entropy: 0.0462, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2095, Epoch 27/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.8774, enc_train_entropy: 0.0367, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2100, Epoch 27/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.8541, enc_train_entropy: 0.0386, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167, 

Step 2105, Epoch 27/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 7.8347, enc_train_entropy: 0.0403, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167, 

Step 2110, Epoch 27/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.7979, enc_train_entropy: 0.0433, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2115, Epoch 27/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8013, enc_train_entropy: 0.0430, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2120, Epoch 27/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8352, enc_train_entropy: 0.0402, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2125, Epoch 27/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8711, enc_train_entropy: 0.0372, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2130, Epoch 27/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.9159, enc_train_entropy: 0.0335, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2135, Epoch 27/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0011, enc_train_loss: 7.8956, enc_train_entropy: 0.0352, dec_train_loss: 0.0011, train_edge_accuracy: 0.9150, 

Step 2140, Epoch 27/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.8476, enc_train_entropy: 0.0392, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 2145, Epoch 27/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8699, enc_train_entropy: 0.0373, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2150, Epoch 27/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.8571, enc_train_entropy: 0.0384, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 2155, Epoch 27/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8100, enc_train_entropy: 0.0423, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Epoch 27/50 completed, Global Step: 2159
nri_train_loss: 0.0007, enc_train_loss: 7.8100, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0423, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167
nri_val_loss: 0.0008, enc_val_loss: 7.8465, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0393, dec_val_loss: 0.0008, val_edge_accuracy: 0.9162

---------------------------------------------------------------------------


Step 2160, Epoch 28/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.8201, enc_train_entropy: 0.0415, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2165, Epoch 28/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8552, enc_train_entropy: 0.0385, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2170, Epoch 28/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9475, enc_train_entropy: 0.0309, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2175, Epoch 28/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8853, enc_train_entropy: 0.0360, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2180, Epoch 28/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.8457, enc_train_entropy: 0.0393, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2185, Epoch 28/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8375, enc_train_entropy: 0.0400, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2190, Epoch 28/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9326, enc_train_entropy: 0.0321, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2195, Epoch 28/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 7.9342, enc_train_entropy: 0.0320, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 2200, Epoch 28/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.9377, enc_train_entropy: 0.0317, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2205, Epoch 28/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.9554, enc_train_entropy: 0.0302, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2210, Epoch 28/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8928, enc_train_entropy: 0.0354, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2215, Epoch 28/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8757, enc_train_entropy: 0.0368, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2220, Epoch 28/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.9657, enc_train_entropy: 0.0293, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2225, Epoch 28/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 7.9118, enc_train_entropy: 0.0338, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 2230, Epoch 28/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8985, enc_train_entropy: 0.0349, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2235, Epoch 28/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8985, enc_train_entropy: 0.0349, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Epoch 28/50 completed, Global Step: 2239
nri_train_loss: 0.0006, enc_train_loss: 7.8985, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0349, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167
nri_val_loss: 0.0007, enc_val_loss: 7.9285, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0324, dec_val_loss: 0.0007, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2240, Epoch 29/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9170, enc_train_entropy: 0.0334, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2245, Epoch 29/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9666, enc_train_entropy: 0.0293, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2250, Epoch 29/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.9152, enc_train_entropy: 0.0335, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2255, Epoch 29/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.9188, enc_train_entropy: 0.0332, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2260, Epoch 29/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.8943, enc_train_entropy: 0.0353, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2265, Epoch 29/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9272, enc_train_entropy: 0.0325, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2270, Epoch 29/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.9218, enc_train_entropy: 0.0330, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2275, Epoch 29/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.8871, enc_train_entropy: 0.0359, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2280, Epoch 29/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8666, enc_train_entropy: 0.0376, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2285, Epoch 29/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9457, enc_train_entropy: 0.0310, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2290, Epoch 29/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.8845, enc_train_entropy: 0.0361, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2295, Epoch 29/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.8741, enc_train_entropy: 0.0370, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2300, Epoch 29/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9127, enc_train_entropy: 0.0338, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2305, Epoch 29/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9601, enc_train_entropy: 0.0298, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2310, Epoch 29/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.8730, enc_train_entropy: 0.0371, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2315, Epoch 29/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9764, enc_train_entropy: 0.0284, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Epoch 29/50 completed, Global Step: 2319
nri_train_loss: 0.0005, enc_train_loss: 7.9764, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0284, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167
nri_val_loss: 0.0007, enc_val_loss: 7.9766, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0284, dec_val_loss: 0.0007, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2320, Epoch 30/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9948, enc_train_entropy: 0.0269, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2325, Epoch 30/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0067, enc_train_entropy: 0.0259, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2330, Epoch 30/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 7.9509, enc_train_entropy: 0.0306, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2335, Epoch 30/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.9554, enc_train_entropy: 0.0302, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2340, Epoch 30/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9880, enc_train_entropy: 0.0275, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2345, Epoch 30/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0008, enc_train_entropy: 0.0264, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2350, Epoch 30/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9952, enc_train_entropy: 0.0269, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2355, Epoch 30/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.9848, enc_train_entropy: 0.0277, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2360, Epoch 30/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.0314, enc_train_entropy: 0.0239, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2365, Epoch 30/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9834, enc_train_entropy: 0.0279, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2370, Epoch 30/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9865, enc_train_entropy: 0.0276, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2375, Epoch 30/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9800, enc_train_entropy: 0.0281, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2380, Epoch 30/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0242, enc_train_entropy: 0.0245, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2385, Epoch 30/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.9973, enc_train_entropy: 0.0267, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2390, Epoch 30/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 7.9618, enc_train_entropy: 0.0297, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2395, Epoch 30/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9107, enc_train_entropy: 0.0339, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Epoch 30/50 completed, Global Step: 2399
nri_train_loss: 0.0005, enc_train_loss: 7.9107, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0339, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167
nri_val_loss: 0.0006, enc_val_loss: 8.0309, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0239, dec_val_loss: 0.0006, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2400, Epoch 31/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9974, enc_train_entropy: 0.0267, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2405, Epoch 31/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0226, enc_train_entropy: 0.0246, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2410, Epoch 31/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.0210, enc_train_entropy: 0.0247, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2415, Epoch 31/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9969, enc_train_entropy: 0.0267, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2420, Epoch 31/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0450, enc_train_entropy: 0.0227, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2425, Epoch 31/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0349, enc_train_entropy: 0.0236, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2430, Epoch 31/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.9410, enc_train_entropy: 0.0314, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2435, Epoch 31/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0550, enc_train_entropy: 0.0219, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2440, Epoch 31/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0367, enc_train_entropy: 0.0234, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2445, Epoch 31/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0462, enc_train_entropy: 0.0226, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2450, Epoch 31/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 8.0248, enc_train_entropy: 0.0244, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 2455, Epoch 31/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9586, enc_train_entropy: 0.0299, dec_train_loss: 0.0005, train_edge_accuracy: 0.9150, 

Step 2460, Epoch 31/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9864, enc_train_entropy: 0.0276, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2465, Epoch 31/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9851, enc_train_entropy: 0.0277, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2470, Epoch 31/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0329, enc_train_entropy: 0.0237, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2475, Epoch 31/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 7.9733, enc_train_entropy: 0.0287, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Epoch 31/50 completed, Global Step: 2479
nri_train_loss: 0.0004, enc_train_loss: 7.9733, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0287, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167
nri_val_loss: 0.0005, enc_val_loss: 8.0250, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0244, dec_val_loss: 0.0005, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2480, Epoch 32/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9864, enc_train_entropy: 0.0276, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2485, Epoch 32/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 7.9909, enc_train_entropy: 0.0272, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2490, Epoch 32/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0166, enc_train_entropy: 0.0251, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2495, Epoch 32/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9956, enc_train_entropy: 0.0269, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2500, Epoch 32/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0320, enc_train_entropy: 0.0238, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2505, Epoch 32/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 8.0387, enc_train_entropy: 0.0233, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2510, Epoch 32/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0624, enc_train_entropy: 0.0213, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2515, Epoch 32/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0013, enc_train_loss: 8.0223, enc_train_entropy: 0.0246, dec_train_loss: 0.0013, train_edge_accuracy: 0.9167, 

Step 2520, Epoch 32/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0293, enc_train_entropy: 0.0240, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2525, Epoch 32/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0572, enc_train_entropy: 0.0217, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2530, Epoch 32/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0819, enc_train_entropy: 0.0197, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2535, Epoch 32/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0789, enc_train_entropy: 0.0199, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2540, Epoch 32/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 8.0544, enc_train_entropy: 0.0219, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2545, Epoch 32/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1011, enc_train_entropy: 0.0181, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2550, Epoch 32/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.1133, enc_train_entropy: 0.0170, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2555, Epoch 32/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0846, enc_train_entropy: 0.0194, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Epoch 32/50 completed, Global Step: 2559
nri_train_loss: 0.0004, enc_train_loss: 8.0846, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0194, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167
nri_val_loss: 0.0005, enc_val_loss: 8.0921, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0188, dec_val_loss: 0.0005, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2560, Epoch 33/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0908, enc_train_entropy: 0.0189, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2565, Epoch 33/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 8.0166, enc_train_entropy: 0.0251, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2570, Epoch 33/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0411, enc_train_entropy: 0.0231, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2575, Epoch 33/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0505, enc_train_entropy: 0.0223, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2580, Epoch 33/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.0373, enc_train_entropy: 0.0234, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2585, Epoch 33/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0780, enc_train_entropy: 0.0200, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2590, Epoch 33/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0433, enc_train_entropy: 0.0229, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2595, Epoch 33/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0375, enc_train_entropy: 0.0234, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2600, Epoch 33/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0353, enc_train_entropy: 0.0235, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2605, Epoch 33/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9996, enc_train_entropy: 0.0265, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2610, Epoch 33/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0345, enc_train_entropy: 0.0236, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2615, Epoch 33/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0056, enc_train_entropy: 0.0260, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2620, Epoch 33/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0269, enc_train_entropy: 0.0242, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2625, Epoch 33/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0719, enc_train_entropy: 0.0205, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2630, Epoch 33/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0522, enc_train_entropy: 0.0221, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2635, Epoch 33/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0634, enc_train_entropy: 0.0212, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Epoch 33/50 completed, Global Step: 2639
nri_train_loss: 0.0004, enc_train_loss: 8.0634, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0212, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167
nri_val_loss: 0.0008, enc_val_loss: 8.0828, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0196, dec_val_loss: 0.0008, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2640, Epoch 34/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.1012, enc_train_entropy: 0.0180, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2645, Epoch 34/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.0626, enc_train_entropy: 0.0213, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2650, Epoch 34/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0408, enc_train_entropy: 0.0231, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2655, Epoch 34/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0600, enc_train_entropy: 0.0215, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2660, Epoch 34/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0988, enc_train_entropy: 0.0182, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2665, Epoch 34/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0987, enc_train_entropy: 0.0183, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2670, Epoch 34/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.0536, enc_train_entropy: 0.0220, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2675, Epoch 34/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0967, enc_train_entropy: 0.0184, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2680, Epoch 34/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0337, enc_train_entropy: 0.0237, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2685, Epoch 34/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0570, enc_train_entropy: 0.0217, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2690, Epoch 34/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.0356, enc_train_entropy: 0.0235, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2695, Epoch 34/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9587, enc_train_entropy: 0.0299, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2700, Epoch 34/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9638, enc_train_entropy: 0.0295, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2705, Epoch 34/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.0075, enc_train_entropy: 0.0259, dec_train_loss: 0.0006, train_edge_accuracy: 0.9150, 

Step 2710, Epoch 34/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 7.9630, enc_train_entropy: 0.0296, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2715, Epoch 34/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0721, enc_train_entropy: 0.0205, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Epoch 34/50 completed, Global Step: 2719
nri_train_loss: 0.0004, enc_train_loss: 8.0721, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0205, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167
nri_val_loss: 0.0006, enc_val_loss: 8.0847, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0194, dec_val_loss: 0.0006, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2720, Epoch 35/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.0592, enc_train_entropy: 0.0215, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2725, Epoch 35/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0631, enc_train_entropy: 0.0212, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2730, Epoch 35/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1039, enc_train_entropy: 0.0178, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2735, Epoch 35/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1034, enc_train_entropy: 0.0179, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2740, Epoch 35/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1215, enc_train_entropy: 0.0164, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2745, Epoch 35/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.1124, enc_train_entropy: 0.0171, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 2750, Epoch 35/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1350, enc_train_entropy: 0.0152, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2755, Epoch 35/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1056, enc_train_entropy: 0.0177, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2760, Epoch 35/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1166, enc_train_entropy: 0.0168, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2765, Epoch 35/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0986, enc_train_entropy: 0.0183, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2770, Epoch 35/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0340, enc_train_entropy: 0.0236, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2775, Epoch 35/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0924, enc_train_entropy: 0.0188, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2780, Epoch 35/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0456, enc_train_entropy: 0.0227, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2785, Epoch 35/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0772, enc_train_entropy: 0.0200, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2790, Epoch 35/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0907, enc_train_entropy: 0.0189, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2795, Epoch 35/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0944, enc_train_entropy: 0.0186, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Epoch 35/50 completed, Global Step: 2799
nri_train_loss: 0.0005, enc_train_loss: 8.0944, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0186, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167
nri_val_loss: 0.0004, enc_val_loss: 8.1208, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0164, dec_val_loss: 0.0004, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2800, Epoch 36/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0653, enc_train_entropy: 0.0210, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2805, Epoch 36/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0918, enc_train_entropy: 0.0188, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2810, Epoch 36/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1297, enc_train_entropy: 0.0157, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2815, Epoch 36/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1153, enc_train_entropy: 0.0169, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2820, Epoch 36/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1112, enc_train_entropy: 0.0172, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2825, Epoch 36/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0009, enc_train_loss: 8.1337, enc_train_entropy: 0.0153, dec_train_loss: 0.0009, train_edge_accuracy: 0.9167, 

Step 2830, Epoch 36/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0008, enc_train_loss: 8.1105, enc_train_entropy: 0.0173, dec_train_loss: 0.0008, train_edge_accuracy: 0.9167, 

Step 2835, Epoch 36/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0982, enc_train_entropy: 0.0183, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2840, Epoch 36/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1499, enc_train_entropy: 0.0140, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2845, Epoch 36/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0985, enc_train_entropy: 0.0183, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2850, Epoch 36/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0933, enc_train_entropy: 0.0187, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2855, Epoch 36/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1315, enc_train_entropy: 0.0155, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2860, Epoch 36/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0983, enc_train_entropy: 0.0183, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2865, Epoch 36/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0978, enc_train_entropy: 0.0183, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2870, Epoch 36/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0919, enc_train_entropy: 0.0188, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2875, Epoch 36/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0895, enc_train_entropy: 0.0190, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 36/50 completed, Global Step: 2879
nri_train_loss: 0.0003, enc_train_loss: 8.0895, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0190, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0004, enc_val_loss: 8.0917, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0188, dec_val_loss: 0.0004, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2880, Epoch 37/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0959, enc_train_entropy: 0.0185, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2885, Epoch 37/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0654, enc_train_entropy: 0.0210, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2890, Epoch 37/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0511, enc_train_entropy: 0.0222, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2895, Epoch 37/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0546, enc_train_entropy: 0.0219, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2900, Epoch 37/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1071, enc_train_entropy: 0.0176, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2905, Epoch 37/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0791, enc_train_entropy: 0.0199, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2910, Epoch 37/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1117, enc_train_entropy: 0.0172, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2915, Epoch 37/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1110, enc_train_entropy: 0.0172, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2920, Epoch 37/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1312, enc_train_entropy: 0.0156, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2925, Epoch 37/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1089, enc_train_entropy: 0.0174, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2930, Epoch 37/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0925, enc_train_entropy: 0.0188, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2935, Epoch 37/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1806, enc_train_entropy: 0.0114, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2940, Epoch 37/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1011, enc_train_entropy: 0.0181, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2945, Epoch 37/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1297, enc_train_entropy: 0.0157, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2950, Epoch 37/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1314, enc_train_entropy: 0.0155, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2955, Epoch 37/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.0933, enc_train_entropy: 0.0187, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 37/50 completed, Global Step: 2959
nri_train_loss: 0.0003, enc_train_loss: 8.0933, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0187, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0009, enc_val_loss: 8.1430, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0146, dec_val_loss: 0.0009, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 2960, Epoch 38/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0010, enc_train_loss: 8.0821, enc_train_entropy: 0.0196, dec_train_loss: 0.0010, train_edge_accuracy: 0.9167, 

Step 2965, Epoch 38/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.0896, enc_train_entropy: 0.0190, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 2970, Epoch 38/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1189, enc_train_entropy: 0.0166, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 2975, Epoch 38/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1008, enc_train_entropy: 0.0181, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2980, Epoch 38/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1517, enc_train_entropy: 0.0138, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2985, Epoch 38/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1612, enc_train_entropy: 0.0130, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 2990, Epoch 38/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1254, enc_train_entropy: 0.0160, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 2995, Epoch 38/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1185, enc_train_entropy: 0.0166, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3000, Epoch 38/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.0999, enc_train_entropy: 0.0182, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3005, Epoch 38/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1394, enc_train_entropy: 0.0149, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 3010, Epoch 38/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1561, enc_train_entropy: 0.0135, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 3015, Epoch 38/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1314, enc_train_entropy: 0.0155, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3020, Epoch 38/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1119, enc_train_entropy: 0.0172, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3025, Epoch 38/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1480, enc_train_entropy: 0.0142, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3030, Epoch 38/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0855, enc_train_entropy: 0.0194, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3035, Epoch 38/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1648, enc_train_entropy: 0.0127, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 38/50 completed, Global Step: 3039
nri_train_loss: 0.0003, enc_train_loss: 8.1648, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0127, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.1538, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0137, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3040, Epoch 39/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.0805, enc_train_entropy: 0.0198, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3045, Epoch 39/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1573, enc_train_entropy: 0.0134, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3050, Epoch 39/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1138, enc_train_entropy: 0.0170, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3055, Epoch 39/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1352, enc_train_entropy: 0.0152, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3060, Epoch 39/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1476, enc_train_entropy: 0.0142, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3065, Epoch 39/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1373, enc_train_entropy: 0.0150, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3070, Epoch 39/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1197, enc_train_entropy: 0.0165, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3075, Epoch 39/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1757, enc_train_entropy: 0.0118, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3080, Epoch 39/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1600, enc_train_entropy: 0.0131, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3085, Epoch 39/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1846, enc_train_entropy: 0.0111, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3090, Epoch 39/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1252, enc_train_entropy: 0.0160, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3095, Epoch 39/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1502, enc_train_entropy: 0.0140, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3100, Epoch 39/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1676, enc_train_entropy: 0.0125, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3105, Epoch 39/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1417, enc_train_entropy: 0.0147, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3110, Epoch 39/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1747, enc_train_entropy: 0.0119, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3115, Epoch 39/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1636, enc_train_entropy: 0.0128, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 39/50 completed, Global Step: 3119
nri_train_loss: 0.0003, enc_train_loss: 8.1636, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0128, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.1643, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0128, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3120, Epoch 40/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1861, enc_train_entropy: 0.0110, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3125, Epoch 40/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1694, enc_train_entropy: 0.0124, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3130, Epoch 40/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1250, enc_train_entropy: 0.0161, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3135, Epoch 40/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1876, enc_train_entropy: 0.0108, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3140, Epoch 40/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1251, enc_train_entropy: 0.0161, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3145, Epoch 40/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1480, enc_train_entropy: 0.0141, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3150, Epoch 40/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1772, enc_train_entropy: 0.0117, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3155, Epoch 40/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1679, enc_train_entropy: 0.0125, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3160, Epoch 40/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1678, enc_train_entropy: 0.0125, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3165, Epoch 40/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1728, enc_train_entropy: 0.0121, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3170, Epoch 40/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1661, enc_train_entropy: 0.0126, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3175, Epoch 40/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1990, enc_train_entropy: 0.0099, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3180, Epoch 40/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1660, enc_train_entropy: 0.0126, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3185, Epoch 40/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1897, enc_train_entropy: 0.0107, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3190, Epoch 40/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1830, enc_train_entropy: 0.0112, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3195, Epoch 40/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1711, enc_train_entropy: 0.0122, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Epoch 40/50 completed, Global Step: 3199
nri_train_loss: 0.0002, enc_train_loss: 8.1711, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0122, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.1706, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0123, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3200, Epoch 41/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1965, enc_train_entropy: 0.0101, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3205, Epoch 41/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1193, enc_train_entropy: 0.0165, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3210, Epoch 41/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1177, enc_train_entropy: 0.0167, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3215, Epoch 41/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1180, enc_train_entropy: 0.0167, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3220, Epoch 41/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1070, enc_train_entropy: 0.0176, dec_train_loss: 0.0006, train_edge_accuracy: 0.9150, 

Step 3225, Epoch 41/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1662, enc_train_entropy: 0.0126, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3230, Epoch 41/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1824, enc_train_entropy: 0.0113, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3235, Epoch 41/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1518, enc_train_entropy: 0.0138, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3240, Epoch 41/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1251, enc_train_entropy: 0.0161, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3245, Epoch 41/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1551, enc_train_entropy: 0.0136, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3250, Epoch 41/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1461, enc_train_entropy: 0.0143, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3255, Epoch 41/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1428, enc_train_entropy: 0.0146, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3260, Epoch 41/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1533, enc_train_entropy: 0.0137, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3265, Epoch 41/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1531, enc_train_entropy: 0.0137, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3270, Epoch 41/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1907, enc_train_entropy: 0.0106, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3275, Epoch 41/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1590, enc_train_entropy: 0.0132, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Epoch 41/50 completed, Global Step: 3279
nri_train_loss: 0.0004, enc_train_loss: 8.1590, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0132, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167
nri_val_loss: 0.0004, enc_val_loss: 8.1807, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0114, dec_val_loss: 0.0004, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3280, Epoch 42/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1818, enc_train_entropy: 0.0113, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 3285, Epoch 42/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1575, enc_train_entropy: 0.0134, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3290, Epoch 42/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1653, enc_train_entropy: 0.0127, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3295, Epoch 42/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1893, enc_train_entropy: 0.0107, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3300, Epoch 42/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1447, enc_train_entropy: 0.0144, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3305, Epoch 42/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1929, enc_train_entropy: 0.0104, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3310, Epoch 42/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1900, enc_train_entropy: 0.0107, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3315, Epoch 42/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1559, enc_train_entropy: 0.0135, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3320, Epoch 42/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1879, enc_train_entropy: 0.0108, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3325, Epoch 42/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1889, enc_train_entropy: 0.0107, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3330, Epoch 42/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1808, enc_train_entropy: 0.0114, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3335, Epoch 42/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1686, enc_train_entropy: 0.0124, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3340, Epoch 42/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1744, enc_train_entropy: 0.0120, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3345, Epoch 42/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1950, enc_train_entropy: 0.0102, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3350, Epoch 42/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2021, enc_train_entropy: 0.0096, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3355, Epoch 42/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1816, enc_train_entropy: 0.0114, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 42/50 completed, Global Step: 3359
nri_train_loss: 0.0003, enc_train_loss: 8.1816, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0114, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.2012, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0097, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3360, Epoch 43/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1074, enc_train_entropy: 0.0175, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3365, Epoch 43/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2016, enc_train_entropy: 0.0097, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3370, Epoch 43/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2021, enc_train_entropy: 0.0096, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3375, Epoch 43/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1915, enc_train_entropy: 0.0105, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3380, Epoch 43/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1685, enc_train_entropy: 0.0124, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3385, Epoch 43/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1769, enc_train_entropy: 0.0117, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3390, Epoch 43/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1888, enc_train_entropy: 0.0107, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3395, Epoch 43/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1744, enc_train_entropy: 0.0119, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3400, Epoch 43/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2055, enc_train_entropy: 0.0094, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3405, Epoch 43/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1817, enc_train_entropy: 0.0113, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3410, Epoch 43/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1492, enc_train_entropy: 0.0140, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3415, Epoch 43/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2028, enc_train_entropy: 0.0096, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3420, Epoch 43/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1668, enc_train_entropy: 0.0126, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3425, Epoch 43/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1599, enc_train_entropy: 0.0132, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3430, Epoch 43/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1763, enc_train_entropy: 0.0118, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3435, Epoch 43/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1469, enc_train_entropy: 0.0142, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 43/50 completed, Global Step: 3439
nri_train_loss: 0.0003, enc_train_loss: 8.1469, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0142, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.1927, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0104, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3440, Epoch 44/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1986, enc_train_entropy: 0.0099, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3445, Epoch 44/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1881, enc_train_entropy: 0.0108, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3450, Epoch 44/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1719, enc_train_entropy: 0.0122, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3455, Epoch 44/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1974, enc_train_entropy: 0.0100, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3460, Epoch 44/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1941, enc_train_entropy: 0.0103, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3465, Epoch 44/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1472, enc_train_entropy: 0.0142, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3470, Epoch 44/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1939, enc_train_entropy: 0.0103, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3475, Epoch 44/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1985, enc_train_entropy: 0.0099, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3480, Epoch 44/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1878, enc_train_entropy: 0.0108, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3485, Epoch 44/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1780, enc_train_entropy: 0.0116, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 3490, Epoch 44/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2048, enc_train_entropy: 0.0094, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3495, Epoch 44/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2149, enc_train_entropy: 0.0086, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3500, Epoch 44/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2062, enc_train_entropy: 0.0093, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3505, Epoch 44/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2127, enc_train_entropy: 0.0088, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3510, Epoch 44/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1498, enc_train_entropy: 0.0140, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3515, Epoch 44/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1898, enc_train_entropy: 0.0107, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Epoch 44/50 completed, Global Step: 3519
nri_train_loss: 0.0002, enc_train_loss: 8.1898, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0107, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.1986, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0099, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3520, Epoch 45/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2133, enc_train_entropy: 0.0087, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3525, Epoch 45/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1572, enc_train_entropy: 0.0134, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3530, Epoch 45/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1951, enc_train_entropy: 0.0102, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3535, Epoch 45/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2131, enc_train_entropy: 0.0087, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3540, Epoch 45/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2010, enc_train_entropy: 0.0097, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3545, Epoch 45/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2001, enc_train_entropy: 0.0098, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3550, Epoch 45/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1676, enc_train_entropy: 0.0125, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3555, Epoch 45/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1800, enc_train_entropy: 0.0115, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3560, Epoch 45/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1447, enc_train_entropy: 0.0144, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3565, Epoch 45/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1722, enc_train_entropy: 0.0121, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3570, Epoch 45/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0014, enc_train_loss: 8.1965, enc_train_entropy: 0.0101, dec_train_loss: 0.0014, train_edge_accuracy: 0.9167, 

Step 3575, Epoch 45/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0007, enc_train_loss: 8.1768, enc_train_entropy: 0.0118, dec_train_loss: 0.0007, train_edge_accuracy: 0.9167, 

Step 3580, Epoch 45/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.2101, enc_train_entropy: 0.0090, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3585, Epoch 45/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1827, enc_train_entropy: 0.0113, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3590, Epoch 45/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1531, enc_train_entropy: 0.0137, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3595, Epoch 45/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0012, enc_train_loss: 8.1849, enc_train_entropy: 0.0111, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167, 

Epoch 45/50 completed, Global Step: 3599
nri_train_loss: 0.0012, enc_train_loss: 8.1849, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0111, dec_train_loss: 0.0012, train_edge_accuracy: 0.9167
nri_val_loss: 0.0004, enc_val_loss: 8.1625, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0129, dec_val_loss: 0.0004, val_edge_accuracy: 0.9165

---------------------------------------------------------------------------


Step 3600, Epoch 46/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1912, enc_train_entropy: 0.0105, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3605, Epoch 46/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0006, enc_train_loss: 8.1647, enc_train_entropy: 0.0128, dec_train_loss: 0.0006, train_edge_accuracy: 0.9167, 

Step 3610, Epoch 46/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1683, enc_train_entropy: 0.0125, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3615, Epoch 46/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1996, enc_train_entropy: 0.0098, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3620, Epoch 46/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2177, enc_train_entropy: 0.0083, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3625, Epoch 46/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1644, enc_train_entropy: 0.0128, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3630, Epoch 46/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2178, enc_train_entropy: 0.0083, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3635, Epoch 46/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1910, enc_train_entropy: 0.0106, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3640, Epoch 46/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2274, enc_train_entropy: 0.0075, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3645, Epoch 46/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1939, enc_train_entropy: 0.0103, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3650, Epoch 46/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1964, enc_train_entropy: 0.0101, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3655, Epoch 46/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2193, enc_train_entropy: 0.0082, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3660, Epoch 46/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2011, enc_train_entropy: 0.0097, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3665, Epoch 46/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2014, enc_train_entropy: 0.0097, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3670, Epoch 46/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2112, enc_train_entropy: 0.0089, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3675, Epoch 46/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2173, enc_train_entropy: 0.0084, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Epoch 46/50 completed, Global Step: 3679
nri_train_loss: 0.0003, enc_train_loss: 8.2173, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0084, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.2219, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0080, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3680, Epoch 47/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1802, enc_train_entropy: 0.0115, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3685, Epoch 47/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1930, enc_train_entropy: 0.0104, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3690, Epoch 47/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2008, enc_train_entropy: 0.0098, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3695, Epoch 47/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2093, enc_train_entropy: 0.0090, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3700, Epoch 47/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2109, enc_train_entropy: 0.0089, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3705, Epoch 47/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2146, enc_train_entropy: 0.0086, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3710, Epoch 47/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1560, enc_train_entropy: 0.0135, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3715, Epoch 47/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2084, enc_train_entropy: 0.0091, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3720, Epoch 47/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2247, enc_train_entropy: 0.0078, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3725, Epoch 47/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2172, enc_train_entropy: 0.0084, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3730, Epoch 47/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2095, enc_train_entropy: 0.0090, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3735, Epoch 47/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1979, enc_train_entropy: 0.0100, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3740, Epoch 47/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1691, enc_train_entropy: 0.0124, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3745, Epoch 47/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1942, enc_train_entropy: 0.0103, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3750, Epoch 47/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2272, enc_train_entropy: 0.0075, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3755, Epoch 47/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2328, enc_train_entropy: 0.0071, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Epoch 47/50 completed, Global Step: 3759
nri_train_loss: 0.0002, enc_train_loss: 8.2328, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0071, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167
nri_val_loss: 0.0002, enc_val_loss: 8.2303, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0073, dec_val_loss: 0.0002, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3760, Epoch 48/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2174, enc_train_entropy: 0.0084, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3765, Epoch 48/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2379, enc_train_entropy: 0.0067, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3770, Epoch 48/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2362, enc_train_entropy: 0.0068, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3775, Epoch 48/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2434, enc_train_entropy: 0.0062, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3780, Epoch 48/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2248, enc_train_entropy: 0.0077, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3785, Epoch 48/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1930, enc_train_entropy: 0.0104, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3790, Epoch 48/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2156, enc_train_entropy: 0.0085, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3795, Epoch 48/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2299, enc_train_entropy: 0.0073, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3800, Epoch 48/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2115, enc_train_entropy: 0.0089, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3805, Epoch 48/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2134, enc_train_entropy: 0.0087, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3810, Epoch 48/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2091, enc_train_entropy: 0.0091, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3815, Epoch 48/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1591, enc_train_entropy: 0.0132, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3820, Epoch 48/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1834, enc_train_entropy: 0.0112, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3825, Epoch 48/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1566, enc_train_entropy: 0.0134, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3830, Epoch 48/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1825, enc_train_entropy: 0.0113, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3835, Epoch 48/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.1641, enc_train_entropy: 0.0128, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Epoch 48/50 completed, Global Step: 3839
nri_train_loss: 0.0005, enc_train_loss: 8.1641, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0128, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167
nri_val_loss: 0.0005, enc_val_loss: 8.1867, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0109, dec_val_loss: 0.0005, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3840, Epoch 49/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2161, enc_train_entropy: 0.0085, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3845, Epoch 49/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1567, enc_train_entropy: 0.0134, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3850, Epoch 49/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2256, enc_train_entropy: 0.0077, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3855, Epoch 49/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2392, enc_train_entropy: 0.0066, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3860, Epoch 49/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2299, enc_train_entropy: 0.0073, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3865, Epoch 49/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2264, enc_train_entropy: 0.0076, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3870, Epoch 49/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2331, enc_train_entropy: 0.0071, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3875, Epoch 49/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2360, enc_train_entropy: 0.0068, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3880, Epoch 49/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2298, enc_train_entropy: 0.0073, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3885, Epoch 49/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2266, enc_train_entropy: 0.0076, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3890, Epoch 49/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2320, enc_train_entropy: 0.0071, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3895, Epoch 49/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2222, enc_train_entropy: 0.0080, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3900, Epoch 49/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.1651, enc_train_entropy: 0.0127, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3905, Epoch 49/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1663, enc_train_entropy: 0.0126, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3910, Epoch 49/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2146, enc_train_entropy: 0.0086, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3915, Epoch 49/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.1802, enc_train_entropy: 0.0115, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Epoch 49/50 completed, Global Step: 3919
nri_train_loss: 0.0004, enc_train_loss: 8.1802, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0115, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167
nri_val_loss: 0.0003, enc_val_loss: 8.2320, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0071, dec_val_loss: 0.0003, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Step 3920, Epoch 50/50, Batch 1/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2055, enc_train_entropy: 0.0094, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3925, Epoch 50/50, Batch 6/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2380, enc_train_entropy: 0.0066, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3930, Epoch 50/50, Batch 11/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2213, enc_train_entropy: 0.0080, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3935, Epoch 50/50, Batch 16/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2348, enc_train_entropy: 0.0069, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3940, Epoch 50/50, Batch 21/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2005, enc_train_entropy: 0.0098, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3945, Epoch 50/50, Batch 26/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2406, enc_train_entropy: 0.0064, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3950, Epoch 50/50, Batch 31/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1903, enc_train_entropy: 0.0106, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3955, Epoch 50/50, Batch 36/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2280, enc_train_entropy: 0.0075, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3960, Epoch 50/50, Batch 41/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2269, enc_train_entropy: 0.0076, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3965, Epoch 50/50, Batch 46/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.1880, enc_train_entropy: 0.0108, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3970, Epoch 50/50, Batch 51/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0003, enc_train_loss: 8.2194, enc_train_entropy: 0.0082, dec_train_loss: 0.0003, train_edge_accuracy: 0.9167, 

Step 3975, Epoch 50/50, Batch 56/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2145, enc_train_entropy: 0.0086, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Step 3980, Epoch 50/50, Batch 61/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2345, enc_train_entropy: 0.0069, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3985, Epoch 50/50, Batch 66/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0005, enc_train_loss: 8.2373, enc_train_entropy: 0.0067, dec_train_loss: 0.0005, train_edge_accuracy: 0.9167, 

Step 3990, Epoch 50/50, Batch 71/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0004, enc_train_loss: 8.2438, enc_train_entropy: 0.0062, dec_train_loss: 0.0004, train_edge_accuracy: 0.9167, 

Step 3995, Epoch 50/50, Batch 76/80
temp: 0.7000, beta: 0.0000, gamma: 0.0000, 
enc_train_warmup_loss: 0.0000, 
nri_train_loss: 0.0002, enc_train_loss: 8.2507, enc_train_entropy: 0.0056, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167, 

Epoch 50/50 completed, Global Step: 3999
nri_train_loss: 0.0002, enc_train_loss: 8.2507, enc_train_warmup_loss: 0.0000, enc_train_entropy: 0.0056, dec_train_loss: 0.0002, train_edge_accuracy: 0.9167
nri_val_loss: 0.0004, enc_val_loss: 8.2507, enc_val_warmup_loss: 0.0000, enc_val_entropy: 0.0056, dec_val_loss: 0.0004, val_edge_accuracy: 0.9167

---------------------------------------------------------------------------


Training completed in 1384.76 seconds or 23.08 minutes or 0.3846553423669603 hours.
Total training steps: 3999

Training completed for model '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16'. Trained model saved at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16\checkpoints

---------------------------------------------------------------------------

<<<<<<<<<<<< TRAINING LOSS PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating training loss plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16...

Training loss (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16


<<<<<<<<<<<< ENCODER EDGE ACCURACY PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating encoder edge accuracy plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16...

Encoder edge accuracy (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16


<<<<<<<<<<<< ENCODER EDGE ENTROPY PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating encoder edge entropy plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16...

Encoder edge entropy (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16


<<<<<<<<<<<< DECODER OUTPUT PLOT (TRAIN) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.319' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16...

Decoder output plot for rep '1001.3191' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16


<<<<<<<<<<<< DECODER OUTPUT PLOT (VAL) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.234' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16...

Decoder output plot for rep '1001.2338' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16


---------------------------------------------------------------------------

TESTING TRAINED NRI MODEL...

.ckpt_files available in C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16\checkpoints:

['best-model-epoch=46-val_loss=0.0000.ckpt']

Testing environment set. Testing will be logged at: C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16\test

Trained NRI Model Loaded for testing.
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Testing: |                                                                      | 0/? [00:00<?, ?it/s]
Initializing input processors for encoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Initializing input processors for decoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------
Testing:   0%|                                                                 | 0/10 [00:00<?, ?it/s]Testing DataLoader 0:   0%|                                                    | 0/10 [00:00<?, ?it/s]Testing DataLoader 0:  10%|####4                                       | 1/10 [00:00<00:01,  8.54it/s]Testing DataLoader 0:  20%|########8                                   | 2/10 [00:00<00:00,  9.37it/s]Testing DataLoader 0:  30%|#############2                              | 3/10 [00:00<00:00,  9.61it/s]Testing DataLoader 0:  40%|#################6                          | 4/10 [00:00<00:00,  9.63it/s]Testing DataLoader 0:  50%|######################                      | 5/10 [00:00<00:00,  9.66it/s]Testing DataLoader 0:  60%|##########################4                 | 6/10 [00:00<00:00,  9.50it/s]Testing DataLoader 0:  70%|##############################8             | 7/10 [00:00<00:00,  9.40it/s]Testing DataLoader 0:  80%|###################################2        | 8/10 [00:00<00:00,  9.54it/s]Testing DataLoader 0:  90%|#######################################6    | 9/10 [00:00<00:00,  9.57it/s]Testing DataLoader 0: 100%|###########################################| 10/10 [00:01<00:00,  9.65it/s]
Testing completed in 1.04 seconds or 0.02 minutes or 0.0002885744306776259 hours.

nri_test_loss: 8.2343, enc_test_loss: 8.2341, dec_test_loss: 0.0002, test_edge_accuracy: 0.9167

Edge predictions are as follows (showing probabilities for each edge type):

Rep 1,001.487:
[[5.5051135e-04 9.9944943e-01]
 [9.9996674e-01 3.3205830e-05]
 [9.9999440e-01 5.5596074e-06]
 [3.1275762e-05 9.9996877e-01]
 [1.0694078e-04 9.9989307e-01]
 [1.4015834e-04 9.9985981e-01]
 [9.9997437e-01 2.5683250e-05]
 [1.9384824e-02 9.8061520e-01]
 [2.4830314e-07 9.9999976e-01]
 [1.0000000e+00 2.4360194e-08]
 [9.9719620e-01 2.8037999e-03]
 [2.1550590e-05 9.9997842e-01]]

Rep 1,001.139:
[[3.1973750e-04 9.9968028e-01]
 [9.9913990e-01 8.6008362e-04]
 [9.9996066e-01 3.9372051e-05]
 [1.5374084e-04 9.9984622e-01]
 [9.7833054e-06 9.9999022e-01]
 [2.4245930e-04 9.9975759e-01]
 [9.9975258e-01 2.4745314e-04]
 [1.5431156e-04 9.9984562e-01]
 [1.2714889e-05 9.9998724e-01]
 [1.0000000e+00 1.1730584e-08]
 [9.8990065e-01 1.0099339e-02]
 [5.9018901e-04 9.9940979e-01]]

Rep 1,001.493:
[[4.9662072e-04 9.9950337e-01]
 [9.9999094e-01 9.0592666e-06]
 [9.9999893e-01 1.1131572e-06]
 [8.0361561e-04 9.9919635e-01]
 [1.1619391e-04 9.9988377e-01]
 [9.8202110e-04 9.9901795e-01]
 [9.9999523e-01 4.7396998e-06]
 [2.3125526e-03 9.9768746e-01]
 [4.8940724e-06 9.9999511e-01]
 [1.0000000e+00 2.5470499e-09]
 [9.9620664e-01 3.7932983e-03]
 [1.9125633e-05 9.9998093e-01]]

Rep 1,001.163:
[[5.6707789e-03 9.9432927e-01]
 [9.9981588e-01 1.8409219e-04]
 [9.9986589e-01 1.3409689e-04]
 [3.8818980e-03 9.9611807e-01]
 [1.2733242e-04 9.9987268e-01]
 [6.5535650e-04 9.9934465e-01]
 [9.9929976e-01 7.0017547e-04]
 [4.2047314e-04 9.9957949e-01]
 [3.5645506e-05 9.9996436e-01]
 [9.9999976e-01 2.2589485e-07]
 [9.9562752e-01 4.3724342e-03]
 [1.1240283e-02 9.8875976e-01]]

Rep 1,001.118:
[[6.3480239e-04 9.9936527e-01]
 [9.9797589e-01 2.0241383e-03]
 [9.9992383e-01 7.6150609e-05]
 [8.7918720e-04 9.9912077e-01]
 [3.1145610e-05 9.9996889e-01]
 [2.8407502e-03 9.9715924e-01]
 [9.9958688e-01 4.1317331e-04]
 [4.8973039e-04 9.9951029e-01]
 [4.9937047e-05 9.9995005e-01]
 [1.0000000e+00 4.8032732e-08]
 [9.9651319e-01 3.4867993e-03]
 [5.3025346e-04 9.9946982e-01]]

Rep 1,001.842:
[[1.4077458e-03 9.9859220e-01]
 [9.9876261e-01 1.2374583e-03]
 [9.9981660e-01 1.8342603e-04]
 [4.4487468e-03 9.9555123e-01]
 [1.2870498e-04 9.9987125e-01]
 [1.5686636e-03 9.9843127e-01]
 [9.9801457e-01 1.9854316e-03]
 [2.2876741e-04 9.9977130e-01]
 [2.4526023e-05 9.9997544e-01]
 [9.9999976e-01 1.9338606e-07]
 [9.9387497e-01 6.1250683e-03]
 [2.1789174e-03 9.9782109e-01]]

Rep 1,001.203:
[[2.0469185e-04 9.9979538e-01]
 [9.9978918e-01 2.1082816e-04]
 [9.9998963e-01 1.0383971e-05]
 [1.6607203e-04 9.9983394e-01]
 [7.0584123e-05 9.9992943e-01]
 [1.0133841e-03 9.9898654e-01]
 [9.9966359e-01 3.3640617e-04]
 [4.4924673e-04 9.9955076e-01]
 [2.9997175e-06 9.9999702e-01]
 [1.0000000e+00 1.2263311e-08]
 [9.9541938e-01 4.5806342e-03]
 [1.3972279e-04 9.9986029e-01]]

Rep 1,001.479:
[[4.1648224e-03 9.9583519e-01]
 [9.9997425e-01 2.5748262e-05]
 [9.9998927e-01 1.0703673e-05]
 [3.1886689e-04 9.9968112e-01]
 [5.4191914e-04 9.9945813e-01]
 [3.6351215e-03 9.9636489e-01]
 [9.9996412e-01 3.5902056e-05]
 [6.5717562e-03 9.9342817e-01]
 [9.5323145e-07 9.9999905e-01]
 [1.0000000e+00 2.7046383e-08]
 [9.9715602e-01 2.8439697e-03]
 [3.6126527e-05 9.9996388e-01]]

Rep 1,001.251:
[[4.2668828e-03 9.9573308e-01]
 [9.9942774e-01 5.7225907e-04]
 [9.9993432e-01 6.5695589e-05]
 [6.2726723e-04 9.9937278e-01]
 [6.5439977e-05 9.9993455e-01]
 [1.6166661e-03 9.9838328e-01]
 [9.9943238e-01 5.6753226e-04]
 [4.1019268e-04 9.9958986e-01]
 [1.0853652e-06 9.9999893e-01]
 [9.9999988e-01 1.2837832e-07]
 [9.8911011e-01 1.0889937e-02]
 [8.2159349e-05 9.9991786e-01]]

Rep 1,001.416:
[[1.8637637e-03 9.9813616e-01]
 [9.9999058e-01 9.4764946e-06]
 [9.9999869e-01 1.3199680e-06]
 [2.0173608e-04 9.9979824e-01]
 [8.4297353e-06 9.9999154e-01]
 [6.6635454e-05 9.9993336e-01]
 [9.9998951e-01 1.0454478e-05]
 [7.1798876e-04 9.9928206e-01]
 [3.7797481e-06 9.9999619e-01]
 [1.0000000e+00 5.6677346e-10]
 [9.9831021e-01 1.6897684e-03]
 [9.8496283e-05 9.9990153e-01]]

Rep 1,001.102:
[[1.5319312e-04 9.9984682e-01]
 [9.9899918e-01 1.0007761e-03]
 [9.9987030e-01 1.2964147e-04]
 [6.2520674e-05 9.9993753e-01]
 [4.0088496e-05 9.9995995e-01]
 [2.8535767e-04 9.9971467e-01]
 [9.9930620e-01 6.9375779e-04]
 [9.4716367e-04 9.9905282e-01]
 [9.1059874e-06 9.9999094e-01]
 [9.9999988e-01 6.3538181e-08]
 [9.9400938e-01 5.9906510e-03]
 [5.0265645e-04 9.9949729e-01]]

Rep 1,001.343:
[[5.44381328e-04 9.99455631e-01]
 [9.99962568e-01 3.74309930e-05]
 [9.99984980e-01 1.50670048e-05]
 [1.50997876e-04 9.99848962e-01]
 [1.30532469e-04 9.99869466e-01]
 [5.85726986e-04 9.99414325e-01]
 [9.99894023e-01 1.05964566e-04]
 [3.65831627e-04 9.99634147e-01]
 [1.88599859e-06 9.99998093e-01]
 [9.99999881e-01 6.54374190e-08]
 [9.93037164e-01 6.96286885e-03]
 [5.09778874e-05 9.99948978e-01]]

Rep 1,001.240:
[[3.9145249e-04 9.9960858e-01]
 [9.9989772e-01 1.0230132e-04]
 [9.9996829e-01 3.1675245e-05]
 [2.8997418e-04 9.9971002e-01]
 [8.7975299e-05 9.9991202e-01]
 [2.4583359e-04 9.9975413e-01]
 [9.9996054e-01 3.9407962e-05]
 [8.9493149e-04 9.9910504e-01]
 [1.8654239e-06 9.9999809e-01]
 [1.0000000e+00 8.7495620e-09]
 [9.9746382e-01 2.5361655e-03]
 [4.5305103e-05 9.9995470e-01]]

Rep 1,001.112:
[[1.00749475e-03 9.98992503e-01]
 [9.99656796e-01 3.43171414e-04]
 [9.99917626e-01 8.23363589e-05]
 [5.20349677e-05 9.99947906e-01]
 [1.19272394e-04 9.99880672e-01]
 [4.41593555e-04 9.99558389e-01]
 [9.97968137e-01 2.03180499e-03]
 [2.01714970e-03 9.97982860e-01]
 [8.49333901e-06 9.99991536e-01]
 [9.99999881e-01 1.12722589e-07]
 [9.97145593e-01 2.85442010e-03]
 [1.38828601e-03 9.98611689e-01]]

Rep 1,001.179:
[[3.42256739e-04 9.99657750e-01]
 [9.99235630e-01 7.64396158e-04]
 [9.99973178e-01 2.68248114e-05]
 [6.51396695e-04 9.99348581e-01]
 [5.25918076e-05 9.99947429e-01]
 [1.47517154e-03 9.98524845e-01]
 [9.99824822e-01 1.75247260e-04]
 [3.56098317e-04 9.99643922e-01]
 [9.10246217e-06 9.99990940e-01]
 [1.00000000e+00 1.28832305e-08]
 [9.98219192e-01 1.78079982e-03]
 [3.05107125e-04 9.99694943e-01]]

Rep 1,001.239:
[[1.8416817e-03 9.9815828e-01]
 [9.9964178e-01 3.5824621e-04]
 [9.9997365e-01 2.6340504e-05]
 [3.4643043e-04 9.9965358e-01]
 [1.4203468e-05 9.9998581e-01]
 [1.8728047e-04 9.9981278e-01]
 [9.9984360e-01 1.5637073e-04]
 [2.7335345e-04 9.9972659e-01]
 [6.6332706e-07 9.9999928e-01]
 [1.0000000e+00 2.9334164e-08]
 [9.9464214e-01 5.3578401e-03]
 [8.0937993e-05 9.9991906e-01]]

Rep 1,001.391:
[[1.7814855e-03 9.9821848e-01]
 [9.9998593e-01 1.4083747e-05]
 [9.9999511e-01 4.9102855e-06]
 [8.3420222e-04 9.9916577e-01]
 [2.5776200e-04 9.9974221e-01]
 [5.6250667e-04 9.9943751e-01]
 [9.9998498e-01 1.4994301e-05]
 [2.1218916e-03 9.9787807e-01]
 [6.3139754e-07 9.9999940e-01]
 [1.0000000e+00 6.9326904e-09]
 [9.9853909e-01 1.4608761e-03]
 [3.5890858e-05 9.9996412e-01]]

Rep 1,001.247:
[[6.6768948e-04 9.9933225e-01]
 [9.9994910e-01 5.0897255e-05]
 [9.9998832e-01 1.1699339e-05]
 [1.3647888e-04 9.9986351e-01]
 [2.2435632e-05 9.9997759e-01]
 [1.7418024e-04 9.9982589e-01]
 [9.9997962e-01 2.0348023e-05]
 [2.3216787e-03 9.9767834e-01]
 [7.4402175e-05 9.9992561e-01]
 [1.0000000e+00 5.5306817e-09]
 [9.9642545e-01 3.5744878e-03]
 [5.7387829e-04 9.9942613e-01]]

Rep 1,001.125:
[[1.4534486e-04 9.9985468e-01]
 [9.9943608e-01 5.6394679e-04]
 [9.9996829e-01 3.1749008e-05]
 [4.5295080e-04 9.9954706e-01]
 [1.0551325e-04 9.9989450e-01]
 [7.4701430e-04 9.9925297e-01]
 [9.9979359e-01 2.0636854e-04]
 [3.7615813e-04 9.9962378e-01]
 [6.9091234e-06 9.9999309e-01]
 [1.0000000e+00 8.9377172e-09]
 [9.9771798e-01 2.2820733e-03]
 [2.3162458e-04 9.9976844e-01]]

Rep 1,001.386:
[[4.0969107e-04 9.9959034e-01]
 [9.9998271e-01 1.7248769e-05]
 [9.9999142e-01 8.5904067e-06]
 [1.9996731e-04 9.9980003e-01]
 [1.5377281e-04 9.9984622e-01]
 [8.4845710e-04 9.9915159e-01]
 [9.9996352e-01 3.6420417e-05]
 [2.0282038e-03 9.9797183e-01]
 [1.7489959e-06 9.9999821e-01]
 [1.0000000e+00 4.9869790e-08]
 [9.9468189e-01 5.3180484e-03]
 [7.0962531e-05 9.9992907e-01]]

Rep 1,001.330:
[[2.2596903e-03 9.9774027e-01]
 [9.9998510e-01 1.4931217e-05]
 [9.9999213e-01 7.9121082e-06]
 [3.0890803e-04 9.9969113e-01]
 [7.1143717e-05 9.9992883e-01]
 [3.0874574e-04 9.9969125e-01]
 [9.9993408e-01 6.5957225e-05]
 [4.7740788e-04 9.9952257e-01]
 [1.5670981e-06 9.9999845e-01]
 [1.0000000e+00 1.2531425e-08]
 [9.9791235e-01 2.0875968e-03]
 [1.0135179e-04 9.9989867e-01]]

Rep 1,001.202:
[[1.2090809e-04 9.9987912e-01]
 [9.9990249e-01 9.7511467e-05]
 [9.9994206e-01 5.7962287e-05]
 [7.4271324e-05 9.9992573e-01]
 [1.4311280e-04 9.9985683e-01]
 [4.4587502e-04 9.9955410e-01]
 [9.9964976e-01 3.5024455e-04]
 [5.6767667e-04 9.9943227e-01]
 [4.1854866e-05 9.9995816e-01]
 [1.0000000e+00 1.7564876e-08]
 [9.9756479e-01 2.4352507e-03]
 [1.4760821e-03 9.9852389e-01]]

Rep 1,001.149:
[[2.82775552e-04 9.99717176e-01]
 [9.99298215e-01 7.01788755e-04]
 [9.99886155e-01 1.13885515e-04]
 [9.93637950e-05 9.99900579e-01]
 [7.76540619e-05 9.99922395e-01]
 [2.69034528e-04 9.99731004e-01]
 [9.98825133e-01 1.17485411e-03]
 [4.63865144e-04 9.99536157e-01]
 [1.66994305e-05 9.99983311e-01]
 [9.99999881e-01 1.40345094e-07]
 [9.91551638e-01 8.44832696e-03]
 [1.80017692e-03 9.98199821e-01]]

Rep 1,001.208:
[[1.85330445e-03 9.98146653e-01]
 [9.99848366e-01 1.51555825e-04]
 [9.99969125e-01 3.08251765e-05]
 [4.06082108e-04 9.99593914e-01]
 [1.52319029e-04 9.99847651e-01]
 [1.04750588e-03 9.98952508e-01]
 [9.99616981e-01 3.82996106e-04]
 [5.30383142e-04 9.99469578e-01]
 [6.40835788e-06 9.99993563e-01]
 [9.99999881e-01 1.09259176e-07]
 [9.94178653e-01 5.82134444e-03]
 [1.88103149e-04 9.99811947e-01]]

Rep 1,001.219:
[[2.2605893e-03 9.9773943e-01]
 [9.9981421e-01 1.8580204e-04]
 [9.9997509e-01 2.4868874e-05]
 [2.6368808e-03 9.9736315e-01]
 [4.5430566e-05 9.9995458e-01]
 [5.9096329e-04 9.9940908e-01]
 [9.9987209e-01 1.2792340e-04]
 [7.6177216e-04 9.9923825e-01]
 [2.9299636e-06 9.9999702e-01]
 [1.0000000e+00 3.5770274e-08]
 [9.9771297e-01 2.2869848e-03]
 [2.0816810e-04 9.9979180e-01]]

Rep 1,001.397:
[[5.1896909e-04 9.9948102e-01]
 [9.9998164e-01 1.8345554e-05]
 [9.9999774e-01 2.2986051e-06]
 [2.3623646e-04 9.9976379e-01]
 [2.8848148e-05 9.9997115e-01]
 [9.0587564e-05 9.9990940e-01]
 [9.9997866e-01 2.1374692e-05]
 [1.0181483e-03 9.9898177e-01]
 [1.1008855e-06 9.9999893e-01]
 [1.0000000e+00 1.0823960e-09]
 [9.9718708e-01 2.8129257e-03]
 [2.2142673e-04 9.9977857e-01]]

Rep 1,001.224:
[[2.5381957e-04 9.9974614e-01]
 [9.9993157e-01 6.8448775e-05]
 [9.9998200e-01 1.8057968e-05]
 [7.2947289e-05 9.9992704e-01]
 [3.8041926e-05 9.9996197e-01]
 [4.1196984e-04 9.9958807e-01]
 [9.9970335e-01 2.9667441e-04]
 [2.3959343e-04 9.9976045e-01]
 [7.3145216e-06 9.9999273e-01]
 [9.9999988e-01 1.6188319e-07]
 [9.8669690e-01 1.3303130e-02]
 [2.6699083e-04 9.9973303e-01]]

Rep 1,001.204:
[[8.3210203e-04 9.9916792e-01]
 [9.9970394e-01 2.9607877e-04]
 [9.9998605e-01 1.3958419e-05]
 [1.8820255e-04 9.9981183e-01]
 [5.9890615e-05 9.9994016e-01]
 [5.9433858e-04 9.9940562e-01]
 [9.9983966e-01 1.6027293e-04]
 [1.2701221e-03 9.9872988e-01]
 [4.6121586e-06 9.9999535e-01]
 [1.0000000e+00 3.9582677e-08]
 [9.9870658e-01 1.2933698e-03]
 [2.4846024e-04 9.9975151e-01]]

Rep 1,001.459:
[[5.14584186e-04 9.99485373e-01]
 [9.99993682e-01 6.27327836e-06]
 [9.99996781e-01 3.21768880e-06]
 [1.09044195e-05 9.99989152e-01]
 [1.87751604e-04 9.99812305e-01]
 [2.13492705e-04 9.99786556e-01]
 [9.99987483e-01 1.25617016e-05]
 [1.17170606e-02 9.88282979e-01]
 [2.14462125e-06 9.99997854e-01]
 [1.00000000e+00 2.44872318e-08]
 [9.96113300e-01 3.88666708e-03]
 [1.17899262e-05 9.99988198e-01]]

Rep 1,001.399:
[[1.5829731e-04 9.9984169e-01]
 [9.9995673e-01 4.3311564e-05]
 [9.9999416e-01 5.8033311e-06]
 [7.9337900e-05 9.9992061e-01]
 [9.9302051e-05 9.9990070e-01]
 [1.5016092e-04 9.9984980e-01]
 [9.9988031e-01 1.1962115e-04]
 [2.0574704e-03 9.9794251e-01]
 [1.0260334e-06 9.9999893e-01]
 [1.0000000e+00 1.4535736e-08]
 [9.9664414e-01 3.3558381e-03]
 [1.4131551e-04 9.9985862e-01]]

Rep 1,001.225:
[[1.8977489e-03 9.9810225e-01]
 [9.9975115e-01 2.4879852e-04]
 [9.9998355e-01 1.6422513e-05]
 [1.0021219e-03 9.9899787e-01]
 [2.1523899e-04 9.9978477e-01]
 [3.1181774e-03 9.9688184e-01]
 [9.9985349e-01 1.4650251e-04]
 [5.5862445e-04 9.9944133e-01]
 [1.6508770e-06 9.9999833e-01]
 [1.0000000e+00 2.0456920e-08]
 [9.8636925e-01 1.3630717e-02]
 [6.8686917e-05 9.9993134e-01]]

Rep 1,001.289:
[[3.8283621e-04 9.9961710e-01]
 [9.9996877e-01 3.1223550e-05]
 [9.9999237e-01 7.6331607e-06]
 [1.6909346e-04 9.9983084e-01]
 [2.5274736e-05 9.9997473e-01]
 [1.6593433e-04 9.9983406e-01]
 [9.9997973e-01 2.0308031e-05]
 [5.5022497e-04 9.9944979e-01]
 [2.5349116e-06 9.9999750e-01]
 [1.0000000e+00 1.5824295e-08]
 [9.9505889e-01 4.9411613e-03]
 [1.8712891e-04 9.9981290e-01]]

Rep 1,001.254:
[[1.01328327e-03 9.98986661e-01]
 [9.99897838e-01 1.02137761e-04]
 [9.99994278e-01 5.70648172e-06]
 [1.88120903e-04 9.99811947e-01]
 [1.83679422e-05 9.99981642e-01]
 [1.44983453e-04 9.99855042e-01]
 [9.99898195e-01 1.01818216e-04]
 [2.06008190e-04 9.99794066e-01]
 [1.76218748e-06 9.99998212e-01]
 [9.99999881e-01 6.04684871e-08]
 [9.88978088e-01 1.10219782e-02]
 [7.59235845e-05 9.99924064e-01]]

Rep 1,001.134:
[[1.0523198e-03 9.9894768e-01]
 [9.9958307e-01 4.1690099e-04]
 [9.9995041e-01 4.9628423e-05]
 [3.1074497e-04 9.9968922e-01]
 [9.6347358e-06 9.9999034e-01]
 [1.8800561e-04 9.9981207e-01]
 [9.9985147e-01 1.4849640e-04]
 [1.3635487e-03 9.9863642e-01]
 [1.1005704e-04 9.9988997e-01]
 [1.0000000e+00 1.8940103e-08]
 [9.9376339e-01 6.2366654e-03]
 [1.2048038e-03 9.9879515e-01]]

Rep 1,001.429:
[[2.8041998e-04 9.9971956e-01]
 [9.9996662e-01 3.3335571e-05]
 [9.9998653e-01 1.3413730e-05]
 [1.1723215e-04 9.9988270e-01]
 [1.1990049e-04 9.9988008e-01]
 [5.0466799e-04 9.9949527e-01]
 [9.9996841e-01 3.1572890e-05]
 [6.8550318e-04 9.9931455e-01]
 [7.3801368e-07 9.9999928e-01]
 [1.0000000e+00 2.4236915e-08]
 [9.9466151e-01 5.3385394e-03]
 [2.2601458e-05 9.9997735e-01]]

Rep 1,001.343:
[[2.54720420e-04 9.99745309e-01]
 [9.99934673e-01 6.53122479e-05]
 [9.99990344e-01 9.62732338e-06]
 [2.95999722e-04 9.99703944e-01]
 [5.09232814e-05 9.99949098e-01]
 [1.65855861e-04 9.99834061e-01]
 [9.99899983e-01 1.00053134e-04]
 [5.43521193e-04 9.99456465e-01]
 [5.05084245e-06 9.99994993e-01]
 [1.00000000e+00 4.74764796e-08]
 [9.90382254e-01 9.61775053e-03]
 [9.54065399e-05 9.99904633e-01]]

Rep 1,001.460:
[[1.2375438e-03 9.9876249e-01]
 [9.9997818e-01 2.1775151e-05]
 [9.9999583e-01 4.2198867e-06]
 [8.8351296e-04 9.9911648e-01]
 [6.1221341e-05 9.9993873e-01]
 [2.4232108e-04 9.9975771e-01]
 [9.9996519e-01 3.4827979e-05]
 [1.5040153e-03 9.9849594e-01]
 [1.6256980e-07 9.9999988e-01]
 [1.0000000e+00 1.7973253e-08]
 [9.9365729e-01 6.3427077e-03]
 [9.2381542e-06 9.9999082e-01]]

Rep 1,001.492:
[[3.0325950e-04 9.9969673e-01]
 [9.9997568e-01 2.4317722e-05]
 [9.9999821e-01 1.7930817e-06]
 [4.9153979e-05 9.9995089e-01]
 [5.3275971e-06 9.9999464e-01]
 [3.3014425e-05 9.9996698e-01]
 [9.9998820e-01 1.1773881e-05]
 [3.6711342e-04 9.9963284e-01]
 [5.4526134e-07 9.9999940e-01]
 [1.0000000e+00 3.3249381e-10]
 [9.9724019e-01 2.7597921e-03]
 [5.7266891e-05 9.9994278e-01]]

Rep 1,001.278:
[[7.7410054e-04 9.9922585e-01]
 [9.9984419e-01 1.5575244e-04]
 [9.9996459e-01 3.5415640e-05]
 [4.6620102e-04 9.9953377e-01]
 [5.1328279e-05 9.9994862e-01]
 [3.1891308e-04 9.9968112e-01]
 [9.9992299e-01 7.7026729e-05]
 [9.6619944e-04 9.9903381e-01]
 [4.7729532e-06 9.9999523e-01]
 [1.0000000e+00 9.3502788e-09]
 [9.9421412e-01 5.7858475e-03]
 [4.2590327e-05 9.9995744e-01]]

Rep 1,001.117:
[[9.8270515e-04 9.9901724e-01]
 [9.9948454e-01 5.1543565e-04]
 [9.9994862e-01 5.1348208e-05]
 [1.6623457e-04 9.9983370e-01]
 [6.6259636e-05 9.9993372e-01]
 [1.2567198e-03 9.9874336e-01]
 [9.9881005e-01 1.1899866e-03]
 [8.8253342e-05 9.9991179e-01]
 [2.1329630e-05 9.9997866e-01]
 [9.9999988e-01 1.7116156e-07]
 [9.9153250e-01 8.4674731e-03]
 [1.1816702e-03 9.9881834e-01]]

Rep 1,001.429:
[[4.2277640e-03 9.9577218e-01]
 [9.9997020e-01 2.9765959e-05]
 [9.9998665e-01 1.3331347e-05]
 [1.8118542e-04 9.9981886e-01]
 [2.1855732e-04 9.9978143e-01]
 [1.8619205e-03 9.9813807e-01]
 [9.9994540e-01 5.4566270e-05]
 [8.2099270e-03 9.9179006e-01]
 [4.7479469e-07 9.9999952e-01]
 [1.0000000e+00 4.6407216e-08]
 [9.9737984e-01 2.6201799e-03]
 [1.8871786e-05 9.9998116e-01]]

Rep 1,001.188:
[[2.8463737e-03 9.9715364e-01]
 [9.9989641e-01 1.0357848e-04]
 [9.9999523e-01 4.7776030e-06]
 [1.3754403e-04 9.9986243e-01]
 [7.1108757e-06 9.9999285e-01]
 [1.5976425e-04 9.9984026e-01]
 [9.9987161e-01 1.2843037e-04]
 [2.8035129e-04 9.9971968e-01]
 [2.3170280e-05 9.9997687e-01]
 [1.0000000e+00 4.2916528e-09]
 [9.9686182e-01 3.1382502e-03]
 [1.4741956e-03 9.9852580e-01]]

Rep 1,001.197:
[[2.3281755e-04 9.9976724e-01]
 [9.9976867e-01 2.3132531e-04]
 [9.9998391e-01 1.6133918e-05]
 [9.1016867e-05 9.9990892e-01]
 [1.4177998e-05 9.9998581e-01]
 [9.1101974e-05 9.9990892e-01]
 [9.9983728e-01 1.6275333e-04]
 [1.2702923e-04 9.9987292e-01]
 [2.9371395e-06 9.9999702e-01]
 [1.0000000e+00 5.4147988e-09]
 [9.7658896e-01 2.3411063e-02]
 [5.1568775e-04 9.9948430e-01]]

Rep 1,001.251:
[[2.5348729e-04 9.9974650e-01]
 [9.9452037e-01 5.4796385e-03]
 [9.9803454e-01 1.9654834e-03]
 [8.7630696e-04 9.9912375e-01]
 [1.6693666e-04 9.9983299e-01]
 [1.9913001e-03 9.9800867e-01]
 [9.9576062e-01 4.2394390e-03]
 [8.2238007e-04 9.9917763e-01]
 [8.5018175e-05 9.9991500e-01]
 [9.9999845e-01 1.5335814e-06]
 [9.9080557e-01 9.1944067e-03]
 [7.5851409e-03 9.9241489e-01]]

Rep 1,001.449:
[[4.8746719e-04 9.9951255e-01]
 [9.9999321e-01 6.7997707e-06]
 [9.9999821e-01 1.7904125e-06]
 [6.4661610e-05 9.9993539e-01]
 [1.7699305e-04 9.9982303e-01]
 [4.3887796e-04 9.9956113e-01]
 [9.9997187e-01 2.8133285e-05]
 [3.8893211e-03 9.9611074e-01]
 [4.9197447e-06 9.9999511e-01]
 [1.0000000e+00 4.3901114e-08]
 [9.9648094e-01 3.5190163e-03]
 [8.1240258e-05 9.9991870e-01]]

Rep 1,001.250:
[[4.5783832e-04 9.9954224e-01]
 [9.9997246e-01 2.7507531e-05]
 [9.9997771e-01 2.2328075e-05]
 [2.8196228e-04 9.9971801e-01]
 [6.5593056e-05 9.9993443e-01]
 [1.5516025e-04 9.9984479e-01]
 [9.9995816e-01 4.1884330e-05]
 [1.3524739e-03 9.9864751e-01]
 [2.4894266e-06 9.9999750e-01]
 [1.0000000e+00 1.9876600e-08]
 [9.9685150e-01 3.1485106e-03]
 [3.4235494e-04 9.9965763e-01]]

Rep 1,001.140:
[[2.7990632e-03 9.9720097e-01]
 [9.9952960e-01 4.7036598e-04]
 [9.9995720e-01 4.2811113e-05]
 [1.1810183e-04 9.9988186e-01]
 [4.8561244e-05 9.9995148e-01]
 [3.6197840e-04 9.9963796e-01]
 [9.9962044e-01 3.7949215e-04]
 [8.2918664e-04 9.9917090e-01]
 [1.0713263e-05 9.9998927e-01]
 [9.9999988e-01 1.6427450e-07]
 [9.9734539e-01 2.6545953e-03]
 [7.9231785e-04 9.9920768e-01]]

Rep 1,001.276:
[[4.92504565e-04 9.99507546e-01]
 [9.99830723e-01 1.69264298e-04]
 [9.99985695e-01 1.43230327e-05]
 [3.12441203e-04 9.99687552e-01]
 [1.04805105e-04 9.99895215e-01]
 [1.35202194e-03 9.98647988e-01]
 [9.99610603e-01 3.89462599e-04]
 [5.25318203e-04 9.99474704e-01]
 [9.08073525e-06 9.99990940e-01]
 [9.99999881e-01 7.05215015e-08]
 [9.97796893e-01 2.20316881e-03]
 [2.48579890e-04 9.99751389e-01]]

Rep 1,001.419:
[[7.4700109e-04 9.9925297e-01]
 [9.9997187e-01 2.8076358e-05]
 [9.9999726e-01 2.7789381e-06]
 [2.7865672e-04 9.9972135e-01]
 [8.8453358e-05 9.9991155e-01]
 [5.6310184e-04 9.9943691e-01]
 [9.9997938e-01 2.0671981e-05]
 [2.7153301e-03 9.9728465e-01]
 [1.2351409e-06 9.9999881e-01]
 [1.0000000e+00 1.2192224e-08]
 [9.9648094e-01 3.5190834e-03]
 [2.1478761e-05 9.9997854e-01]]

Rep 1,001.396:
[[1.9229917e-03 9.9807703e-01]
 [9.9997628e-01 2.3773726e-05]
 [9.9996817e-01 3.1815507e-05]
 [3.3484568e-04 9.9966514e-01]
 [1.2628212e-04 9.9987376e-01]
 [2.5999721e-04 9.9973994e-01]
 [9.9999022e-01 9.7238762e-06]
 [2.2379351e-03 9.9776208e-01]
 [1.1561521e-06 9.9999881e-01]
 [1.0000000e+00 3.5787945e-08]
 [9.6225601e-01 3.7744045e-02]
 [7.7076176e-05 9.9992287e-01]]

Adjacency matrix from edge pred is as follows:

Rep 1,001.487:
[[[0.0000000e+00 0.0000000e+00]
  [5.5051135e-04 9.9944943e-01]
  [9.9996674e-01 3.3205830e-05]
  [9.9999440e-01 5.5596074e-06]]

 [[3.1275762e-05 9.9996877e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.0694078e-04 9.9989307e-01]
  [1.4015834e-04 9.9985981e-01]]

 [[9.9997437e-01 2.5683250e-05]
  [1.9384824e-02 9.8061520e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.4830314e-07 9.9999976e-01]]

 [[1.0000000e+00 2.4360194e-08]
  [9.9719620e-01 2.8037999e-03]
  [2.1550590e-05 9.9997842e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.139:
[[[0.0000000e+00 0.0000000e+00]
  [3.1973750e-04 9.9968028e-01]
  [9.9913990e-01 8.6008362e-04]
  [9.9996066e-01 3.9372051e-05]]

 [[1.5374084e-04 9.9984622e-01]
  [0.0000000e+00 0.0000000e+00]
  [9.7833054e-06 9.9999022e-01]
  [2.4245930e-04 9.9975759e-01]]

 [[9.9975258e-01 2.4745314e-04]
  [1.5431156e-04 9.9984562e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.2714889e-05 9.9998724e-01]]

 [[1.0000000e+00 1.1730584e-08]
  [9.8990065e-01 1.0099339e-02]
  [5.9018901e-04 9.9940979e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.493:
[[[0.0000000e+00 0.0000000e+00]
  [4.9662072e-04 9.9950337e-01]
  [9.9999094e-01 9.0592666e-06]
  [9.9999893e-01 1.1131572e-06]]

 [[8.0361561e-04 9.9919635e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.1619391e-04 9.9988377e-01]
  [9.8202110e-04 9.9901795e-01]]

 [[9.9999523e-01 4.7396998e-06]
  [2.3125526e-03 9.9768746e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.8940724e-06 9.9999511e-01]]

 [[1.0000000e+00 2.5470499e-09]
  [9.9620664e-01 3.7932983e-03]
  [1.9125633e-05 9.9998093e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.163:
[[[0.0000000e+00 0.0000000e+00]
  [5.6707789e-03 9.9432927e-01]
  [9.9981588e-01 1.8409219e-04]
  [9.9986589e-01 1.3409689e-04]]

 [[3.8818980e-03 9.9611807e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.2733242e-04 9.9987268e-01]
  [6.5535650e-04 9.9934465e-01]]

 [[9.9929976e-01 7.0017547e-04]
  [4.2047314e-04 9.9957949e-01]
  [0.0000000e+00 0.0000000e+00]
  [3.5645506e-05 9.9996436e-01]]

 [[9.9999976e-01 2.2589485e-07]
  [9.9562752e-01 4.3724342e-03]
  [1.1240283e-02 9.8875976e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.118:
[[[0.0000000e+00 0.0000000e+00]
  [6.3480239e-04 9.9936527e-01]
  [9.9797589e-01 2.0241383e-03]
  [9.9992383e-01 7.6150609e-05]]

 [[8.7918720e-04 9.9912077e-01]
  [0.0000000e+00 0.0000000e+00]
  [3.1145610e-05 9.9996889e-01]
  [2.8407502e-03 9.9715924e-01]]

 [[9.9958688e-01 4.1317331e-04]
  [4.8973039e-04 9.9951029e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.9937047e-05 9.9995005e-01]]

 [[1.0000000e+00 4.8032732e-08]
  [9.9651319e-01 3.4867993e-03]
  [5.3025346e-04 9.9946982e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.842:
[[[0.0000000e+00 0.0000000e+00]
  [1.4077458e-03 9.9859220e-01]
  [9.9876261e-01 1.2374583e-03]
  [9.9981660e-01 1.8342603e-04]]

 [[4.4487468e-03 9.9555123e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.2870498e-04 9.9987125e-01]
  [1.5686636e-03 9.9843127e-01]]

 [[9.9801457e-01 1.9854316e-03]
  [2.2876741e-04 9.9977130e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.4526023e-05 9.9997544e-01]]

 [[9.9999976e-01 1.9338606e-07]
  [9.9387497e-01 6.1250683e-03]
  [2.1789174e-03 9.9782109e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.203:
[[[0.0000000e+00 0.0000000e+00]
  [2.0469185e-04 9.9979538e-01]
  [9.9978918e-01 2.1082816e-04]
  [9.9998963e-01 1.0383971e-05]]

 [[1.6607203e-04 9.9983394e-01]
  [0.0000000e+00 0.0000000e+00]
  [7.0584123e-05 9.9992943e-01]
  [1.0133841e-03 9.9898654e-01]]

 [[9.9966359e-01 3.3640617e-04]
  [4.4924673e-04 9.9955076e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.9997175e-06 9.9999702e-01]]

 [[1.0000000e+00 1.2263311e-08]
  [9.9541938e-01 4.5806342e-03]
  [1.3972279e-04 9.9986029e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.479:
[[[0.0000000e+00 0.0000000e+00]
  [4.1648224e-03 9.9583519e-01]
  [9.9997425e-01 2.5748262e-05]
  [9.9998927e-01 1.0703673e-05]]

 [[3.1886689e-04 9.9968112e-01]
  [0.0000000e+00 0.0000000e+00]
  [5.4191914e-04 9.9945813e-01]
  [3.6351215e-03 9.9636489e-01]]

 [[9.9996412e-01 3.5902056e-05]
  [6.5717562e-03 9.9342817e-01]
  [0.0000000e+00 0.0000000e+00]
  [9.5323145e-07 9.9999905e-01]]

 [[1.0000000e+00 2.7046383e-08]
  [9.9715602e-01 2.8439697e-03]
  [3.6126527e-05 9.9996388e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.251:
[[[0.0000000e+00 0.0000000e+00]
  [4.2668828e-03 9.9573308e-01]
  [9.9942774e-01 5.7225907e-04]
  [9.9993432e-01 6.5695589e-05]]

 [[6.2726723e-04 9.9937278e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.5439977e-05 9.9993455e-01]
  [1.6166661e-03 9.9838328e-01]]

 [[9.9943238e-01 5.6753226e-04]
  [4.1019268e-04 9.9958986e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.0853652e-06 9.9999893e-01]]

 [[9.9999988e-01 1.2837832e-07]
  [9.8911011e-01 1.0889937e-02]
  [8.2159349e-05 9.9991786e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.416:
[[[0.0000000e+00 0.0000000e+00]
  [1.8637637e-03 9.9813616e-01]
  [9.9999058e-01 9.4764946e-06]
  [9.9999869e-01 1.3199680e-06]]

 [[2.0173608e-04 9.9979824e-01]
  [0.0000000e+00 0.0000000e+00]
  [8.4297353e-06 9.9999154e-01]
  [6.6635454e-05 9.9993336e-01]]

 [[9.9998951e-01 1.0454478e-05]
  [7.1798876e-04 9.9928206e-01]
  [0.0000000e+00 0.0000000e+00]
  [3.7797481e-06 9.9999619e-01]]

 [[1.0000000e+00 5.6677346e-10]
  [9.9831021e-01 1.6897684e-03]
  [9.8496283e-05 9.9990153e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.102:
[[[0.0000000e+00 0.0000000e+00]
  [1.5319312e-04 9.9984682e-01]
  [9.9899918e-01 1.0007761e-03]
  [9.9987030e-01 1.2964147e-04]]

 [[6.2520674e-05 9.9993753e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.0088496e-05 9.9995995e-01]
  [2.8535767e-04 9.9971467e-01]]

 [[9.9930620e-01 6.9375779e-04]
  [9.4716367e-04 9.9905282e-01]
  [0.0000000e+00 0.0000000e+00]
  [9.1059874e-06 9.9999094e-01]]

 [[9.9999988e-01 6.3538181e-08]
  [9.9400938e-01 5.9906510e-03]
  [5.0265645e-04 9.9949729e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.343:
[[[0.00000000e+00 0.00000000e+00]
  [5.44381328e-04 9.99455631e-01]
  [9.99962568e-01 3.74309930e-05]
  [9.99984980e-01 1.50670048e-05]]

 [[1.50997876e-04 9.99848962e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.30532469e-04 9.99869466e-01]
  [5.85726986e-04 9.99414325e-01]]

 [[9.99894023e-01 1.05964566e-04]
  [3.65831627e-04 9.99634147e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.88599859e-06 9.99998093e-01]]

 [[9.99999881e-01 6.54374190e-08]
  [9.93037164e-01 6.96286885e-03]
  [5.09778874e-05 9.99948978e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.240:
[[[0.0000000e+00 0.0000000e+00]
  [3.9145249e-04 9.9960858e-01]
  [9.9989772e-01 1.0230132e-04]
  [9.9996829e-01 3.1675245e-05]]

 [[2.8997418e-04 9.9971002e-01]
  [0.0000000e+00 0.0000000e+00]
  [8.7975299e-05 9.9991202e-01]
  [2.4583359e-04 9.9975413e-01]]

 [[9.9996054e-01 3.9407962e-05]
  [8.9493149e-04 9.9910504e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.8654239e-06 9.9999809e-01]]

 [[1.0000000e+00 8.7495620e-09]
  [9.9746382e-01 2.5361655e-03]
  [4.5305103e-05 9.9995470e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.112:
[[[0.00000000e+00 0.00000000e+00]
  [1.00749475e-03 9.98992503e-01]
  [9.99656796e-01 3.43171414e-04]
  [9.99917626e-01 8.23363589e-05]]

 [[5.20349677e-05 9.99947906e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.19272394e-04 9.99880672e-01]
  [4.41593555e-04 9.99558389e-01]]

 [[9.97968137e-01 2.03180499e-03]
  [2.01714970e-03 9.97982860e-01]
  [0.00000000e+00 0.00000000e+00]
  [8.49333901e-06 9.99991536e-01]]

 [[9.99999881e-01 1.12722589e-07]
  [9.97145593e-01 2.85442010e-03]
  [1.38828601e-03 9.98611689e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.179:
[[[0.00000000e+00 0.00000000e+00]
  [3.42256739e-04 9.99657750e-01]
  [9.99235630e-01 7.64396158e-04]
  [9.99973178e-01 2.68248114e-05]]

 [[6.51396695e-04 9.99348581e-01]
  [0.00000000e+00 0.00000000e+00]
  [5.25918076e-05 9.99947429e-01]
  [1.47517154e-03 9.98524845e-01]]

 [[9.99824822e-01 1.75247260e-04]
  [3.56098317e-04 9.99643922e-01]
  [0.00000000e+00 0.00000000e+00]
  [9.10246217e-06 9.99990940e-01]]

 [[1.00000000e+00 1.28832305e-08]
  [9.98219192e-01 1.78079982e-03]
  [3.05107125e-04 9.99694943e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.239:
[[[0.0000000e+00 0.0000000e+00]
  [1.8416817e-03 9.9815828e-01]
  [9.9964178e-01 3.5824621e-04]
  [9.9997365e-01 2.6340504e-05]]

 [[3.4643043e-04 9.9965358e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.4203468e-05 9.9998581e-01]
  [1.8728047e-04 9.9981278e-01]]

 [[9.9984360e-01 1.5637073e-04]
  [2.7335345e-04 9.9972659e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.6332706e-07 9.9999928e-01]]

 [[1.0000000e+00 2.9334164e-08]
  [9.9464214e-01 5.3578401e-03]
  [8.0937993e-05 9.9991906e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.391:
[[[0.0000000e+00 0.0000000e+00]
  [1.7814855e-03 9.9821848e-01]
  [9.9998593e-01 1.4083747e-05]
  [9.9999511e-01 4.9102855e-06]]

 [[8.3420222e-04 9.9916577e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.5776200e-04 9.9974221e-01]
  [5.6250667e-04 9.9943751e-01]]

 [[9.9998498e-01 1.4994301e-05]
  [2.1218916e-03 9.9787807e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.3139754e-07 9.9999940e-01]]

 [[1.0000000e+00 6.9326904e-09]
  [9.9853909e-01 1.4608761e-03]
  [3.5890858e-05 9.9996412e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.247:
[[[0.0000000e+00 0.0000000e+00]
  [6.6768948e-04 9.9933225e-01]
  [9.9994910e-01 5.0897255e-05]
  [9.9998832e-01 1.1699339e-05]]

 [[1.3647888e-04 9.9986351e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.2435632e-05 9.9997759e-01]
  [1.7418024e-04 9.9982589e-01]]

 [[9.9997962e-01 2.0348023e-05]
  [2.3216787e-03 9.9767834e-01]
  [0.0000000e+00 0.0000000e+00]
  [7.4402175e-05 9.9992561e-01]]

 [[1.0000000e+00 5.5306817e-09]
  [9.9642545e-01 3.5744878e-03]
  [5.7387829e-04 9.9942613e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.125:
[[[0.0000000e+00 0.0000000e+00]
  [1.4534486e-04 9.9985468e-01]
  [9.9943608e-01 5.6394679e-04]
  [9.9996829e-01 3.1749008e-05]]

 [[4.5295080e-04 9.9954706e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.0551325e-04 9.9989450e-01]
  [7.4701430e-04 9.9925297e-01]]

 [[9.9979359e-01 2.0636854e-04]
  [3.7615813e-04 9.9962378e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.9091234e-06 9.9999309e-01]]

 [[1.0000000e+00 8.9377172e-09]
  [9.9771798e-01 2.2820733e-03]
  [2.3162458e-04 9.9976844e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.386:
[[[0.0000000e+00 0.0000000e+00]
  [4.0969107e-04 9.9959034e-01]
  [9.9998271e-01 1.7248769e-05]
  [9.9999142e-01 8.5904067e-06]]

 [[1.9996731e-04 9.9980003e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.5377281e-04 9.9984622e-01]
  [8.4845710e-04 9.9915159e-01]]

 [[9.9996352e-01 3.6420417e-05]
  [2.0282038e-03 9.9797183e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.7489959e-06 9.9999821e-01]]

 [[1.0000000e+00 4.9869790e-08]
  [9.9468189e-01 5.3180484e-03]
  [7.0962531e-05 9.9992907e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.330:
[[[0.0000000e+00 0.0000000e+00]
  [2.2596903e-03 9.9774027e-01]
  [9.9998510e-01 1.4931217e-05]
  [9.9999213e-01 7.9121082e-06]]

 [[3.0890803e-04 9.9969113e-01]
  [0.0000000e+00 0.0000000e+00]
  [7.1143717e-05 9.9992883e-01]
  [3.0874574e-04 9.9969125e-01]]

 [[9.9993408e-01 6.5957225e-05]
  [4.7740788e-04 9.9952257e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.5670981e-06 9.9999845e-01]]

 [[1.0000000e+00 1.2531425e-08]
  [9.9791235e-01 2.0875968e-03]
  [1.0135179e-04 9.9989867e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.202:
[[[0.0000000e+00 0.0000000e+00]
  [1.2090809e-04 9.9987912e-01]
  [9.9990249e-01 9.7511467e-05]
  [9.9994206e-01 5.7962287e-05]]

 [[7.4271324e-05 9.9992573e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.4311280e-04 9.9985683e-01]
  [4.4587502e-04 9.9955410e-01]]

 [[9.9964976e-01 3.5024455e-04]
  [5.6767667e-04 9.9943227e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.1854866e-05 9.9995816e-01]]

 [[1.0000000e+00 1.7564876e-08]
  [9.9756479e-01 2.4352507e-03]
  [1.4760821e-03 9.9852389e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.149:
[[[0.00000000e+00 0.00000000e+00]
  [2.82775552e-04 9.99717176e-01]
  [9.99298215e-01 7.01788755e-04]
  [9.99886155e-01 1.13885515e-04]]

 [[9.93637950e-05 9.99900579e-01]
  [0.00000000e+00 0.00000000e+00]
  [7.76540619e-05 9.99922395e-01]
  [2.69034528e-04 9.99731004e-01]]

 [[9.98825133e-01 1.17485411e-03]
  [4.63865144e-04 9.99536157e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.66994305e-05 9.99983311e-01]]

 [[9.99999881e-01 1.40345094e-07]
  [9.91551638e-01 8.44832696e-03]
  [1.80017692e-03 9.98199821e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.208:
[[[0.00000000e+00 0.00000000e+00]
  [1.85330445e-03 9.98146653e-01]
  [9.99848366e-01 1.51555825e-04]
  [9.99969125e-01 3.08251765e-05]]

 [[4.06082108e-04 9.99593914e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.52319029e-04 9.99847651e-01]
  [1.04750588e-03 9.98952508e-01]]

 [[9.99616981e-01 3.82996106e-04]
  [5.30383142e-04 9.99469578e-01]
  [0.00000000e+00 0.00000000e+00]
  [6.40835788e-06 9.99993563e-01]]

 [[9.99999881e-01 1.09259176e-07]
  [9.94178653e-01 5.82134444e-03]
  [1.88103149e-04 9.99811947e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.219:
[[[0.0000000e+00 0.0000000e+00]
  [2.2605893e-03 9.9773943e-01]
  [9.9981421e-01 1.8580204e-04]
  [9.9997509e-01 2.4868874e-05]]

 [[2.6368808e-03 9.9736315e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.5430566e-05 9.9995458e-01]
  [5.9096329e-04 9.9940908e-01]]

 [[9.9987209e-01 1.2792340e-04]
  [7.6177216e-04 9.9923825e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.9299636e-06 9.9999702e-01]]

 [[1.0000000e+00 3.5770274e-08]
  [9.9771297e-01 2.2869848e-03]
  [2.0816810e-04 9.9979180e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.397:
[[[0.0000000e+00 0.0000000e+00]
  [5.1896909e-04 9.9948102e-01]
  [9.9998164e-01 1.8345554e-05]
  [9.9999774e-01 2.2986051e-06]]

 [[2.3623646e-04 9.9976379e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.8848148e-05 9.9997115e-01]
  [9.0587564e-05 9.9990940e-01]]

 [[9.9997866e-01 2.1374692e-05]
  [1.0181483e-03 9.9898177e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.1008855e-06 9.9999893e-01]]

 [[1.0000000e+00 1.0823960e-09]
  [9.9718708e-01 2.8129257e-03]
  [2.2142673e-04 9.9977857e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.224:
[[[0.0000000e+00 0.0000000e+00]
  [2.5381957e-04 9.9974614e-01]
  [9.9993157e-01 6.8448775e-05]
  [9.9998200e-01 1.8057968e-05]]

 [[7.2947289e-05 9.9992704e-01]
  [0.0000000e+00 0.0000000e+00]
  [3.8041926e-05 9.9996197e-01]
  [4.1196984e-04 9.9958807e-01]]

 [[9.9970335e-01 2.9667441e-04]
  [2.3959343e-04 9.9976045e-01]
  [0.0000000e+00 0.0000000e+00]
  [7.3145216e-06 9.9999273e-01]]

 [[9.9999988e-01 1.6188319e-07]
  [9.8669690e-01 1.3303130e-02]
  [2.6699083e-04 9.9973303e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.204:
[[[0.0000000e+00 0.0000000e+00]
  [8.3210203e-04 9.9916792e-01]
  [9.9970394e-01 2.9607877e-04]
  [9.9998605e-01 1.3958419e-05]]

 [[1.8820255e-04 9.9981183e-01]
  [0.0000000e+00 0.0000000e+00]
  [5.9890615e-05 9.9994016e-01]
  [5.9433858e-04 9.9940562e-01]]

 [[9.9983966e-01 1.6027293e-04]
  [1.2701221e-03 9.9872988e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.6121586e-06 9.9999535e-01]]

 [[1.0000000e+00 3.9582677e-08]
  [9.9870658e-01 1.2933698e-03]
  [2.4846024e-04 9.9975151e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.459:
[[[0.00000000e+00 0.00000000e+00]
  [5.14584186e-04 9.99485373e-01]
  [9.99993682e-01 6.27327836e-06]
  [9.99996781e-01 3.21768880e-06]]

 [[1.09044195e-05 9.99989152e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.87751604e-04 9.99812305e-01]
  [2.13492705e-04 9.99786556e-01]]

 [[9.99987483e-01 1.25617016e-05]
  [1.17170606e-02 9.88282979e-01]
  [0.00000000e+00 0.00000000e+00]
  [2.14462125e-06 9.99997854e-01]]

 [[1.00000000e+00 2.44872318e-08]
  [9.96113300e-01 3.88666708e-03]
  [1.17899262e-05 9.99988198e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.399:
[[[0.0000000e+00 0.0000000e+00]
  [1.5829731e-04 9.9984169e-01]
  [9.9995673e-01 4.3311564e-05]
  [9.9999416e-01 5.8033311e-06]]

 [[7.9337900e-05 9.9992061e-01]
  [0.0000000e+00 0.0000000e+00]
  [9.9302051e-05 9.9990070e-01]
  [1.5016092e-04 9.9984980e-01]]

 [[9.9988031e-01 1.1962115e-04]
  [2.0574704e-03 9.9794251e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.0260334e-06 9.9999893e-01]]

 [[1.0000000e+00 1.4535736e-08]
  [9.9664414e-01 3.3558381e-03]
  [1.4131551e-04 9.9985862e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.225:
[[[0.0000000e+00 0.0000000e+00]
  [1.8977489e-03 9.9810225e-01]
  [9.9975115e-01 2.4879852e-04]
  [9.9998355e-01 1.6422513e-05]]

 [[1.0021219e-03 9.9899787e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.1523899e-04 9.9978477e-01]
  [3.1181774e-03 9.9688184e-01]]

 [[9.9985349e-01 1.4650251e-04]
  [5.5862445e-04 9.9944133e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.6508770e-06 9.9999833e-01]]

 [[1.0000000e+00 2.0456920e-08]
  [9.8636925e-01 1.3630717e-02]
  [6.8686917e-05 9.9993134e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.289:
[[[0.0000000e+00 0.0000000e+00]
  [3.8283621e-04 9.9961710e-01]
  [9.9996877e-01 3.1223550e-05]
  [9.9999237e-01 7.6331607e-06]]

 [[1.6909346e-04 9.9983084e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.5274736e-05 9.9997473e-01]
  [1.6593433e-04 9.9983406e-01]]

 [[9.9997973e-01 2.0308031e-05]
  [5.5022497e-04 9.9944979e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.5349116e-06 9.9999750e-01]]

 [[1.0000000e+00 1.5824295e-08]
  [9.9505889e-01 4.9411613e-03]
  [1.8712891e-04 9.9981290e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.254:
[[[0.00000000e+00 0.00000000e+00]
  [1.01328327e-03 9.98986661e-01]
  [9.99897838e-01 1.02137761e-04]
  [9.99994278e-01 5.70648172e-06]]

 [[1.88120903e-04 9.99811947e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.83679422e-05 9.99981642e-01]
  [1.44983453e-04 9.99855042e-01]]

 [[9.99898195e-01 1.01818216e-04]
  [2.06008190e-04 9.99794066e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.76218748e-06 9.99998212e-01]]

 [[9.99999881e-01 6.04684871e-08]
  [9.88978088e-01 1.10219782e-02]
  [7.59235845e-05 9.99924064e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.134:
[[[0.0000000e+00 0.0000000e+00]
  [1.0523198e-03 9.9894768e-01]
  [9.9958307e-01 4.1690099e-04]
  [9.9995041e-01 4.9628423e-05]]

 [[3.1074497e-04 9.9968922e-01]
  [0.0000000e+00 0.0000000e+00]
  [9.6347358e-06 9.9999034e-01]
  [1.8800561e-04 9.9981207e-01]]

 [[9.9985147e-01 1.4849640e-04]
  [1.3635487e-03 9.9863642e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.1005704e-04 9.9988997e-01]]

 [[1.0000000e+00 1.8940103e-08]
  [9.9376339e-01 6.2366654e-03]
  [1.2048038e-03 9.9879515e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.429:
[[[0.0000000e+00 0.0000000e+00]
  [2.8041998e-04 9.9971956e-01]
  [9.9996662e-01 3.3335571e-05]
  [9.9998653e-01 1.3413730e-05]]

 [[1.1723215e-04 9.9988270e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.1990049e-04 9.9988008e-01]
  [5.0466799e-04 9.9949527e-01]]

 [[9.9996841e-01 3.1572890e-05]
  [6.8550318e-04 9.9931455e-01]
  [0.0000000e+00 0.0000000e+00]
  [7.3801368e-07 9.9999928e-01]]

 [[1.0000000e+00 2.4236915e-08]
  [9.9466151e-01 5.3385394e-03]
  [2.2601458e-05 9.9997735e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.343:
[[[0.00000000e+00 0.00000000e+00]
  [2.54720420e-04 9.99745309e-01]
  [9.99934673e-01 6.53122479e-05]
  [9.99990344e-01 9.62732338e-06]]

 [[2.95999722e-04 9.99703944e-01]
  [0.00000000e+00 0.00000000e+00]
  [5.09232814e-05 9.99949098e-01]
  [1.65855861e-04 9.99834061e-01]]

 [[9.99899983e-01 1.00053134e-04]
  [5.43521193e-04 9.99456465e-01]
  [0.00000000e+00 0.00000000e+00]
  [5.05084245e-06 9.99994993e-01]]

 [[1.00000000e+00 4.74764796e-08]
  [9.90382254e-01 9.61775053e-03]
  [9.54065399e-05 9.99904633e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.460:
[[[0.0000000e+00 0.0000000e+00]
  [1.2375438e-03 9.9876249e-01]
  [9.9997818e-01 2.1775151e-05]
  [9.9999583e-01 4.2198867e-06]]

 [[8.8351296e-04 9.9911648e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.1221341e-05 9.9993873e-01]
  [2.4232108e-04 9.9975771e-01]]

 [[9.9996519e-01 3.4827979e-05]
  [1.5040153e-03 9.9849594e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.6256980e-07 9.9999988e-01]]

 [[1.0000000e+00 1.7973253e-08]
  [9.9365729e-01 6.3427077e-03]
  [9.2381542e-06 9.9999082e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.492:
[[[0.0000000e+00 0.0000000e+00]
  [3.0325950e-04 9.9969673e-01]
  [9.9997568e-01 2.4317722e-05]
  [9.9999821e-01 1.7930817e-06]]

 [[4.9153979e-05 9.9995089e-01]
  [0.0000000e+00 0.0000000e+00]
  [5.3275971e-06 9.9999464e-01]
  [3.3014425e-05 9.9996698e-01]]

 [[9.9998820e-01 1.1773881e-05]
  [3.6711342e-04 9.9963284e-01]
  [0.0000000e+00 0.0000000e+00]
  [5.4526134e-07 9.9999940e-01]]

 [[1.0000000e+00 3.3249381e-10]
  [9.9724019e-01 2.7597921e-03]
  [5.7266891e-05 9.9994278e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.278:
[[[0.0000000e+00 0.0000000e+00]
  [7.7410054e-04 9.9922585e-01]
  [9.9984419e-01 1.5575244e-04]
  [9.9996459e-01 3.5415640e-05]]

 [[4.6620102e-04 9.9953377e-01]
  [0.0000000e+00 0.0000000e+00]
  [5.1328279e-05 9.9994862e-01]
  [3.1891308e-04 9.9968112e-01]]

 [[9.9992299e-01 7.7026729e-05]
  [9.6619944e-04 9.9903381e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.7729532e-06 9.9999523e-01]]

 [[1.0000000e+00 9.3502788e-09]
  [9.9421412e-01 5.7858475e-03]
  [4.2590327e-05 9.9995744e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.117:
[[[0.0000000e+00 0.0000000e+00]
  [9.8270515e-04 9.9901724e-01]
  [9.9948454e-01 5.1543565e-04]
  [9.9994862e-01 5.1348208e-05]]

 [[1.6623457e-04 9.9983370e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.6259636e-05 9.9993372e-01]
  [1.2567198e-03 9.9874336e-01]]

 [[9.9881005e-01 1.1899866e-03]
  [8.8253342e-05 9.9991179e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.1329630e-05 9.9997866e-01]]

 [[9.9999988e-01 1.7116156e-07]
  [9.9153250e-01 8.4674731e-03]
  [1.1816702e-03 9.9881834e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.429:
[[[0.0000000e+00 0.0000000e+00]
  [4.2277640e-03 9.9577218e-01]
  [9.9997020e-01 2.9765959e-05]
  [9.9998665e-01 1.3331347e-05]]

 [[1.8118542e-04 9.9981886e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.1855732e-04 9.9978143e-01]
  [1.8619205e-03 9.9813807e-01]]

 [[9.9994540e-01 5.4566270e-05]
  [8.2099270e-03 9.9179006e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.7479469e-07 9.9999952e-01]]

 [[1.0000000e+00 4.6407216e-08]
  [9.9737984e-01 2.6201799e-03]
  [1.8871786e-05 9.9998116e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.188:
[[[0.0000000e+00 0.0000000e+00]
  [2.8463737e-03 9.9715364e-01]
  [9.9989641e-01 1.0357848e-04]
  [9.9999523e-01 4.7776030e-06]]

 [[1.3754403e-04 9.9986243e-01]
  [0.0000000e+00 0.0000000e+00]
  [7.1108757e-06 9.9999285e-01]
  [1.5976425e-04 9.9984026e-01]]

 [[9.9987161e-01 1.2843037e-04]
  [2.8035129e-04 9.9971968e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.3170280e-05 9.9997687e-01]]

 [[1.0000000e+00 4.2916528e-09]
  [9.9686182e-01 3.1382502e-03]
  [1.4741956e-03 9.9852580e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.197:
[[[0.0000000e+00 0.0000000e+00]
  [2.3281755e-04 9.9976724e-01]
  [9.9976867e-01 2.3132531e-04]
  [9.9998391e-01 1.6133918e-05]]

 [[9.1016867e-05 9.9990892e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.4177998e-05 9.9998581e-01]
  [9.1101974e-05 9.9990892e-01]]

 [[9.9983728e-01 1.6275333e-04]
  [1.2702923e-04 9.9987292e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.9371395e-06 9.9999702e-01]]

 [[1.0000000e+00 5.4147988e-09]
  [9.7658896e-01 2.3411063e-02]
  [5.1568775e-04 9.9948430e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.251:
[[[0.0000000e+00 0.0000000e+00]
  [2.5348729e-04 9.9974650e-01]
  [9.9452037e-01 5.4796385e-03]
  [9.9803454e-01 1.9654834e-03]]

 [[8.7630696e-04 9.9912375e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.6693666e-04 9.9983299e-01]
  [1.9913001e-03 9.9800867e-01]]

 [[9.9576062e-01 4.2394390e-03]
  [8.2238007e-04 9.9917763e-01]
  [0.0000000e+00 0.0000000e+00]
  [8.5018175e-05 9.9991500e-01]]

 [[9.9999845e-01 1.5335814e-06]
  [9.9080557e-01 9.1944067e-03]
  [7.5851409e-03 9.9241489e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.449:
[[[0.0000000e+00 0.0000000e+00]
  [4.8746719e-04 9.9951255e-01]
  [9.9999321e-01 6.7997707e-06]
  [9.9999821e-01 1.7904125e-06]]

 [[6.4661610e-05 9.9993539e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.7699305e-04 9.9982303e-01]
  [4.3887796e-04 9.9956113e-01]]

 [[9.9997187e-01 2.8133285e-05]
  [3.8893211e-03 9.9611074e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.9197447e-06 9.9999511e-01]]

 [[1.0000000e+00 4.3901114e-08]
  [9.9648094e-01 3.5190163e-03]
  [8.1240258e-05 9.9991870e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.250:
[[[0.0000000e+00 0.0000000e+00]
  [4.5783832e-04 9.9954224e-01]
  [9.9997246e-01 2.7507531e-05]
  [9.9997771e-01 2.2328075e-05]]

 [[2.8196228e-04 9.9971801e-01]
  [0.0000000e+00 0.0000000e+00]
  [6.5593056e-05 9.9993443e-01]
  [1.5516025e-04 9.9984479e-01]]

 [[9.9995816e-01 4.1884330e-05]
  [1.3524739e-03 9.9864751e-01]
  [0.0000000e+00 0.0000000e+00]
  [2.4894266e-06 9.9999750e-01]]

 [[1.0000000e+00 1.9876600e-08]
  [9.9685150e-01 3.1485106e-03]
  [3.4235494e-04 9.9965763e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.140:
[[[0.0000000e+00 0.0000000e+00]
  [2.7990632e-03 9.9720097e-01]
  [9.9952960e-01 4.7036598e-04]
  [9.9995720e-01 4.2811113e-05]]

 [[1.1810183e-04 9.9988186e-01]
  [0.0000000e+00 0.0000000e+00]
  [4.8561244e-05 9.9995148e-01]
  [3.6197840e-04 9.9963796e-01]]

 [[9.9962044e-01 3.7949215e-04]
  [8.2918664e-04 9.9917090e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.0713263e-05 9.9998927e-01]]

 [[9.9999988e-01 1.6427450e-07]
  [9.9734539e-01 2.6545953e-03]
  [7.9231785e-04 9.9920768e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.276:
[[[0.00000000e+00 0.00000000e+00]
  [4.92504565e-04 9.99507546e-01]
  [9.99830723e-01 1.69264298e-04]
  [9.99985695e-01 1.43230327e-05]]

 [[3.12441203e-04 9.99687552e-01]
  [0.00000000e+00 0.00000000e+00]
  [1.04805105e-04 9.99895215e-01]
  [1.35202194e-03 9.98647988e-01]]

 [[9.99610603e-01 3.89462599e-04]
  [5.25318203e-04 9.99474704e-01]
  [0.00000000e+00 0.00000000e+00]
  [9.08073525e-06 9.99990940e-01]]

 [[9.99999881e-01 7.05215015e-08]
  [9.97796893e-01 2.20316881e-03]
  [2.48579890e-04 9.99751389e-01]
  [0.00000000e+00 0.00000000e+00]]]

Rep 1,001.419:
[[[0.0000000e+00 0.0000000e+00]
  [7.4700109e-04 9.9925297e-01]
  [9.9997187e-01 2.8076358e-05]
  [9.9999726e-01 2.7789381e-06]]

 [[2.7865672e-04 9.9972135e-01]
  [0.0000000e+00 0.0000000e+00]
  [8.8453358e-05 9.9991155e-01]
  [5.6310184e-04 9.9943691e-01]]

 [[9.9997938e-01 2.0671981e-05]
  [2.7153301e-03 9.9728465e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.2351409e-06 9.9999881e-01]]

 [[1.0000000e+00 1.2192224e-08]
  [9.9648094e-01 3.5190834e-03]
  [2.1478761e-05 9.9997854e-01]
  [0.0000000e+00 0.0000000e+00]]]

Rep 1,001.396:
[[[0.0000000e+00 0.0000000e+00]
  [1.9229917e-03 9.9807703e-01]
  [9.9997628e-01 2.3773726e-05]
  [9.9996817e-01 3.1815507e-05]]

 [[3.3484568e-04 9.9966514e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.2628212e-04 9.9987376e-01]
  [2.5999721e-04 9.9973994e-01]]

 [[9.9999022e-01 9.7238762e-06]
  [2.2379351e-03 9.9776208e-01]
  [0.0000000e+00 0.0000000e+00]
  [1.1561521e-06 9.9999881e-01]]

 [[1.0000000e+00 3.5787945e-08]
  [9.6225601e-01 3.7744045e-02]
  [7.7076176e-05 9.9992287e-01]
  [0.0000000e+00 0.0000000e+00]]]

Test metrics and hyperparameters logged for tensorboard at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16\test

---------------------------------------------------------------------------

<<<<<<<<<<<< DECODER OUTPUT PLOT (TEST) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.487' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16...

Decoder output plot for rep '1001.4866' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=2\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16\test

Testing DataLoader 0: 100%|###########################################| 10/10 [00:03<00:00,  3.29it/s]

        Test metric               DataLoader 0        

       dec/test_loss         0.00024981246679089963   
  enc/test_edge_accuracy       0.9166668057441711     
     enc/test_entropy         0.006974043790251017    
       enc/test_loss            8.234077453613281     
       nri/test_loss            8.23432731628418      


===========================================================================

Nri model '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_2.16' training completed.


=== EXECUTION COMPLETED ===
Log saved at: 2025-09-18 18:21:54
