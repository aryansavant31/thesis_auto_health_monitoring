=== SCRIPT EXECUTION LOG ===
Script: topology_estimation.train.py
Base Name: [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1
Start Time: 2025-09-13 16:38:02
End Time: 2025-09-13 16:39:23

CPU: Intel64 Family 6 Model 154 Stepping 3, GenuineIntel (Cores: 20), Max Frequency: 2300.00 MHz
GPUs Detected: 1
GPU 0: NVIDIA GeForce RTX 3050 Ti Laptop GPU, Memory: 4.00 GB
OS: Windows 11 (10.0.26100)

Python Version: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 12:58:53) [MSC v.1929 64 bit (AMD64)]
========================================================================================================================


Starting nri model training...

'Train' type dataset selected:


Dataset selections:
---------------------------------------------
*_(<ds_subtype_num>) <ds_subtype> : [<augments>]_*

- **Healthy configs**
  (1) series_tp    : [OG]

- **Unhealthy configs**

- **Unknown configs**


Node and signal types:
---------------------------------------------
*_(<node_num>) <node_type> : [<signal_types>]_*

  (1) mass_1   : [acc, pos, vel]
  (2) mass_2   : [acc, pos, vel]
  (3) mass_3   : [acc, pos, vel]
  (4) mass_4   : [acc, pos, vel]

Node group name: m004
Signal group name: apv


For ds_type 'OK' and others....
---------------------------------------------
Maximum timesteps across all node types: 500,001

No data interpolation applied.

'fs' is updated in data_config as given in loaded healthy (or unknown) data.
New fs:
[[500., 500., 500.],
 [500., 500., 500.],
 [500., 500., 500.],
 [500., 500., 500.]]

No exclusive rep numbers found in keys of hfd5 file. Hence, using default rep numbers.


[1 sample = (n_nodes, n_timesteps (window_length), n_dims)]
------------------------------------------------------------
Total samples: 5000 
Train: 4000/4000 [OK=4000, NOK=0, UK=0], Test: 500/500 [OK=500, NOK=0, UK=0], Val: 500/500 [OK=500, NOK=0, UK=0],
Remainder: 0 [OK=0, NOK=0, UK=0]

train_data_loader statistics:
Number of batches: 80
torch.Size([50, 4, 100, 3])  => (batch_size, n_nodes, n_timesteps, n_dims)

test_data_loader statistics:
Number of batches: 10
torch.Size([50, 4, 100, 3]) 

val_data_loader statistics:
Number of batches: 10
torch.Size([50, 4, 100, 3]) 

---------------------------------------------------------------------------

Loading Relation Matrices...

Relation Matrices loaded successfully.

## Relation Matrices Summary 

**Adjacency matrix for input** => shape: (4, 4)
     n1   n2   n3   n4
n1  0.0  1.0  1.0  1.0
n2  1.0  0.0  1.0  1.0
n3  1.0  1.0  0.0  1.0
n4  1.0  1.0  1.0  0.0


**Receiver relation matrix** => shape: (12, 4)
      n1   n2   n3   n4
e12  0.0  1.0  0.0  0.0
e13  0.0  0.0  1.0  0.0
e14  0.0  0.0  0.0  1.0
e21  1.0  0.0  0.0  0.0
e23  0.0  0.0  1.0  0.0
e24  0.0  0.0  0.0  1.0
e31  1.0  0.0  0.0  0.0
e32  0.0  1.0  0.0  0.0
e34  0.0  0.0  0.0  1.0
e41  1.0  0.0  0.0  0.0
e42  0.0  1.0  0.0  0.0
e43  0.0  0.0  1.0  0.0


**Sender relation matrix:** => shape: (12, 4)
      n1   n2   n3   n4
e12  1.0  0.0  0.0  0.0
e13  1.0  0.0  0.0  0.0
e14  1.0  0.0  0.0  0.0
e21  0.0  1.0  0.0  0.0
e23  0.0  1.0  0.0  0.0
e24  0.0  1.0  0.0  0.0
e31  0.0  0.0  1.0  0.0
e32  0.0  0.0  1.0  0.0
e34  0.0  0.0  1.0  0.0
e41  0.0  0.0  0.0  1.0
e42  0.0  0.0  0.0  1.0
e43  0.0  0.0  0.0  1.0


---------------------------------------------------------------------------

<<<<<< ENCODER PARAMETERS >>>>>>
Encoder model parameters:
-------------------------
n_edge_types: 1
is_residual_connection: True
do_prob: {'mlp': 0.0, 'cnn': 0.0}
is_batch_norm: {'mlp': False, 'cnn': False}
is_xavier_weights: False
attention_output_size: 5
domain_config: {'type': 'time', 'cutoff_freq': 0}
raw_data_norm: min_max
feat_configs: []
reduc_config: None
feat_norm: None
pipeline: [['1/node_emd.1', 'mlp'], ['1/pairwise_op', 'concat'], ['1/edge_emd.1.@', 'mlp'], ['2/aggregate', 'mean'], ['2/node_emd.1', 'mlp'], ['2/pairwise_op', 'concat'], ['2/edge_emd.1', 'mlp']]
edge_emb_configs: {'mlp': [[256, 'elu'], [256, 'elu']], 'cnn': [[5, 2, 64], [8]]}
node_emb_configs: {'mlp': [[256, 'elu'], [256, 'elu']], 'cnn': [[5, 2, 64], [8]]}
n_comps: 100
n_dims: 3

<<<<<< DECODER PARAMETERS >>>>>>

Decoder model parameters:
-------------------------
n_edge_types: 1
msg_out_size: 256
edge_mlp_config: [[256, 'tanh'], [256, 'tanh']]
out_mlp_config: [[256, 'relu'], [256, 'relu']]
do_prob: 0
is_batch_norm: False
is_xavier_weights: False
recur_emb_type: gru
domain_config: {'type': 'time', 'cutoff_freq': 0}
raw_data_norm: min_max
feat_configs: []
feat_norm: None
reduc_config: None
n_dims: 3

Decoder run parameters:
-------------------------
temp: 0.5
is_hard: True
skip_first_edge_type: False
pred_steps: 10
is_burn_in: True
final_pred_steps: 30
is_dynamic_graph: False
show_conf_band: False

Training parameters set to: 
lr=0.001, 
optimizer=adam, 
loss_type_encoder=kld, 
loss_type_decoder=mse, 
prior=None, 
add_const_kld=False

---------------------------------------------------------------------------

NRI Model Initialized with the following configurations:
----- NRI Model Summary -----
-- Encoder Summary
Encoder(
  (emb_fn_dict): ModuleDict(
    (1/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=300, out_features=256, bias=True)
        (1): ELU(alpha=1.0)
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): ELU(alpha=1.0)
      )
    )
    (1/edge_emd1@): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): ELU(alpha=1.0)
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): ELU(alpha=1.0)
      )
    )
    (2/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ELU(alpha=1.0)
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): ELU(alpha=1.0)
      )
    )
    (2/edge_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=768, out_features=256, bias=True)
        (1): ELU(alpha=1.0)
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): ELU(alpha=1.0)
      )
    )
  )
  (attention_layer_dict): ModuleDict()
  (output_layer): Linear(in_features=256, out_features=1, bias=True)
)
-- Decoder Summary
Decoder(
  (edge_mlp_fn): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Tanh()
        (2): Dropout(p=0, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): Tanh()
      )
    )
  )
  (recurrent_emb_fn): GRU(
    (input_u): Linear(in_features=3, out_features=256, bias=True)
    (hidden_u): Linear(in_features=256, out_features=256, bias=True)
    (input_r): Linear(in_features=3, out_features=256, bias=True)
    (hidden_r): Linear(in_features=256, out_features=256, bias=True)
    (input_h): Linear(in_features=3, out_features=256, bias=True)
    (hidden_h): Linear(in_features=256, out_features=256, bias=True)
  )
  (mean_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
      (2): Dropout(p=0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ReLU()
    )
  )
  (var_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): ReLU()
      (2): Dropout(p=0, inplace=False)
      (3): Linear(in_features=256, out_features=256, bias=True)
      (4): ReLU()
    )
  )
  (mean_output_layer): Linear(in_features=256, out_features=3, bias=True)
  (var_output_layer): Linear(in_features=256, out_features=3, bias=True)
)

---------------------------------------------------------------------------

'[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1' already exists in the log path 'C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1'.
(a) Overwrite exsiting version, (b) create new version, (c) stop training (Choose 'a', 'b' or 'c'):  Are you sure you want to remove the '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1' from the log path C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1? (y/n): Overwrote '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1' from the log path C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1.
Model parameters saved to C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1.

Training environment set. Training will be logged at: C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1

---------------------------------------------------------------------------

Initializing input processors for encoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Initializing input processors for decoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Training: |                                                                                          | 0/? [00:00<?, ?it/s]Training:   0%|                                                                                     | 0/80 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                      | 0/80 [00:00<?, ?it/s]Epoch 0:   1%|9                                                                             | 1/80 [00:00<00:38,  2.04it/s]Epoch 0:   1%|8                                                                 | 1/80 [00:00<00:38,  2.04it/s, v_num=_1.1]Epoch 0:   2%|#6                                                                | 2/80 [00:00<00:31,  2.46it/s, v_num=_1.1]Epoch 0:   2%|#6                                                                | 2/80 [00:00<00:31,  2.46it/s, v_num=_1.1]Epoch 0:   4%|##4                                                               | 3/80 [00:01<00:29,  2.62it/s, v_num=_1.1]Epoch 0:   4%|##4                                                               | 3/80 [00:01<00:29,  2.62it/s, v_num=_1.1]Epoch 0:   5%|###3                                                              | 4/80 [00:01<00:27,  2.73it/s, v_num=_1.1]Epoch 0:   5%|###3                                                              | 4/80 [00:01<00:27,  2.73it/s, v_num=_1.1]Epoch 0:   6%|####1                                                             | 5/80 [00:01<00:26,  2.80it/s, v_num=_1.1]Epoch 0:   6%|####1                                                             | 5/80 [00:01<00:26,  2.80it/s, v_num=_1.1]Epoch 0:   8%|####9                                                             | 6/80 [00:02<00:25,  2.88it/s, v_num=_1.1]Epoch 0:   8%|####9                                                             | 6/80 [00:02<00:25,  2.88it/s, v_num=_1.1]Epoch 0:   9%|#####7                                                            | 7/80 [00:02<00:25,  2.91it/s, v_num=_1.1]Epoch 0:   9%|#####7                                                            | 7/80 [00:02<00:25,  2.91it/s, v_num=_1.1]Epoch 0:  10%|######6                                                           | 8/80 [00:02<00:24,  2.93it/s, v_num=_1.1]Epoch 0:  10%|######6                                                           | 8/80 [00:02<00:24,  2.93it/s, v_num=_1.1]Epoch 0:  11%|#######4                                                          | 9/80 [00:03<00:24,  2.94it/s, v_num=_1.1]Epoch 0:  11%|#######4                                                          | 9/80 [00:03<00:24,  2.94it/s, v_num=_1.1]Epoch 0:  12%|########1                                                        | 10/80 [00:03<00:23,  2.95it/s, v_num=_1.1]Epoch 0:  12%|########1                                                        | 10/80 [00:03<00:23,  2.95it/s, v_num=_1.1]Epoch 0:  14%|########9                                                        | 11/80 [00:03<00:23,  2.98it/s, v_num=_1.1]Epoch 0:  14%|########9                                                        | 11/80 [00:03<00:23,  2.98it/s, v_num=_1.1]Epoch 0:  15%|#########7                                                       | 12/80 [00:03<00:22,  3.01it/s, v_num=_1.1]Epoch 0:  15%|#########7                                                       | 12/80 [00:03<00:22,  3.01it/s, v_num=_1.1]Epoch 0:  16%|##########5                                                      | 13/80 [00:04<00:22,  3.03it/s, v_num=_1.1]Epoch 0:  16%|##########5                                                      | 13/80 [00:04<00:22,  3.03it/s, v_num=_1.1]Epoch 0:  18%|###########3                                                     | 14/80 [00:04<00:21,  3.01it/s, v_num=_1.1]Epoch 0:  18%|###########3                                                     | 14/80 [00:04<00:21,  3.01it/s, v_num=_1.1]Epoch 0:  19%|############1                                                    | 15/80 [00:04<00:21,  3.04it/s, v_num=_1.1]Epoch 0:  19%|############1                                                    | 15/80 [00:04<00:21,  3.04it/s, v_num=_1.1]Epoch 0:  20%|#############                                                    | 16/80 [00:05<00:20,  3.05it/s, v_num=_1.1]Epoch 0:  20%|#############                                                    | 16/80 [00:05<00:20,  3.05it/s, v_num=_1.1]Epoch 0:  21%|#############8                                                   | 17/80 [00:05<00:20,  3.06it/s, v_num=_1.1]Epoch 0:  21%|#############8                                                   | 17/80 [00:05<00:20,  3.06it/s, v_num=_1.1]Epoch 0:  22%|##############6                                                  | 18/80 [00:05<00:20,  3.08it/s, v_num=_1.1]Epoch 0:  22%|##############6                                                  | 18/80 [00:05<00:20,  3.08it/s, v_num=_1.1]Epoch 0:  24%|###############4                                                 | 19/80 [00:06<00:19,  3.08it/s, v_num=_1.1]Epoch 0:  24%|###############4                                                 | 19/80 [00:06<00:19,  3.08it/s, v_num=_1.1]Epoch 0:  25%|################2                                                | 20/80 [00:06<00:19,  3.08it/s, v_num=_1.1]Epoch 0:  25%|################2                                                | 20/80 [00:06<00:19,  3.08it/s, v_num=_1.1]Epoch 0:  26%|#################                                                | 21/80 [00:06<00:19,  3.08it/s, v_num=_1.1]Epoch 0:  26%|#################                                                | 21/80 [00:06<00:19,  3.08it/s, v_num=_1.1]Epoch 0:  28%|#################8                                               | 22/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 0:  28%|#################8                                               | 22/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 0:  29%|##################6                                              | 23/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 0:  29%|##################6                                              | 23/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 0:  30%|###################5                                             | 24/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 0:  30%|###################5                                             | 24/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 0:  31%|####################3                                            | 25/80 [00:08<00:17,  3.08it/s, v_num=_1.1]Epoch 0:  31%|####################3                                            | 25/80 [00:08<00:17,  3.08it/s, v_num=_1.1]Epoch 0:  32%|#####################1                                           | 26/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 0:  32%|#####################1                                           | 26/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 0:  34%|#####################9                                           | 27/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 0:  34%|#####################9                                           | 27/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 0:  35%|######################7                                          | 28/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 0:  35%|######################7                                          | 28/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 0:  36%|#######################5                                         | 29/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 0:  36%|#######################5                                         | 29/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 0:  38%|########################3                                        | 30/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 0:  38%|########################3                                        | 30/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 0:  39%|#########################1                                       | 31/80 [00:09<00:15,  3.10it/s, v_num=_1.1]Epoch 0:  39%|#########################1                                       | 31/80 [00:09<00:15,  3.10it/s, v_num=_1.1]Epoch 0:  40%|##########################                                       | 32/80 [00:10<00:15,  3.10it/s, v_num=_1.1]Epoch 0:  40%|##########################                                       | 32/80 [00:10<00:15,  3.10it/s, v_num=_1.1]Epoch 0:  41%|##########################8                                      | 33/80 [00:10<00:15,  3.10it/s, v_num=_1.1]Epoch 0:  41%|##########################8                                      | 33/80 [00:10<00:15,  3.10it/s, v_num=_1.1]Epoch 0:  42%|###########################6                                     | 34/80 [00:10<00:14,  3.10it/s, v_num=_1.1]Epoch 0:  42%|###########################6                                     | 34/80 [00:10<00:14,  3.10it/s, v_num=_1.1]Epoch 0:  44%|############################4                                    | 35/80 [00:11<00:14,  3.11it/s, v_num=_1.1]Epoch 0:  44%|############################4                                    | 35/80 [00:11<00:14,  3.11it/s, v_num=_1.1]Epoch 0:  45%|#############################2                                   | 36/80 [00:11<00:14,  3.11it/s, v_num=_1.1]Epoch 0:  45%|#############################2                                   | 36/80 [00:11<00:14,  3.11it/s, v_num=_1.1]Epoch 0:  46%|##############################                                   | 37/80 [00:11<00:13,  3.11it/s, v_num=_1.1]Epoch 0:  46%|##############################                                   | 37/80 [00:11<00:13,  3.11it/s, v_num=_1.1]Epoch 0:  48%|##############################8                                  | 38/80 [00:12<00:13,  3.12it/s, v_num=_1.1]Epoch 0:  48%|##############################8                                  | 38/80 [00:12<00:13,  3.12it/s, v_num=_1.1]Epoch 0:  49%|###############################6                                 | 39/80 [00:12<00:13,  3.12it/s, v_num=_1.1]Epoch 0:  49%|###############################6                                 | 39/80 [00:12<00:13,  3.12it/s, v_num=_1.1]Epoch 0:  50%|################################5                                | 40/80 [00:12<00:12,  3.12it/s, v_num=_1.1]Epoch 0:  50%|################################5                                | 40/80 [00:12<00:12,  3.12it/s, v_num=_1.1]Epoch 0:  51%|#################################3                               | 41/80 [00:13<00:12,  3.12it/s, v_num=_1.1]Epoch 0:  51%|#################################3                               | 41/80 [00:13<00:12,  3.12it/s, v_num=_1.1]Epoch 0:  52%|##################################1                              | 42/80 [00:13<00:12,  3.12it/s, v_num=_1.1]Epoch 0:  52%|##################################1                              | 42/80 [00:13<00:12,  3.12it/s, v_num=_1.1]Epoch 0:  54%|##################################9                              | 43/80 [00:13<00:11,  3.12it/s, v_num=_1.1]Epoch 0:  54%|##################################9                              | 43/80 [00:13<00:11,  3.12it/s, v_num=_1.1]Epoch 0:  55%|###################################7                             | 44/80 [00:14<00:11,  3.12it/s, v_num=_1.1]Epoch 0:  55%|###################################7                             | 44/80 [00:14<00:11,  3.12it/s, v_num=_1.1]Epoch 0:  56%|####################################5                            | 45/80 [00:14<00:11,  3.13it/s, v_num=_1.1]Epoch 0:  56%|####################################5                            | 45/80 [00:14<00:11,  3.13it/s, v_num=_1.1]Epoch 0:  57%|#####################################3                           | 46/80 [00:14<00:10,  3.12it/s, v_num=_1.1]Epoch 0:  57%|#####################################3                           | 46/80 [00:14<00:10,  3.12it/s, v_num=_1.1]Epoch 0:  59%|######################################1                          | 47/80 [00:15<00:10,  3.12it/s, v_num=_1.1]Epoch 0:  59%|######################################1                          | 47/80 [00:15<00:10,  3.12it/s, v_num=_1.1]Epoch 0:  60%|#######################################                          | 48/80 [00:15<00:10,  3.12it/s, v_num=_1.1]Epoch 0:  60%|#######################################                          | 48/80 [00:15<00:10,  3.12it/s, v_num=_1.1]Epoch 0:  61%|#######################################8                         | 49/80 [00:15<00:09,  3.12it/s, v_num=_1.1]Epoch 0:  61%|#######################################8                         | 49/80 [00:15<00:09,  3.12it/s, v_num=_1.1]Epoch 0:  62%|########################################6                        | 50/80 [00:15<00:09,  3.13it/s, v_num=_1.1]Epoch 0:  62%|########################################6                        | 50/80 [00:15<00:09,  3.13it/s, v_num=_1.1]Epoch 0:  64%|#########################################4                       | 51/80 [00:16<00:09,  3.13it/s, v_num=_1.1]Epoch 0:  64%|#########################################4                       | 51/80 [00:16<00:09,  3.13it/s, v_num=_1.1]Epoch 0:  65%|##########################################2                      | 52/80 [00:16<00:08,  3.12it/s, v_num=_1.1]Epoch 0:  65%|##########################################2                      | 52/80 [00:16<00:08,  3.12it/s, v_num=_1.1]Epoch 0:  66%|###########################################                      | 53/80 [00:16<00:08,  3.13it/s, v_num=_1.1]Epoch 0:  66%|###########################################                      | 53/80 [00:16<00:08,  3.13it/s, v_num=_1.1]Epoch 0:  68%|###########################################8                     | 54/80 [00:17<00:08,  3.13it/s, v_num=_1.1]Epoch 0:  68%|###########################################8                     | 54/80 [00:17<00:08,  3.13it/s, v_num=_1.1]Epoch 0:  69%|############################################6                    | 55/80 [00:17<00:07,  3.13it/s, v_num=_1.1]Epoch 0:  69%|############################################6                    | 55/80 [00:17<00:07,  3.13it/s, v_num=_1.1]Epoch 0:  70%|#############################################5                   | 56/80 [00:17<00:07,  3.14it/s, v_num=_1.1]Epoch 0:  70%|#############################################5                   | 56/80 [00:17<00:07,  3.14it/s, v_num=_1.1]Epoch 0:  71%|##############################################3                  | 57/80 [00:18<00:07,  3.14it/s, v_num=_1.1]Epoch 0:  71%|##############################################3                  | 57/80 [00:18<00:07,  3.14it/s, v_num=_1.1]Epoch 0:  72%|###############################################1                 | 58/80 [00:18<00:07,  3.14it/s, v_num=_1.1]Epoch 0:  72%|###############################################1                 | 58/80 [00:18<00:07,  3.14it/s, v_num=_1.1]Epoch 0:  74%|###############################################9                 | 59/80 [00:18<00:06,  3.15it/s, v_num=_1.1]Epoch 0:  74%|###############################################9                 | 59/80 [00:18<00:06,  3.15it/s, v_num=_1.1]Epoch 0:  75%|################################################7                | 60/80 [00:19<00:06,  3.15it/s, v_num=_1.1]Epoch 0:  75%|################################################7                | 60/80 [00:19<00:06,  3.15it/s, v_num=_1.1]Epoch 0:  76%|#################################################5               | 61/80 [00:19<00:06,  3.15it/s, v_num=_1.1]Epoch 0:  76%|#################################################5               | 61/80 [00:19<00:06,  3.15it/s, v_num=_1.1]Epoch 0:  78%|##################################################3              | 62/80 [00:19<00:05,  3.15it/s, v_num=_1.1]Epoch 0:  78%|##################################################3              | 62/80 [00:19<00:05,  3.15it/s, v_num=_1.1]Epoch 0:  79%|###################################################1             | 63/80 [00:19<00:05,  3.15it/s, v_num=_1.1]Epoch 0:  79%|###################################################1             | 63/80 [00:19<00:05,  3.15it/s, v_num=_1.1]Epoch 0:  80%|####################################################             | 64/80 [00:20<00:05,  3.15it/s, v_num=_1.1]Epoch 0:  80%|####################################################             | 64/80 [00:20<00:05,  3.15it/s, v_num=_1.1]Epoch 0:  81%|####################################################8            | 65/80 [00:20<00:04,  3.15it/s, v_num=_1.1]Epoch 0:  81%|####################################################8            | 65/80 [00:20<00:04,  3.15it/s, v_num=_1.1]Epoch 0:  82%|#####################################################6           | 66/80 [00:20<00:04,  3.15it/s, v_num=_1.1]Epoch 0:  82%|#####################################################6           | 66/80 [00:20<00:04,  3.15it/s, v_num=_1.1]Epoch 0:  84%|######################################################4          | 67/80 [00:21<00:04,  3.16it/s, v_num=_1.1]Epoch 0:  84%|######################################################4          | 67/80 [00:21<00:04,  3.16it/s, v_num=_1.1]Epoch 0:  85%|#######################################################2         | 68/80 [00:21<00:03,  3.15it/s, v_num=_1.1]Epoch 0:  85%|#######################################################2         | 68/80 [00:21<00:03,  3.15it/s, v_num=_1.1]Epoch 0:  86%|########################################################         | 69/80 [00:21<00:03,  3.16it/s, v_num=_1.1]Epoch 0:  86%|########################################################         | 69/80 [00:21<00:03,  3.16it/s, v_num=_1.1]Epoch 0:  88%|########################################################8        | 70/80 [00:22<00:03,  3.16it/s, v_num=_1.1]Epoch 0:  88%|########################################################8        | 70/80 [00:22<00:03,  3.16it/s, v_num=_1.1]Epoch 0:  89%|#########################################################6       | 71/80 [00:22<00:02,  3.15it/s, v_num=_1.1]Epoch 0:  89%|#########################################################6       | 71/80 [00:22<00:02,  3.15it/s, v_num=_1.1]Epoch 0:  90%|##########################################################5      | 72/80 [00:22<00:02,  3.15it/s, v_num=_1.1]Epoch 0:  90%|##########################################################5      | 72/80 [00:22<00:02,  3.15it/s, v_num=_1.1]Epoch 0:  91%|###########################################################3     | 73/80 [00:23<00:02,  3.15it/s, v_num=_1.1]Epoch 0:  91%|###########################################################3     | 73/80 [00:23<00:02,  3.15it/s, v_num=_1.1]Epoch 0:  92%|############################################################1    | 74/80 [00:23<00:01,  3.15it/s, v_num=_1.1]Epoch 0:  92%|############################################################1    | 74/80 [00:23<00:01,  3.15it/s, v_num=_1.1]Epoch 0:  94%|############################################################9    | 75/80 [00:23<00:01,  3.15it/s, v_num=_1.1]Epoch 0:  94%|############################################################9    | 75/80 [00:23<00:01,  3.15it/s, v_num=_1.1]Epoch 0:  95%|#############################################################7   | 76/80 [00:24<00:01,  3.14it/s, v_num=_1.1]Epoch 0:  95%|#############################################################7   | 76/80 [00:24<00:01,  3.14it/s, v_num=_1.1]Epoch 0:  96%|##############################################################5  | 77/80 [00:24<00:00,  3.14it/s, v_num=_1.1]Epoch 0:  96%|##############################################################5  | 77/80 [00:24<00:00,  3.14it/s, v_num=_1.1]Epoch 0:  98%|###############################################################3 | 78/80 [00:24<00:00,  3.14it/s, v_num=_1.1]Epoch 0:  98%|###############################################################3 | 78/80 [00:24<00:00,  3.14it/s, v_num=_1.1]Epoch 0:  99%|################################################################1| 79/80 [00:25<00:00,  3.15it/s, v_num=_1.1]Epoch 0:  99%|################################################################1| 79/80 [00:25<00:00,  3.15it/s, v_num=_1.1]Epoch 0: 100%|#################################################################| 80/80 [00:25<00:00,  3.15it/s, v_num=_1.1]Epoch 0: 100%|#################################################################| 80/80 [00:25<00:00,  3.15it/s, v_num=_1.1]
Validation: |                                                                                        | 0/? [00:00<?, ?it/s][A
Validation:   0%|                                                                                   | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|                                                                      | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|######2                                                       | 1/10 [00:00<00:01,  8.70it/s][A
Validation DataLoader 0:  20%|############4                                                 | 2/10 [00:00<00:00,  8.22it/s][A
Validation DataLoader 0:  30%|##################5                                           | 3/10 [00:00<00:00,  8.19it/s][A
Validation DataLoader 0:  40%|########################8                                     | 4/10 [00:00<00:00,  8.14it/s][A
Validation DataLoader 0:  50%|###############################                               | 5/10 [00:00<00:00,  8.08it/s][A
Validation DataLoader 0:  60%|#####################################1                        | 6/10 [00:00<00:00,  7.79it/s][A
Validation DataLoader 0:  70%|###########################################4                  | 7/10 [00:00<00:00,  7.79it/s][A
Validation DataLoader 0:  80%|#################################################6            | 8/10 [00:01<00:00,  7.82it/s][A
Validation DataLoader 0:  90%|#######################################################8      | 9/10 [00:01<00:00,  7.73it/s][A
Validation DataLoader 0: 100%|#############################################################| 10/10 [00:01<00:00,  7.82it/s][A
                                                                                                                           [AEpoch 0: 100%|#################################################################| 80/80 [00:26<00:00,  3.00it/s, v_num=_1.1]Epoch 0: 100%|#################################################################| 80/80 [00:26<00:00,  3.00it/s, v_num=_1.1]
Epoch 1/2 completed, Global Step: 80
nri_train_loss: -0.5795, enc_train_loss: -0.6212, dec_train_loss: 0.0418, enc_train_edge_accuracy: 0.5000
nri_val_loss: -0.6044, enc_val_loss: -0.6212, dec_val_loss: 0.0169, enc_val_edge_accuracy: 0.5000
Epoch 0:   0%|                                                                          | 0/80 [00:00<?, ?it/s, v_num=_1.1]Epoch 1:   0%|                                                                          | 0/80 [00:00<?, ?it/s, v_num=_1.1]Epoch 1:   1%|8                                                                 | 1/80 [00:00<00:25,  3.11it/s, v_num=_1.1]Epoch 1:   1%|8                                                                 | 1/80 [00:00<00:25,  3.10it/s, v_num=_1.1]Epoch 1:   2%|#6                                                                | 2/80 [00:00<00:25,  3.08it/s, v_num=_1.1]Epoch 1:   2%|#6                                                                | 2/80 [00:00<00:25,  3.08it/s, v_num=_1.1]Epoch 1:   4%|##4                                                               | 3/80 [00:00<00:24,  3.13it/s, v_num=_1.1]Epoch 1:   4%|##4                                                               | 3/80 [00:00<00:24,  3.12it/s, v_num=_1.1]Epoch 1:   5%|###3                                                              | 4/80 [00:01<00:24,  3.08it/s, v_num=_1.1]Epoch 1:   5%|###3                                                              | 4/80 [00:01<00:24,  3.08it/s, v_num=_1.1]Epoch 1:   6%|####1                                                             | 5/80 [00:01<00:25,  2.96it/s, v_num=_1.1]Epoch 1:   6%|####1                                                             | 5/80 [00:01<00:25,  2.96it/s, v_num=_1.1]Epoch 1:   8%|####9                                                             | 6/80 [00:02<00:24,  2.97it/s, v_num=_1.1]Epoch 1:   8%|####9                                                             | 6/80 [00:02<00:24,  2.97it/s, v_num=_1.1]Epoch 1:   9%|#####7                                                            | 7/80 [00:02<00:24,  2.97it/s, v_num=_1.1]Epoch 1:   9%|#####7                                                            | 7/80 [00:02<00:24,  2.97it/s, v_num=_1.1]Epoch 1:  10%|######6                                                           | 8/80 [00:02<00:23,  3.02it/s, v_num=_1.1]Epoch 1:  10%|######6                                                           | 8/80 [00:02<00:23,  3.02it/s, v_num=_1.1]Epoch 1:  11%|#######4                                                          | 9/80 [00:02<00:23,  3.03it/s, v_num=_1.1]Epoch 1:  11%|#######4                                                          | 9/80 [00:02<00:23,  3.03it/s, v_num=_1.1]Epoch 1:  12%|########1                                                        | 10/80 [00:03<00:23,  3.03it/s, v_num=_1.1]Epoch 1:  12%|########1                                                        | 10/80 [00:03<00:23,  3.03it/s, v_num=_1.1]Epoch 1:  14%|########9                                                        | 11/80 [00:03<00:22,  3.04it/s, v_num=_1.1]Epoch 1:  14%|########9                                                        | 11/80 [00:03<00:22,  3.04it/s, v_num=_1.1]Epoch 1:  15%|#########7                                                       | 12/80 [00:03<00:22,  3.04it/s, v_num=_1.1]Epoch 1:  15%|#########7                                                       | 12/80 [00:03<00:22,  3.04it/s, v_num=_1.1]Epoch 1:  16%|##########5                                                      | 13/80 [00:04<00:22,  3.04it/s, v_num=_1.1]Epoch 1:  16%|##########5                                                      | 13/80 [00:04<00:22,  3.04it/s, v_num=_1.1]Epoch 1:  18%|###########3                                                     | 14/80 [00:04<00:21,  3.04it/s, v_num=_1.1]Epoch 1:  18%|###########3                                                     | 14/80 [00:04<00:21,  3.04it/s, v_num=_1.1]Epoch 1:  19%|############1                                                    | 15/80 [00:04<00:21,  3.06it/s, v_num=_1.1]Epoch 1:  19%|############1                                                    | 15/80 [00:04<00:21,  3.06it/s, v_num=_1.1]Epoch 1:  20%|#############                                                    | 16/80 [00:05<00:20,  3.07it/s, v_num=_1.1]Epoch 1:  20%|#############                                                    | 16/80 [00:05<00:20,  3.07it/s, v_num=_1.1]Epoch 1:  21%|#############8                                                   | 17/80 [00:05<00:20,  3.08it/s, v_num=_1.1]Epoch 1:  21%|#############8                                                   | 17/80 [00:05<00:20,  3.08it/s, v_num=_1.1]Epoch 1:  22%|##############6                                                  | 18/80 [00:05<00:20,  3.09it/s, v_num=_1.1]Epoch 1:  22%|##############6                                                  | 18/80 [00:05<00:20,  3.09it/s, v_num=_1.1]Epoch 1:  24%|###############4                                                 | 19/80 [00:06<00:19,  3.09it/s, v_num=_1.1]Epoch 1:  24%|###############4                                                 | 19/80 [00:06<00:19,  3.09it/s, v_num=_1.1]Epoch 1:  25%|################2                                                | 20/80 [00:06<00:19,  3.09it/s, v_num=_1.1]Epoch 1:  25%|################2                                                | 20/80 [00:06<00:19,  3.09it/s, v_num=_1.1]Epoch 1:  26%|#################                                                | 21/80 [00:06<00:19,  3.10it/s, v_num=_1.1]Epoch 1:  26%|#################                                                | 21/80 [00:06<00:19,  3.10it/s, v_num=_1.1]Epoch 1:  28%|#################8                                               | 22/80 [00:07<00:18,  3.09it/s, v_num=_1.1]Epoch 1:  28%|#################8                                               | 22/80 [00:07<00:18,  3.09it/s, v_num=_1.1]Epoch 1:  29%|##################6                                              | 23/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 1:  29%|##################6                                              | 23/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 1:  30%|###################5                                             | 24/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 1:  30%|###################5                                             | 24/80 [00:07<00:18,  3.07it/s, v_num=_1.1]Epoch 1:  31%|####################3                                            | 25/80 [00:08<00:17,  3.08it/s, v_num=_1.1]Epoch 1:  31%|####################3                                            | 25/80 [00:08<00:17,  3.08it/s, v_num=_1.1]Epoch 1:  32%|#####################1                                           | 26/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 1:  32%|#####################1                                           | 26/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 1:  34%|#####################9                                           | 27/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 1:  34%|#####################9                                           | 27/80 [00:08<00:17,  3.09it/s, v_num=_1.1]Epoch 1:  35%|######################7                                          | 28/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 1:  35%|######################7                                          | 28/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 1:  36%|#######################5                                         | 29/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 1:  36%|#######################5                                         | 29/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 1:  38%|########################3                                        | 30/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 1:  38%|########################3                                        | 30/80 [00:09<00:16,  3.10it/s, v_num=_1.1]Epoch 1:  39%|#########################1                                       | 31/80 [00:09<00:15,  3.11it/s, v_num=_1.1]Epoch 1:  39%|#########################1                                       | 31/80 [00:09<00:15,  3.11it/s, v_num=_1.1]Epoch 1:  40%|##########################                                       | 32/80 [00:10<00:15,  3.11it/s, v_num=_1.1]Epoch 1:  40%|##########################                                       | 32/80 [00:10<00:15,  3.11it/s, v_num=_1.1]Epoch 1:  41%|##########################8                                      | 33/80 [00:10<00:15,  3.10it/s, v_num=_1.1]Epoch 1:  41%|##########################8                                      | 33/80 [00:10<00:15,  3.10it/s, v_num=_1.1]Epoch 1:  42%|###########################6                                     | 34/80 [00:10<00:14,  3.11it/s, v_num=_1.1]Epoch 1:  42%|###########################6                                     | 34/80 [00:10<00:14,  3.11it/s, v_num=_1.1]Epoch 1:  44%|############################4                                    | 35/80 [00:11<00:14,  3.11it/s, v_num=_1.1]Epoch 1:  44%|############################4                                    | 35/80 [00:11<00:14,  3.11it/s, v_num=_1.1]Epoch 1:  45%|#############################2                                   | 36/80 [00:11<00:14,  3.12it/s, v_num=_1.1]Epoch 1:  45%|#############################2                                   | 36/80 [00:11<00:14,  3.12it/s, v_num=_1.1]Epoch 1:  46%|##############################                                   | 37/80 [00:11<00:13,  3.12it/s, v_num=_1.1]Epoch 1:  46%|##############################                                   | 37/80 [00:11<00:13,  3.12it/s, v_num=_1.1]Epoch 1:  48%|##############################8                                  | 38/80 [00:12<00:13,  3.12it/s, v_num=_1.1]Epoch 1:  48%|##############################8                                  | 38/80 [00:12<00:13,  3.12it/s, v_num=_1.1]Epoch 1:  49%|###############################6                                 | 39/80 [00:12<00:13,  3.11it/s, v_num=_1.1]Epoch 1:  49%|###############################6                                 | 39/80 [00:12<00:13,  3.11it/s, v_num=_1.1]Epoch 1:  50%|################################5                                | 40/80 [00:12<00:12,  3.12it/s, v_num=_1.1]Epoch 1:  50%|################################5                                | 40/80 [00:12<00:12,  3.12it/s, v_num=_1.1]Epoch 1:  51%|#################################3                               | 41/80 [00:13<00:12,  3.12it/s, v_num=_1.1]Epoch 1:  51%|#################################3                               | 41/80 [00:13<00:12,  3.12it/s, v_num=_1.1]Epoch 1:  52%|##################################1                              | 42/80 [00:13<00:12,  3.13it/s, v_num=_1.1]Epoch 1:  52%|##################################1                              | 42/80 [00:13<00:12,  3.13it/s, v_num=_1.1]Epoch 1:  54%|##################################9                              | 43/80 [00:13<00:11,  3.13it/s, v_num=_1.1]Epoch 1:  54%|##################################9                              | 43/80 [00:13<00:11,  3.13it/s, v_num=_1.1]Epoch 1:  55%|###################################7                             | 44/80 [00:14<00:11,  3.13it/s, v_num=_1.1]Epoch 1:  55%|###################################7                             | 44/80 [00:14<00:11,  3.13it/s, v_num=_1.1]Epoch 1:  56%|####################################5                            | 45/80 [00:14<00:11,  3.14it/s, v_num=_1.1]Epoch 1:  56%|####################################5                            | 45/80 [00:14<00:11,  3.14it/s, v_num=_1.1]Epoch 1:  57%|#####################################3                           | 46/80 [00:14<00:10,  3.15it/s, v_num=_1.1]Epoch 1:  57%|#####################################3                           | 46/80 [00:14<00:10,  3.15it/s, v_num=_1.1]Epoch 1:  59%|######################################1                          | 47/80 [00:14<00:10,  3.15it/s, v_num=_1.1]Epoch 1:  59%|######################################1                          | 47/80 [00:14<00:10,  3.15it/s, v_num=_1.1]Epoch 1:  60%|#######################################                          | 48/80 [00:15<00:10,  3.15it/s, v_num=_1.1]Epoch 1:  60%|#######################################                          | 48/80 [00:15<00:10,  3.15it/s, v_num=_1.1]Epoch 1:  61%|#######################################8                         | 49/80 [00:15<00:09,  3.16it/s, v_num=_1.1]Epoch 1:  61%|#######################################8                         | 49/80 [00:15<00:09,  3.16it/s, v_num=_1.1]Epoch 1:  62%|########################################6                        | 50/80 [00:15<00:09,  3.16it/s, v_num=_1.1]Epoch 1:  62%|########################################6                        | 50/80 [00:15<00:09,  3.16it/s, v_num=_1.1]Epoch 1:  64%|#########################################4                       | 51/80 [00:16<00:09,  3.16it/s, v_num=_1.1]Epoch 1:  64%|#########################################4                       | 51/80 [00:16<00:09,  3.16it/s, v_num=_1.1]Epoch 1:  65%|##########################################2                      | 52/80 [00:16<00:08,  3.16it/s, v_num=_1.1]Epoch 1:  65%|##########################################2                      | 52/80 [00:16<00:08,  3.16it/s, v_num=_1.1]Epoch 1:  66%|###########################################                      | 53/80 [00:16<00:08,  3.16it/s, v_num=_1.1]Epoch 1:  66%|###########################################                      | 53/80 [00:16<00:08,  3.16it/s, v_num=_1.1]Epoch 1:  68%|###########################################8                     | 54/80 [00:17<00:08,  3.16it/s, v_num=_1.1]Epoch 1:  68%|###########################################8                     | 54/80 [00:17<00:08,  3.16it/s, v_num=_1.1]Epoch 1:  69%|############################################6                    | 55/80 [00:17<00:07,  3.16it/s, v_num=_1.1]Epoch 1:  69%|############################################6                    | 55/80 [00:17<00:07,  3.16it/s, v_num=_1.1]Epoch 1:  70%|#############################################5                   | 56/80 [00:17<00:07,  3.16it/s, v_num=_1.1]Epoch 1:  70%|#############################################5                   | 56/80 [00:17<00:07,  3.16it/s, v_num=_1.1]Epoch 1:  71%|##############################################3                  | 57/80 [00:18<00:07,  3.16it/s, v_num=_1.1]Epoch 1:  71%|##############################################3                  | 57/80 [00:18<00:07,  3.16it/s, v_num=_1.1]Epoch 1:  72%|###############################################1                 | 58/80 [00:18<00:06,  3.16it/s, v_num=_1.1]Epoch 1:  72%|###############################################1                 | 58/80 [00:18<00:06,  3.16it/s, v_num=_1.1]Epoch 1:  74%|###############################################9                 | 59/80 [00:18<00:06,  3.16it/s, v_num=_1.1]Epoch 1:  74%|###############################################9                 | 59/80 [00:18<00:06,  3.16it/s, v_num=_1.1]Epoch 1:  75%|################################################7                | 60/80 [00:18<00:06,  3.16it/s, v_num=_1.1]Epoch 1:  75%|################################################7                | 60/80 [00:18<00:06,  3.16it/s, v_num=_1.1]Epoch 1:  76%|#################################################5               | 61/80 [00:19<00:06,  3.17it/s, v_num=_1.1]Epoch 1:  76%|#################################################5               | 61/80 [00:19<00:06,  3.17it/s, v_num=_1.1]Epoch 1:  78%|##################################################3              | 62/80 [00:19<00:05,  3.17it/s, v_num=_1.1]Epoch 1:  78%|##################################################3              | 62/80 [00:19<00:05,  3.17it/s, v_num=_1.1]Epoch 1:  79%|###################################################1             | 63/80 [00:19<00:05,  3.17it/s, v_num=_1.1]Epoch 1:  79%|###################################################1             | 63/80 [00:19<00:05,  3.17it/s, v_num=_1.1]Epoch 1:  80%|####################################################             | 64/80 [00:20<00:05,  3.17it/s, v_num=_1.1]Epoch 1:  80%|####################################################             | 64/80 [00:20<00:05,  3.17it/s, v_num=_1.1]Epoch 1:  81%|####################################################8            | 65/80 [00:20<00:04,  3.16it/s, v_num=_1.1]Epoch 1:  81%|####################################################8            | 65/80 [00:20<00:04,  3.16it/s, v_num=_1.1]Epoch 1:  82%|#####################################################6           | 66/80 [00:20<00:04,  3.17it/s, v_num=_1.1]Epoch 1:  82%|#####################################################6           | 66/80 [00:20<00:04,  3.17it/s, v_num=_1.1]Epoch 1:  84%|######################################################4          | 67/80 [00:21<00:04,  3.17it/s, v_num=_1.1]Epoch 1:  84%|######################################################4          | 67/80 [00:21<00:04,  3.17it/s, v_num=_1.1]Epoch 1:  85%|#######################################################2         | 68/80 [00:21<00:03,  3.17it/s, v_num=_1.1]Epoch 1:  85%|#######################################################2         | 68/80 [00:21<00:03,  3.17it/s, v_num=_1.1]Epoch 1:  86%|########################################################         | 69/80 [00:21<00:03,  3.17it/s, v_num=_1.1]Epoch 1:  86%|########################################################         | 69/80 [00:21<00:03,  3.17it/s, v_num=_1.1]Epoch 1:  88%|########################################################8        | 70/80 [00:22<00:03,  3.17it/s, v_num=_1.1]Epoch 1:  88%|########################################################8        | 70/80 [00:22<00:03,  3.17it/s, v_num=_1.1]Epoch 1:  89%|#########################################################6       | 71/80 [00:22<00:02,  3.18it/s, v_num=_1.1]Epoch 1:  89%|#########################################################6       | 71/80 [00:22<00:02,  3.18it/s, v_num=_1.1]Epoch 1:  90%|##########################################################5      | 72/80 [00:22<00:02,  3.18it/s, v_num=_1.1]Epoch 1:  90%|##########################################################5      | 72/80 [00:22<00:02,  3.18it/s, v_num=_1.1]Epoch 1:  91%|###########################################################3     | 73/80 [00:22<00:02,  3.18it/s, v_num=_1.1]Epoch 1:  91%|###########################################################3     | 73/80 [00:22<00:02,  3.18it/s, v_num=_1.1]Epoch 1:  92%|############################################################1    | 74/80 [00:23<00:01,  3.18it/s, v_num=_1.1]Epoch 1:  92%|############################################################1    | 74/80 [00:23<00:01,  3.18it/s, v_num=_1.1]Epoch 1:  94%|############################################################9    | 75/80 [00:23<00:01,  3.18it/s, v_num=_1.1]Epoch 1:  94%|############################################################9    | 75/80 [00:23<00:01,  3.18it/s, v_num=_1.1]Epoch 1:  95%|#############################################################7   | 76/80 [00:23<00:01,  3.18it/s, v_num=_1.1]Epoch 1:  95%|#############################################################7   | 76/80 [00:23<00:01,  3.18it/s, v_num=_1.1]Epoch 1:  96%|##############################################################5  | 77/80 [00:24<00:00,  3.18it/s, v_num=_1.1]Epoch 1:  96%|##############################################################5  | 77/80 [00:24<00:00,  3.18it/s, v_num=_1.1]Epoch 1:  98%|###############################################################3 | 78/80 [00:24<00:00,  3.18it/s, v_num=_1.1]Epoch 1:  98%|###############################################################3 | 78/80 [00:24<00:00,  3.18it/s, v_num=_1.1]Epoch 1:  99%|################################################################1| 79/80 [00:24<00:00,  3.18it/s, v_num=_1.1]Epoch 1:  99%|################################################################1| 79/80 [00:24<00:00,  3.18it/s, v_num=_1.1]Epoch 1: 100%|#################################################################| 80/80 [00:25<00:00,  3.19it/s, v_num=_1.1]Epoch 1: 100%|#################################################################| 80/80 [00:25<00:00,  3.19it/s, v_num=_1.1]
Validation: |                                                                                        | 0/? [00:00<?, ?it/s][A
Validation:   0%|                                                                                   | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|                                                                      | 0/10 [00:00<?, ?it/s][A
Validation DataLoader 0:  10%|######2                                                       | 1/10 [00:00<00:01,  7.80it/s][A
Validation DataLoader 0:  20%|############4                                                 | 2/10 [00:00<00:01,  7.73it/s][A
Validation DataLoader 0:  30%|##################5                                           | 3/10 [00:00<00:00,  8.06it/s][A
Validation DataLoader 0:  40%|########################8                                     | 4/10 [00:00<00:00,  8.06it/s][A
Validation DataLoader 0:  50%|###############################                               | 5/10 [00:00<00:00,  7.87it/s][A
Validation DataLoader 0:  60%|#####################################1                        | 6/10 [00:00<00:00,  7.94it/s][A
Validation DataLoader 0:  70%|###########################################4                  | 7/10 [00:00<00:00,  8.03it/s][A
Validation DataLoader 0:  80%|#################################################6            | 8/10 [00:00<00:00,  8.12it/s][A
Validation DataLoader 0:  90%|#######################################################8      | 9/10 [00:01<00:00,  8.11it/s][A
Validation DataLoader 0: 100%|#############################################################| 10/10 [00:01<00:00,  8.07it/s][A
                                                                                                                           [AEpoch 1: 100%|#################################################################| 80/80 [00:26<00:00,  3.04it/s, v_num=_1.1]Epoch 1: 100%|#################################################################| 80/80 [00:26<00:00,  3.04it/s, v_num=_1.1]
Epoch 2/2 completed, Global Step: 160
nri_train_loss: -0.6052, enc_train_loss: -0.6212, dec_train_loss: 0.0160, enc_train_edge_accuracy: 0.5000
nri_val_loss: -0.6062, enc_val_loss: -0.6212, dec_val_loss: 0.0151, enc_val_edge_accuracy: 0.5000
Epoch 1: 100%|#################################################################| 80/80 [00:26<00:00,  3.03it/s, v_num=_1.1]

Training completed in 54.16 seconds or 0.90 minutes or 0.015044156048032973 hours.
Total training steps: 160

Training completed for model '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1'. Trained model saved at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1\checkpoints

---------------------------------------------------------------------------

<<<<<<<<<<<< TRAINING LOSS PLOT (TRAIN + VAL) >>>>>>>>>>>>

Creating training loss plot for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1...

Training loss (train + val) plot logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1


<<<<<<<<<<<< DECODER OUTPUT PLOT (TRAIN) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.193' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1...

Decoder output plot for rep '1001.1929' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1


<<<<<<<<<<<< DECODER OUTPUT PLOT (VAL) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.441' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1...

Decoder output plot for rep '1001.4406' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1


---------------------------------------------------------------------------

TESTING TRAINED NRI MODEL...

.ckpt_files available in C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1\checkpoints:

['best-model-epoch=01-val_loss=0.0000.ckpt']

Trained NRI Model Loaded for testing.

Testing environment set. Testing will be logged at: C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1\test
C:\Anaconda3\envs\afd_env\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Testing: |                                                                                           | 0/? [00:00<?, ?it/s]
Initializing input processors for encoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------

Initializing input processors for decoder model...

>> Domain transformer initialized: time(cutoff_freq=0)

>> Raw data normalizer initialized with 'min_max' normalization

>> No feature normalization is applied

>> No time feature extraction is applied

>> No feature reduction is applied

---------------------------------------------------------------------------
Testing:   0%|                                                                                      | 0/10 [00:00<?, ?it/s]Testing DataLoader 0:   0%|                                                                         | 0/10 [00:00<?, ?it/s]Testing DataLoader 0:  10%|######5                                                          | 1/10 [00:00<00:01,  4.62it/s]Testing DataLoader 0:  20%|#############                                                    | 2/10 [00:00<00:01,  6.05it/s]Testing DataLoader 0:  30%|###################5                                             | 3/10 [00:00<00:01,  6.91it/s]Testing DataLoader 0:  40%|##########################                                       | 4/10 [00:00<00:00,  7.51it/s]Testing DataLoader 0:  50%|################################5                                | 5/10 [00:00<00:00,  7.70it/s]Testing DataLoader 0:  60%|#######################################                          | 6/10 [00:00<00:00,  7.73it/s]Testing DataLoader 0:  70%|#############################################5                   | 7/10 [00:00<00:00,  7.92it/s]Testing DataLoader 0:  80%|####################################################             | 8/10 [00:00<00:00,  8.11it/s]Testing DataLoader 0:  90%|##########################################################5      | 9/10 [00:01<00:00,  8.28it/s]Testing DataLoader 0: 100%|################################################################| 10/10 [00:01<00:00,  8.37it/s]
Testing completed in 1.20 seconds or 0.02 minutes or 0.0003323115905125936 hours.

nri_test_loss: -0.6057, enc_test_loss: -0.6212, dec_test_loss: 0.0155, enc_test_edge_accuracy: 0.5000

Edge predictions are as follows (showing probabilities for each edge type):

Rep 1,001.132:
[[0.08333662]
 [0.08333402]
 [0.08333413]
 [0.08333403]
 [0.083333  ]
 [0.08333296]
 [0.08333218]
 [0.08333369]
 [0.08333106]
 [0.08333254]
 [0.08333398]
 [0.0833318 ]]

Rep 1,001.418:
[[0.08333439]
 [0.08333164]
 [0.08333297]
 [0.08333472]
 [0.08333335]
 [0.08333462]
 [0.08333281]
 [0.08333375]
 [0.08333228]
 [0.08333313]
 [0.08333438]
 [0.08333198]]

Rep 1,001.160:
[[0.08333394]
 [0.08333296]
 [0.08333337]
 [0.08333313]
 [0.08333348]
 [0.08333402]
 [0.08333268]
 [0.08333334]
 [0.08333325]
 [0.08333261]
 [0.08333375]
 [0.08333344]]

Rep 1,001.393:
[[0.08333534]
 [0.08333395]
 [0.08333457]
 [0.08333603]
 [0.08333313]
 [0.08333384]
 [0.08333223]
 [0.08333074]
 [0.08333007]
 [0.08333481]
 [0.08333334]
 [0.08333194]]

Rep 1,001.253:
[[0.08333442]
 [0.08333331]
 [0.0833342 ]
 [0.08333372]
 [0.08333296]
 [0.0833339 ]
 [0.08333208]
 [0.08333238]
 [0.08333191]
 [0.08333404]
 [0.08333421]
 [0.08333281]]

Rep 1,001.351:
[[0.08333368]
 [0.0833346 ]
 [0.08333198]
 [0.08333513]
 [0.08333626]
 [0.08333376]
 [0.08333245]
 [0.08333364]
 [0.083332  ]
 [0.08333081]
 [0.08333239]
 [0.08333331]]

Rep 1,001.208:
[[0.08333644]
 [0.08333275]
 [0.08333446]
 [0.08333362]
 [0.08333246]
 [0.08333488]
 [0.08333043]
 [0.08333415]
 [0.08333239]
 [0.08333182]
 [0.08333501]
 [0.08333156]]

Rep 1,001.466:
[[0.08333378]
 [0.08333352]
 [0.08333416]
 [0.08333249]
 [0.08333296]
 [0.08333338]
 [0.08333217]
 [0.0833331 ]
 [0.08333316]
 [0.08333307]
 [0.08333406]
 [0.08333418]]

Rep 1,001.439:
[[0.08333474]
 [0.08333445]
 [0.08333468]
 [0.08333284]
 [0.08333386]
 [0.08333381]
 [0.08333136]
 [0.08333291]
 [0.08333242]
 [0.08333207]
 [0.08333346]
 [0.08333336]]

Rep 1,001.337:
[[0.08333537]
 [0.08333614]
 [0.08333607]
 [0.08333234]
 [0.08333124]
 [0.08333138]
 [0.08333339]
 [0.0833315 ]
 [0.08333264]
 [0.08333418]
 [0.08333254]
 [0.0833333 ]]

Rep 1,001.340:
[[0.08333251]
 [0.08333413]
 [0.08333214]
 [0.08333342]
 [0.08333571]
 [0.08333399]
 [0.08333244]
 [0.08333312]
 [0.08333308]
 [0.08333246]
 [0.08333267]
 [0.08333441]]

Rep 1,001.241:
[[0.08333319]
 [0.08333177]
 [0.08333224]
 [0.08333753]
 [0.08333498]
 [0.08333521]
 [0.08333255]
 [0.08333151]
 [0.08333033]
 [0.08333482]
 [0.08333364]
 [0.08333224]]

Rep 1,001.658:
[[0.08333538]
 [0.08333467]
 [0.08333465]
 [0.08333596]
 [0.08333292]
 [0.08333325]
 [0.0833322 ]
 [0.08333098]
 [0.08333018]
 [0.08333445]
 [0.08333308]
 [0.08333223]]

Rep 1,001.138:
[[0.0833336 ]
 [0.08333433]
 [0.08333276]
 [0.08333521]
 [0.08333594]
 [0.08333427]
 [0.08333074]
 [0.08333082]
 [0.08333056]
 [0.0833339 ]
 [0.08333364]
 [0.08333427]]

Rep 1,001.435:
[[0.0833343 ]
 [0.08333575]
 [0.08333433]
 [0.08333378]
 [0.08333437]
 [0.08333323]
 [0.08333158]
 [0.08333088]
 [0.08333132]
 [0.08333337]
 [0.08333277]
 [0.08333428]]

Rep 1,001.289:
[[0.083334  ]
 [0.08333412]
 [0.08333339]
 [0.08333506]
 [0.08333462]
 [0.08333389]
 [0.08333186]
 [0.08333139]
 [0.08333146]
 [0.08333391]
 [0.08333304]
 [0.08333331]]

Rep 1,001.464:
[[0.08333445]
 [0.08333529]
 [0.08333267]
 [0.08333241]
 [0.08333603]
 [0.08333393]
 [0.08333115]
 [0.0833331 ]
 [0.08333209]
 [0.08333112]
 [0.08333343]
 [0.08333433]]

Rep 1,001.209:
[[0.08333583]
 [0.0833362 ]
 [0.0833346 ]
 [0.08333392]
 [0.08333444]
 [0.0833329 ]
 [0.08333191]
 [0.08333226]
 [0.08333112]
 [0.08333207]
 [0.08333241]
 [0.08333237]]

Rep 1,001.298:
[[0.08333583]
 [0.08333375]
 [0.08333338]
 [0.08333265]
 [0.08333346]
 [0.08333287]
 [0.08333246]
 [0.08333494]
 [0.08333238]
 [0.08333129]
 [0.08333419]
 [0.08333281]]

Rep 1,001.324:
[[0.08333308]
 [0.08333367]
 [0.08333416]
 [0.08333225]
 [0.08333343]
 [0.08333385]
 [0.083333  ]
 [0.08333351]
 [0.08333461]
 [0.08333232]
 [0.08333281]
 [0.08333331]]

Rep 1,001.311:
[[0.08333208]
 [0.08333309]
 [0.08333294]
 [0.08333291]
 [0.08333457]
 [0.08333417]
 [0.08333387]
 [0.08333404]
 [0.08333489]
 [0.08333211]
 [0.08333214]
 [0.08333315]]

Rep 1,001.247:
[[0.08333182]
 [0.08333329]
 [0.08333303]
 [0.08333214]
 [0.08333467]
 [0.08333452]
 [0.08333245]
 [0.08333386]
 [0.08333476]
 [0.08333197]
 [0.08333309]
 [0.08333441]]

Rep 1,001.254:
[[0.08333509]
 [0.08333541]
 [0.08333416]
 [0.08333368]
 [0.08333335]
 [0.08333191]
 [0.08333373]
 [0.08333306]
 [0.08333163]
 [0.0833332 ]
 [0.08333249]
 [0.08333236]]

Rep 1,001.262:
[[0.08333446]
 [0.08333413]
 [0.08333473]
 [0.08333525]
 [0.08333329]
 [0.0833336 ]
 [0.08333384]
 [0.0833315 ]
 [0.08333179]
 [0.08333364]
 [0.08333193]
 [0.08333185]]

Rep 1,001.204:
[[0.08333348]
 [0.08333205]
 [0.08333223]
 [0.08333376]
 [0.08333439]
 [0.08333462]
 [0.08333279]
 [0.08333462]
 [0.08333369]
 [0.08333177]
 [0.08333393]
 [0.08333272]]

Rep 1,001.344:
[[0.08333503]
 [0.08333411]
 [0.08333524]
 [0.08333296]
 [0.083333  ]
 [0.08333411]
 [0.08333109]
 [0.08333178]
 [0.08333232]
 [0.08333313]
 [0.08333393]
 [0.08333331]]

Rep 1,001.266:
[[0.08333565]
 [0.08333458]
 [0.08333436]
 [0.08333617]
 [0.08333328]
 [0.08333283]
 [0.08333459]
 [0.08333283]
 [0.08333093]
 [0.08333322]
 [0.08333138]
 [0.08333017]]

Rep 1,001.194:
[[0.08333229]
 [0.08333389]
 [0.0833334 ]
 [0.08333276]
 [0.08333419]
 [0.08333364]
 [0.08333366]
 [0.08333319]
 [0.08333439]
 [0.08333298]
 [0.0833322 ]
 [0.08333343]]

Rep 1,001.486:
[[0.08333436]
 [0.08333413]
 [0.08333398]
 [0.0833327 ]
 [0.0833343 ]
 [0.08333395]
 [0.08333174]
 [0.08333426]
 [0.08333356]
 [0.08333065]
 [0.0833331 ]
 [0.08333323]]

Rep 1,001.208:
[[0.08333419]
 [0.08333188]
 [0.08333324]
 [0.08333483]
 [0.08333389]
 [0.08333517]
 [0.08333205]
 [0.08333321]
 [0.08333243]
 [0.08333287]
 [0.08333403]
 [0.08333223]]

Rep 1,001.195:
[[0.08333466]
 [0.0833352 ]
 [0.08333372]
 [0.08333405]
 [0.0833342 ]
 [0.08333326]
 [0.08333286]
 [0.08333243]
 [0.08333182]
 [0.08333299]
 [0.08333212]
 [0.08333264]]

Rep 1,001.448:
[[0.0833327 ]
 [0.08333464]
 [0.08333319]
 [0.08333309]
 [0.08333401]
 [0.08333277]
 [0.0833331 ]
 [0.08333207]
 [0.08333282]
 [0.08333372]
 [0.08333292]
 [0.08333492]]

Rep 1,001.987:
[[0.08333422]
 [0.08333235]
 [0.08333431]
 [0.0833338 ]
 [0.08333305]
 [0.08333514]
 [0.08333082]
 [0.0833317 ]
 [0.08333198]
 [0.08333414]
 [0.08333504]
 [0.08333347]]

Rep 1,001.025:
[[0.08333471]
 [0.08333296]
 [0.08333445]
 [0.0833355 ]
 [0.08333229]
 [0.08333409]
 [0.08333227]
 [0.08333226]
 [0.08333153]
 [0.08333416]
 [0.08333395]
 [0.08333181]]

Rep 1,001.167:
[[0.08333498]
 [0.08333284]
 [0.08333348]
 [0.08333345]
 [0.08333379]
 [0.08333521]
 [0.08333047]
 [0.08333255]
 [0.08333185]
 [0.08333299]
 [0.08333515]
 [0.08333322]]

Rep 1,001.447:
[[0.08333348]
 [0.08333305]
 [0.08333477]
 [0.08333103]
 [0.08333321]
 [0.08333475]
 [0.08333093]
 [0.08333296]
 [0.08333421]
 [0.08333292]
 [0.08333458]
 [0.08333406]]

Rep 1,001.234:
[[0.08333486]
 [0.08333465]
 [0.08333477]
 [0.08333452]
 [0.08333149]
 [0.08333159]
 [0.08333489]
 [0.08333208]
 [0.08333197]
 [0.08333489]
 [0.08333224]
 [0.08333201]]

Rep 1,001.314:
[[0.08333417]
 [0.08333459]
 [0.08333398]
 [0.0833318 ]
 [0.08333414]
 [0.0833333 ]
 [0.08333224]
 [0.08333437]
 [0.08333367]
 [0.08333098]
 [0.08333297]
 [0.08333375]]

Rep 1,001.257:
[[0.08333381]
 [0.08333318]
 [0.08333445]
 [0.08333343]
 [0.08333243]
 [0.08333358]
 [0.08333299]
 [0.08333232]
 [0.08333295]
 [0.08333419]
 [0.0833336 ]
 [0.08333309]]

Rep 1,001.408:
[[0.0833343 ]
 [0.08333384]
 [0.08333334]
 [0.0833343 ]
 [0.08333417]
 [0.08333368]
 [0.08333229]
 [0.08333221]
 [0.08333157]
 [0.08333396]
 [0.08333347]
 [0.08333281]]

Rep 1,001.304:
[[0.08333423]
 [0.08333589]
 [0.08333492]
 [0.08333135]
 [0.0833328 ]
 [0.08333147]
 [0.08333365]
 [0.08333452]
 [0.08333432]
 [0.08333157]
 [0.08333196]
 [0.08333325]]

Rep 1,001.414:
[[0.08333632]
 [0.08333478]
 [0.08333416]
 [0.08333649]
 [0.08333436]
 [0.08333375]
 [0.08333312]
 [0.08333223]
 [0.08333008]
 [0.08333308]
 [0.08333171]
 [0.08332995]]

Rep 1,001.251:
[[0.083334  ]
 [0.08333503]
 [0.0833347 ]
 [0.08333263]
 [0.08333395]
 [0.08333345]
 [0.08333158]
 [0.08333114]
 [0.0833327 ]
 [0.08333364]
 [0.08333287]
 [0.0833343 ]]

Rep 1,001.446:
[[0.0833331 ]
 [0.08333554]
 [0.0833336 ]
 [0.08333143]
 [0.08333492]
 [0.08333323]
 [0.08333077]
 [0.08333184]
 [0.08333271]
 [0.0833329 ]
 [0.08333404]
 [0.08333585]]

Rep 1,001.363:
[[0.08333463]
 [0.08333494]
 [0.08333433]
 [0.08333588]
 [0.08333401]
 [0.08333359]
 [0.08333245]
 [0.08333115]
 [0.08333095]
 [0.08333325]
 [0.0833323 ]
 [0.08333248]]

Rep 1,001.409:
[[0.08333409]
 [0.08333431]
 [0.08333436]
 [0.08333195]
 [0.08333281]
 [0.0833327 ]
 [0.08333286]
 [0.08333426]
 [0.08333408]
 [0.08333187]
 [0.08333322]
 [0.08333348]]

Rep 1,001.860:
[[0.08333366]
 [0.08333333]
 [0.08333402]
 [0.08333662]
 [0.08333351]
 [0.08333428]
 [0.08333262]
 [0.08333075]
 [0.08333061]
 [0.08333517]
 [0.08333315]
 [0.08333233]]

Rep 1,001.206:
[[0.08333399]
 [0.08333552]
 [0.08333381]
 [0.08333418]
 [0.08333405]
 [0.08333282]
 [0.08333261]
 [0.08333262]
 [0.08333172]
 [0.08333248]
 [0.08333282]
 [0.08333339]]

Rep 1,001.449:
[[0.0833326 ]
 [0.08333581]
 [0.0833341 ]
 [0.08333236]
 [0.08333366]
 [0.08333249]
 [0.08333275]
 [0.08333159]
 [0.08333313]
 [0.08333352]
 [0.08333258]
 [0.08333544]]

Rep 1,001.440:
[[0.08333486]
 [0.0833351 ]
 [0.08333287]
 [0.08333516]
 [0.08333613]
 [0.08333398]
 [0.08333139]
 [0.08333173]
 [0.08333118]
 [0.08333249]
 [0.08333229]
 [0.08333282]]

Adjacency matrix from edge pred is as follows:

Rep 1,001.132:
[[[0.        ]
  [0.08333662]
  [0.08333402]
  [0.08333413]]

 [[0.08333403]
  [0.        ]
  [0.083333  ]
  [0.08333296]]

 [[0.08333218]
  [0.08333369]
  [0.        ]
  [0.08333106]]

 [[0.08333254]
  [0.08333398]
  [0.0833318 ]
  [0.        ]]]

Rep 1,001.418:
[[[0.        ]
  [0.08333439]
  [0.08333164]
  [0.08333297]]

 [[0.08333472]
  [0.        ]
  [0.08333335]
  [0.08333462]]

 [[0.08333281]
  [0.08333375]
  [0.        ]
  [0.08333228]]

 [[0.08333313]
  [0.08333438]
  [0.08333198]
  [0.        ]]]

Rep 1,001.160:
[[[0.        ]
  [0.08333394]
  [0.08333296]
  [0.08333337]]

 [[0.08333313]
  [0.        ]
  [0.08333348]
  [0.08333402]]

 [[0.08333268]
  [0.08333334]
  [0.        ]
  [0.08333325]]

 [[0.08333261]
  [0.08333375]
  [0.08333344]
  [0.        ]]]

Rep 1,001.393:
[[[0.        ]
  [0.08333534]
  [0.08333395]
  [0.08333457]]

 [[0.08333603]
  [0.        ]
  [0.08333313]
  [0.08333384]]

 [[0.08333223]
  [0.08333074]
  [0.        ]
  [0.08333007]]

 [[0.08333481]
  [0.08333334]
  [0.08333194]
  [0.        ]]]

Rep 1,001.253:
[[[0.        ]
  [0.08333442]
  [0.08333331]
  [0.0833342 ]]

 [[0.08333372]
  [0.        ]
  [0.08333296]
  [0.0833339 ]]

 [[0.08333208]
  [0.08333238]
  [0.        ]
  [0.08333191]]

 [[0.08333404]
  [0.08333421]
  [0.08333281]
  [0.        ]]]

Rep 1,001.351:
[[[0.        ]
  [0.08333368]
  [0.0833346 ]
  [0.08333198]]

 [[0.08333513]
  [0.        ]
  [0.08333626]
  [0.08333376]]

 [[0.08333245]
  [0.08333364]
  [0.        ]
  [0.083332  ]]

 [[0.08333081]
  [0.08333239]
  [0.08333331]
  [0.        ]]]

Rep 1,001.208:
[[[0.        ]
  [0.08333644]
  [0.08333275]
  [0.08333446]]

 [[0.08333362]
  [0.        ]
  [0.08333246]
  [0.08333488]]

 [[0.08333043]
  [0.08333415]
  [0.        ]
  [0.08333239]]

 [[0.08333182]
  [0.08333501]
  [0.08333156]
  [0.        ]]]

Rep 1,001.466:
[[[0.        ]
  [0.08333378]
  [0.08333352]
  [0.08333416]]

 [[0.08333249]
  [0.        ]
  [0.08333296]
  [0.08333338]]

 [[0.08333217]
  [0.0833331 ]
  [0.        ]
  [0.08333316]]

 [[0.08333307]
  [0.08333406]
  [0.08333418]
  [0.        ]]]

Rep 1,001.439:
[[[0.        ]
  [0.08333474]
  [0.08333445]
  [0.08333468]]

 [[0.08333284]
  [0.        ]
  [0.08333386]
  [0.08333381]]

 [[0.08333136]
  [0.08333291]
  [0.        ]
  [0.08333242]]

 [[0.08333207]
  [0.08333346]
  [0.08333336]
  [0.        ]]]

Rep 1,001.337:
[[[0.        ]
  [0.08333537]
  [0.08333614]
  [0.08333607]]

 [[0.08333234]
  [0.        ]
  [0.08333124]
  [0.08333138]]

 [[0.08333339]
  [0.0833315 ]
  [0.        ]
  [0.08333264]]

 [[0.08333418]
  [0.08333254]
  [0.0833333 ]
  [0.        ]]]

Rep 1,001.340:
[[[0.        ]
  [0.08333251]
  [0.08333413]
  [0.08333214]]

 [[0.08333342]
  [0.        ]
  [0.08333571]
  [0.08333399]]

 [[0.08333244]
  [0.08333312]
  [0.        ]
  [0.08333308]]

 [[0.08333246]
  [0.08333267]
  [0.08333441]
  [0.        ]]]

Rep 1,001.241:
[[[0.        ]
  [0.08333319]
  [0.08333177]
  [0.08333224]]

 [[0.08333753]
  [0.        ]
  [0.08333498]
  [0.08333521]]

 [[0.08333255]
  [0.08333151]
  [0.        ]
  [0.08333033]]

 [[0.08333482]
  [0.08333364]
  [0.08333224]
  [0.        ]]]

Rep 1,001.658:
[[[0.        ]
  [0.08333538]
  [0.08333467]
  [0.08333465]]

 [[0.08333596]
  [0.        ]
  [0.08333292]
  [0.08333325]]

 [[0.0833322 ]
  [0.08333098]
  [0.        ]
  [0.08333018]]

 [[0.08333445]
  [0.08333308]
  [0.08333223]
  [0.        ]]]

Rep 1,001.138:
[[[0.        ]
  [0.0833336 ]
  [0.08333433]
  [0.08333276]]

 [[0.08333521]
  [0.        ]
  [0.08333594]
  [0.08333427]]

 [[0.08333074]
  [0.08333082]
  [0.        ]
  [0.08333056]]

 [[0.0833339 ]
  [0.08333364]
  [0.08333427]
  [0.        ]]]

Rep 1,001.435:
[[[0.        ]
  [0.0833343 ]
  [0.08333575]
  [0.08333433]]

 [[0.08333378]
  [0.        ]
  [0.08333437]
  [0.08333323]]

 [[0.08333158]
  [0.08333088]
  [0.        ]
  [0.08333132]]

 [[0.08333337]
  [0.08333277]
  [0.08333428]
  [0.        ]]]

Rep 1,001.289:
[[[0.        ]
  [0.083334  ]
  [0.08333412]
  [0.08333339]]

 [[0.08333506]
  [0.        ]
  [0.08333462]
  [0.08333389]]

 [[0.08333186]
  [0.08333139]
  [0.        ]
  [0.08333146]]

 [[0.08333391]
  [0.08333304]
  [0.08333331]
  [0.        ]]]

Rep 1,001.464:
[[[0.        ]
  [0.08333445]
  [0.08333529]
  [0.08333267]]

 [[0.08333241]
  [0.        ]
  [0.08333603]
  [0.08333393]]

 [[0.08333115]
  [0.0833331 ]
  [0.        ]
  [0.08333209]]

 [[0.08333112]
  [0.08333343]
  [0.08333433]
  [0.        ]]]

Rep 1,001.209:
[[[0.        ]
  [0.08333583]
  [0.0833362 ]
  [0.0833346 ]]

 [[0.08333392]
  [0.        ]
  [0.08333444]
  [0.0833329 ]]

 [[0.08333191]
  [0.08333226]
  [0.        ]
  [0.08333112]]

 [[0.08333207]
  [0.08333241]
  [0.08333237]
  [0.        ]]]

Rep 1,001.298:
[[[0.        ]
  [0.08333583]
  [0.08333375]
  [0.08333338]]

 [[0.08333265]
  [0.        ]
  [0.08333346]
  [0.08333287]]

 [[0.08333246]
  [0.08333494]
  [0.        ]
  [0.08333238]]

 [[0.08333129]
  [0.08333419]
  [0.08333281]
  [0.        ]]]

Rep 1,001.324:
[[[0.        ]
  [0.08333308]
  [0.08333367]
  [0.08333416]]

 [[0.08333225]
  [0.        ]
  [0.08333343]
  [0.08333385]]

 [[0.083333  ]
  [0.08333351]
  [0.        ]
  [0.08333461]]

 [[0.08333232]
  [0.08333281]
  [0.08333331]
  [0.        ]]]

Rep 1,001.311:
[[[0.        ]
  [0.08333208]
  [0.08333309]
  [0.08333294]]

 [[0.08333291]
  [0.        ]
  [0.08333457]
  [0.08333417]]

 [[0.08333387]
  [0.08333404]
  [0.        ]
  [0.08333489]]

 [[0.08333211]
  [0.08333214]
  [0.08333315]
  [0.        ]]]

Rep 1,001.247:
[[[0.        ]
  [0.08333182]
  [0.08333329]
  [0.08333303]]

 [[0.08333214]
  [0.        ]
  [0.08333467]
  [0.08333452]]

 [[0.08333245]
  [0.08333386]
  [0.        ]
  [0.08333476]]

 [[0.08333197]
  [0.08333309]
  [0.08333441]
  [0.        ]]]

Rep 1,001.254:
[[[0.        ]
  [0.08333509]
  [0.08333541]
  [0.08333416]]

 [[0.08333368]
  [0.        ]
  [0.08333335]
  [0.08333191]]

 [[0.08333373]
  [0.08333306]
  [0.        ]
  [0.08333163]]

 [[0.0833332 ]
  [0.08333249]
  [0.08333236]
  [0.        ]]]

Rep 1,001.262:
[[[0.        ]
  [0.08333446]
  [0.08333413]
  [0.08333473]]

 [[0.08333525]
  [0.        ]
  [0.08333329]
  [0.0833336 ]]

 [[0.08333384]
  [0.0833315 ]
  [0.        ]
  [0.08333179]]

 [[0.08333364]
  [0.08333193]
  [0.08333185]
  [0.        ]]]

Rep 1,001.204:
[[[0.        ]
  [0.08333348]
  [0.08333205]
  [0.08333223]]

 [[0.08333376]
  [0.        ]
  [0.08333439]
  [0.08333462]]

 [[0.08333279]
  [0.08333462]
  [0.        ]
  [0.08333369]]

 [[0.08333177]
  [0.08333393]
  [0.08333272]
  [0.        ]]]

Rep 1,001.344:
[[[0.        ]
  [0.08333503]
  [0.08333411]
  [0.08333524]]

 [[0.08333296]
  [0.        ]
  [0.083333  ]
  [0.08333411]]

 [[0.08333109]
  [0.08333178]
  [0.        ]
  [0.08333232]]

 [[0.08333313]
  [0.08333393]
  [0.08333331]
  [0.        ]]]

Rep 1,001.266:
[[[0.        ]
  [0.08333565]
  [0.08333458]
  [0.08333436]]

 [[0.08333617]
  [0.        ]
  [0.08333328]
  [0.08333283]]

 [[0.08333459]
  [0.08333283]
  [0.        ]
  [0.08333093]]

 [[0.08333322]
  [0.08333138]
  [0.08333017]
  [0.        ]]]

Rep 1,001.194:
[[[0.        ]
  [0.08333229]
  [0.08333389]
  [0.0833334 ]]

 [[0.08333276]
  [0.        ]
  [0.08333419]
  [0.08333364]]

 [[0.08333366]
  [0.08333319]
  [0.        ]
  [0.08333439]]

 [[0.08333298]
  [0.0833322 ]
  [0.08333343]
  [0.        ]]]

Rep 1,001.486:
[[[0.        ]
  [0.08333436]
  [0.08333413]
  [0.08333398]]

 [[0.0833327 ]
  [0.        ]
  [0.0833343 ]
  [0.08333395]]

 [[0.08333174]
  [0.08333426]
  [0.        ]
  [0.08333356]]

 [[0.08333065]
  [0.0833331 ]
  [0.08333323]
  [0.        ]]]

Rep 1,001.208:
[[[0.        ]
  [0.08333419]
  [0.08333188]
  [0.08333324]]

 [[0.08333483]
  [0.        ]
  [0.08333389]
  [0.08333517]]

 [[0.08333205]
  [0.08333321]
  [0.        ]
  [0.08333243]]

 [[0.08333287]
  [0.08333403]
  [0.08333223]
  [0.        ]]]

Rep 1,001.195:
[[[0.        ]
  [0.08333466]
  [0.0833352 ]
  [0.08333372]]

 [[0.08333405]
  [0.        ]
  [0.0833342 ]
  [0.08333326]]

 [[0.08333286]
  [0.08333243]
  [0.        ]
  [0.08333182]]

 [[0.08333299]
  [0.08333212]
  [0.08333264]
  [0.        ]]]

Rep 1,001.448:
[[[0.        ]
  [0.0833327 ]
  [0.08333464]
  [0.08333319]]

 [[0.08333309]
  [0.        ]
  [0.08333401]
  [0.08333277]]

 [[0.0833331 ]
  [0.08333207]
  [0.        ]
  [0.08333282]]

 [[0.08333372]
  [0.08333292]
  [0.08333492]
  [0.        ]]]

Rep 1,001.987:
[[[0.        ]
  [0.08333422]
  [0.08333235]
  [0.08333431]]

 [[0.0833338 ]
  [0.        ]
  [0.08333305]
  [0.08333514]]

 [[0.08333082]
  [0.0833317 ]
  [0.        ]
  [0.08333198]]

 [[0.08333414]
  [0.08333504]
  [0.08333347]
  [0.        ]]]

Rep 1,001.025:
[[[0.        ]
  [0.08333471]
  [0.08333296]
  [0.08333445]]

 [[0.0833355 ]
  [0.        ]
  [0.08333229]
  [0.08333409]]

 [[0.08333227]
  [0.08333226]
  [0.        ]
  [0.08333153]]

 [[0.08333416]
  [0.08333395]
  [0.08333181]
  [0.        ]]]

Rep 1,001.167:
[[[0.        ]
  [0.08333498]
  [0.08333284]
  [0.08333348]]

 [[0.08333345]
  [0.        ]
  [0.08333379]
  [0.08333521]]

 [[0.08333047]
  [0.08333255]
  [0.        ]
  [0.08333185]]

 [[0.08333299]
  [0.08333515]
  [0.08333322]
  [0.        ]]]

Rep 1,001.447:
[[[0.        ]
  [0.08333348]
  [0.08333305]
  [0.08333477]]

 [[0.08333103]
  [0.        ]
  [0.08333321]
  [0.08333475]]

 [[0.08333093]
  [0.08333296]
  [0.        ]
  [0.08333421]]

 [[0.08333292]
  [0.08333458]
  [0.08333406]
  [0.        ]]]

Rep 1,001.234:
[[[0.        ]
  [0.08333486]
  [0.08333465]
  [0.08333477]]

 [[0.08333452]
  [0.        ]
  [0.08333149]
  [0.08333159]]

 [[0.08333489]
  [0.08333208]
  [0.        ]
  [0.08333197]]

 [[0.08333489]
  [0.08333224]
  [0.08333201]
  [0.        ]]]

Rep 1,001.314:
[[[0.        ]
  [0.08333417]
  [0.08333459]
  [0.08333398]]

 [[0.0833318 ]
  [0.        ]
  [0.08333414]
  [0.0833333 ]]

 [[0.08333224]
  [0.08333437]
  [0.        ]
  [0.08333367]]

 [[0.08333098]
  [0.08333297]
  [0.08333375]
  [0.        ]]]

Rep 1,001.257:
[[[0.        ]
  [0.08333381]
  [0.08333318]
  [0.08333445]]

 [[0.08333343]
  [0.        ]
  [0.08333243]
  [0.08333358]]

 [[0.08333299]
  [0.08333232]
  [0.        ]
  [0.08333295]]

 [[0.08333419]
  [0.0833336 ]
  [0.08333309]
  [0.        ]]]

Rep 1,001.408:
[[[0.        ]
  [0.0833343 ]
  [0.08333384]
  [0.08333334]]

 [[0.0833343 ]
  [0.        ]
  [0.08333417]
  [0.08333368]]

 [[0.08333229]
  [0.08333221]
  [0.        ]
  [0.08333157]]

 [[0.08333396]
  [0.08333347]
  [0.08333281]
  [0.        ]]]

Rep 1,001.304:
[[[0.        ]
  [0.08333423]
  [0.08333589]
  [0.08333492]]

 [[0.08333135]
  [0.        ]
  [0.0833328 ]
  [0.08333147]]

 [[0.08333365]
  [0.08333452]
  [0.        ]
  [0.08333432]]

 [[0.08333157]
  [0.08333196]
  [0.08333325]
  [0.        ]]]

Rep 1,001.414:
[[[0.        ]
  [0.08333632]
  [0.08333478]
  [0.08333416]]

 [[0.08333649]
  [0.        ]
  [0.08333436]
  [0.08333375]]

 [[0.08333312]
  [0.08333223]
  [0.        ]
  [0.08333008]]

 [[0.08333308]
  [0.08333171]
  [0.08332995]
  [0.        ]]]

Rep 1,001.251:
[[[0.        ]
  [0.083334  ]
  [0.08333503]
  [0.0833347 ]]

 [[0.08333263]
  [0.        ]
  [0.08333395]
  [0.08333345]]

 [[0.08333158]
  [0.08333114]
  [0.        ]
  [0.0833327 ]]

 [[0.08333364]
  [0.08333287]
  [0.0833343 ]
  [0.        ]]]

Rep 1,001.446:
[[[0.        ]
  [0.0833331 ]
  [0.08333554]
  [0.0833336 ]]

 [[0.08333143]
  [0.        ]
  [0.08333492]
  [0.08333323]]

 [[0.08333077]
  [0.08333184]
  [0.        ]
  [0.08333271]]

 [[0.0833329 ]
  [0.08333404]
  [0.08333585]
  [0.        ]]]

Rep 1,001.363:
[[[0.        ]
  [0.08333463]
  [0.08333494]
  [0.08333433]]

 [[0.08333588]
  [0.        ]
  [0.08333401]
  [0.08333359]]

 [[0.08333245]
  [0.08333115]
  [0.        ]
  [0.08333095]]

 [[0.08333325]
  [0.0833323 ]
  [0.08333248]
  [0.        ]]]

Rep 1,001.409:
[[[0.        ]
  [0.08333409]
  [0.08333431]
  [0.08333436]]

 [[0.08333195]
  [0.        ]
  [0.08333281]
  [0.0833327 ]]

 [[0.08333286]
  [0.08333426]
  [0.        ]
  [0.08333408]]

 [[0.08333187]
  [0.08333322]
  [0.08333348]
  [0.        ]]]

Rep 1,001.860:
[[[0.        ]
  [0.08333366]
  [0.08333333]
  [0.08333402]]

 [[0.08333662]
  [0.        ]
  [0.08333351]
  [0.08333428]]

 [[0.08333262]
  [0.08333075]
  [0.        ]
  [0.08333061]]

 [[0.08333517]
  [0.08333315]
  [0.08333233]
  [0.        ]]]

Rep 1,001.206:
[[[0.        ]
  [0.08333399]
  [0.08333552]
  [0.08333381]]

 [[0.08333418]
  [0.        ]
  [0.08333405]
  [0.08333282]]

 [[0.08333261]
  [0.08333262]
  [0.        ]
  [0.08333172]]

 [[0.08333248]
  [0.08333282]
  [0.08333339]
  [0.        ]]]

Rep 1,001.449:
[[[0.        ]
  [0.0833326 ]
  [0.08333581]
  [0.0833341 ]]

 [[0.08333236]
  [0.        ]
  [0.08333366]
  [0.08333249]]

 [[0.08333275]
  [0.08333159]
  [0.        ]
  [0.08333313]]

 [[0.08333352]
  [0.08333258]
  [0.08333544]
  [0.        ]]]

Rep 1,001.440:
[[[0.        ]
  [0.08333486]
  [0.0833351 ]
  [0.08333287]]

 [[0.08333516]
  [0.        ]
  [0.08333613]
  [0.08333398]]

 [[0.08333139]
  [0.08333173]
  [0.        ]
  [0.08333118]]

 [[0.08333249]
  [0.08333229]
  [0.08333282]
  [0.        ]]]

Test metrics and hyperparameters logged for tensorboard at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1\test

---------------------------------------------------------------------------

<<<<<<<<<<<< DECODER OUTPUT PLOT (TEST) >>>>>>>>>>>>

Creating decoder output plot for rep '1,001.132' for [m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1...

Decoder output plot for rep '1001.1319' logged at C:\Aryan_Savant\Thesis_Projects\my_work\AFD_thesis\topology_estimation\logs\mass_sp_dm\M004\scene_1\nri\train\etypes=1\m004\apv\set_G\E=f_mlp1_og_D=gru\tswp_0\[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1\test

Testing DataLoader 0: 100%|################################################################| 10/10 [00:03<00:00,  3.26it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       dec/test_loss       │    0.01547831017524004    │
│  enc/test_edge_accuracy   │            0.5            │
│       enc/test_loss       │    -0.6212267279624939    │
│       nri/test_loss       │    -0.6057483553886414    │
└───────────────────────────┴───────────────────────────┘

===========================================================================

Nri model '[m004_(apv+G)]-(E=f_mlp1_og_D=gru)_edge_est_1.1' training completed.


=== EXECUTION COMPLETED ===
Log saved at: 2025-09-13 16:39:23
