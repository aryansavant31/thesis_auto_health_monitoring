Starting run from main script...
Number of nodes: 5
Number of timesteps: 49
Number of dimensions: 4
Encoder(
  (emb_fn_dict): ModuleDict(
    (1/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=196, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
    (1/node_emd2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=8, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
    (1/edge_emd1@): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=8, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
    (2/node_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=8, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
    (2/node_emd2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=8, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
    (2/edge_emd1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=16, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
    (2/edge_emd2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=16, out_features=64, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.0, inplace=False)
        (3): Linear(in_features=64, out_features=32, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.0, inplace=False)
        (6): Linear(in_features=32, out_features=16, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.0, inplace=False)
        (9): Linear(in_features=16, out_features=8, bias=True)
      )
    )
  )
  (attention_layer_dict): ModuleDict()
  (output_layer): Linear(in_features=8, out_features=2, bias=True)
)
Decoder(
  (edge_mlp_fn): ModuleList(
    (0-1): 2 x MLP(
      (layers): ModuleList(
        (0): Linear(in_features=128, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=64, out_features=32, bias=True)
        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): Tanh()
        (7): Dropout(p=0, inplace=False)
        (8): Linear(in_features=32, out_features=16, bias=True)
        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): Tanh()
        (11): Dropout(p=0, inplace=False)
        (12): Linear(in_features=16, out_features=64, bias=True)
        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (recurrent_emb_fn): GRU(
    (input_u): Linear(in_features=4, out_features=64, bias=True)
    (hidden_u): Linear(in_features=64, out_features=64, bias=True)
    (input_r): Linear(in_features=4, out_features=64, bias=True)
    (hidden_r): Linear(in_features=64, out_features=64, bias=True)
    (input_h): Linear(in_features=4, out_features=64, bias=True)
    (hidden_h): Linear(in_features=64, out_features=64, bias=True)
  )
  (mean_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Tanh()
      (3): Dropout(p=0, inplace=False)
      (4): Linear(in_features=64, out_features=32, bias=True)
      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): Tanh()
      (7): Dropout(p=0, inplace=False)
      (8): Linear(in_features=32, out_features=16, bias=True)
      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): Tanh()
      (11): Dropout(p=0, inplace=False)
      (12): Linear(in_features=16, out_features=64, bias=True)
      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (var_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Tanh()
      (3): Dropout(p=0, inplace=False)
      (4): Linear(in_features=64, out_features=32, bias=True)
      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): Tanh()
      (7): Dropout(p=0, inplace=False)
      (8): Linear(in_features=32, out_features=16, bias=True)
      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): Tanh()
      (11): Dropout(p=0, inplace=False)
      (12): Linear(in_features=16, out_features=64, bias=True)
      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (mean_output_layer): Linear(in_features=64, out_features=4, bias=True)
  (var_output_layer): Linear(in_features=64, out_features=4, bias=True)
)
NRI(
  (encoder): Encoder(
    (emb_fn_dict): ModuleDict(
      (1/node_emd1): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=196, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
      (1/node_emd2): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=8, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
      (1/edge_emd1@): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=8, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
      (2/node_emd1): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=8, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
      (2/node_emd2): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=8, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
      (2/edge_emd1): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=16, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
      (2/edge_emd2): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=16, out_features=64, bias=True)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=64, out_features=32, bias=True)
          (4): ReLU()
          (5): Dropout(p=0.0, inplace=False)
          (6): Linear(in_features=32, out_features=16, bias=True)
          (7): ReLU()
          (8): Dropout(p=0.0, inplace=False)
          (9): Linear(in_features=16, out_features=8, bias=True)
        )
      )
    )
    (attention_layer_dict): ModuleDict()
    (output_layer): Linear(in_features=8, out_features=2, bias=True)
  )
  (decoder): Decoder(
    (edge_mlp_fn): ModuleList(
      (0-1): 2 x MLP(
        (layers): ModuleList(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0, inplace=False)
          (4): Linear(in_features=64, out_features=32, bias=True)
          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (6): Tanh()
          (7): Dropout(p=0, inplace=False)
          (8): Linear(in_features=32, out_features=16, bias=True)
          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (10): Tanh()
          (11): Dropout(p=0, inplace=False)
          (12): Linear(in_features=16, out_features=64, bias=True)
          (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (recurrent_emb_fn): GRU(
      (input_u): Linear(in_features=4, out_features=64, bias=True)
      (hidden_u): Linear(in_features=64, out_features=64, bias=True)
      (input_r): Linear(in_features=4, out_features=64, bias=True)
      (hidden_r): Linear(in_features=64, out_features=64, bias=True)
      (input_h): Linear(in_features=4, out_features=64, bias=True)
      (hidden_h): Linear(in_features=64, out_features=64, bias=True)
    )
    (mean_mlp): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=64, out_features=32, bias=True)
        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): Tanh()
        (7): Dropout(p=0, inplace=False)
        (8): Linear(in_features=32, out_features=16, bias=True)
        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): Tanh()
        (11): Dropout(p=0, inplace=False)
        (12): Linear(in_features=16, out_features=64, bias=True)
        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (var_mlp): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Tanh()
        (3): Dropout(p=0, inplace=False)
        (4): Linear(in_features=64, out_features=32, bias=True)
        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (6): Tanh()
        (7): Dropout(p=0, inplace=False)
        (8): Linear(in_features=32, out_features=16, bias=True)
        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (10): Tanh()
        (11): Dropout(p=0, inplace=False)
        (12): Linear(in_features=16, out_features=64, bias=True)
        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (mean_output_layer): Linear(in_features=64, out_features=4, bias=True)
    (var_output_layer): Linear(in_features=64, out_features=4, bias=True)
  )
)
Training: |                                                                                                      | 0/? [00:00<?, ?it/s]Training:   0%|                                                                                                  | 0/5 [00:00<?, ?it/s]Epoch 0:   0%|                                                                                                   | 0/5 [00:00<?, ?it/s]Epoch 0:  20%|##################2                                                                        | 1/5 [00:00<00:02,  1.98it/s]Epoch 0:  20%|################2                                                                | 1/5 [00:00<00:02,  1.98it/s, v_num=23]Epoch 0:  40%|################################4                                                | 2/5 [00:00<00:01,  2.37it/s, v_num=23]Epoch 0:  40%|################################4                                                | 2/5 [00:00<00:01,  2.36it/s, v_num=23]Epoch 0:  60%|################################################6                                | 3/5 [00:01<00:00,  2.59it/s, v_num=23]Epoch 0:  60%|################################################6                                | 3/5 [00:01<00:00,  2.59it/s, v_num=23]Epoch 0:  80%|################################################################8                | 4/5 [00:01<00:00,  2.70it/s, v_num=23]Epoch 0:  80%|################################################################8                | 4/5 [00:01<00:00,  2.69it/s, v_num=23]Epoch 0: 100%|#################################################################################| 5/5 [00:01<00:00,  2.74it/s, v_num=23]Epoch 0: 100%|#################################################################################| 5/5 [00:01<00:00,  2.74it/s, v_num=23]Epoch 0: 100%|#| 5/5 [00:01<00:00,  2.73it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 0:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loss_decodEpoch 1:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loss_decodEpoch 1:  20%|2| 1/5 [00:00<00:01,  3.33it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  20%|2| 1/5 [00:00<00:01,  3.33it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  40%|4| 2/5 [00:00<00:00,  3.24it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  40%|4| 2/5 [00:00<00:00,  3.24it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  60%|6| 3/5 [00:00<00:00,  3.21it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  60%|6| 3/5 [00:00<00:00,  3.21it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  80%|8| 4/5 [00:01<00:00,  3.14it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1:  80%|8| 4/5 [00:01<00:00,  3.14it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1: 100%|#| 5/5 [00:01<00:00,  3.13it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1: 100%|#| 5/5 [00:01<00:00,  3.13it/s, v_num=23, train_edge_accuracy=0.510, train_loss=148.0, train_loss_encoder=-2.69, train_loEpoch 1: 100%|#| 5/5 [00:01<00:00,  3.13it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 1:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loss_decodEpoch 2:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loss_decodEpoch 2:  20%|2| 1/5 [00:00<00:01,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  20%|2| 1/5 [00:00<00:01,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  40%|4| 2/5 [00:00<00:00,  3.23it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  40%|4| 2/5 [00:00<00:00,  3.23it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  60%|6| 3/5 [00:00<00:00,  3.21it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  60%|6| 3/5 [00:00<00:00,  3.20it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  80%|8| 4/5 [00:01<00:00,  3.19it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2:  80%|8| 4/5 [00:01<00:00,  3.19it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2: 100%|#| 5/5 [00:01<00:00,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2: 100%|#| 5/5 [00:01<00:00,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=131.0, train_loss_encoder=-2.68, train_loEpoch 2: 100%|#| 5/5 [00:01<00:00,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 2:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loss_decodEpoch 3:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loss_decodEpoch 3:  20%|2| 1/5 [00:00<00:01,  3.19it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  20%|2| 1/5 [00:00<00:01,  3.19it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  40%|4| 2/5 [00:00<00:00,  3.25it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  40%|4| 2/5 [00:00<00:00,  3.25it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  60%|6| 3/5 [00:00<00:00,  3.30it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  60%|6| 3/5 [00:00<00:00,  3.30it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  80%|8| 4/5 [00:01<00:00,  3.29it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3:  80%|8| 4/5 [00:01<00:00,  3.28it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3: 100%|#| 5/5 [00:01<00:00,  3.27it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3: 100%|#| 5/5 [00:01<00:00,  3.27it/s, v_num=23, train_edge_accuracy=0.510, train_loss=119.0, train_loss_encoder=-2.67, train_loEpoch 3: 100%|#| 5/5 [00:01<00:00,  3.26it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 3:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loss_decodEpoch 4:   0%| | 0/5 [00:00<?, ?it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loss_decodEpoch 4:  20%|2| 1/5 [00:00<00:01,  3.24it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  20%|2| 1/5 [00:00<00:01,  3.23it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  40%|4| 2/5 [00:00<00:00,  3.29it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  40%|4| 2/5 [00:00<00:00,  3.29it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  60%|6| 3/5 [00:00<00:00,  3.30it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  60%|6| 3/5 [00:00<00:00,  3.30it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  80%|8| 4/5 [00:01<00:00,  3.27it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4:  80%|8| 4/5 [00:01<00:00,  3.27it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4: 100%|#| 5/5 [00:01<00:00,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4: 100%|#| 5/5 [00:01<00:00,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.66, train_loEpoch 4: 100%|#| 5/5 [00:01<00:00,  3.18it/s, v_num=23, train_edge_accuracy=0.510, train_loss=97.60, train_loss_encoder=-2.67, train_loEpoch 4: 100%|#| 5/5 [00:01<00:00,  3.01it/s, v_num=23, train_edge_accuracy=0.510, train_loss=97.60, train_loss_encoder=-2.67, train_lo
