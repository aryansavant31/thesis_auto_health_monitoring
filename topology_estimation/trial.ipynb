{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9906d9cd",
   "metadata": {},
   "source": [
    "# Topology Estimation Model\n",
    "\n",
    "This notebook contains all the steps of topology model developement. \n",
    "\n",
    "In this notebook, the model can be:\n",
    "- trained and tested\n",
    "- loaded and run for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a89842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097a33d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run from main script...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting run from main script...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbe905",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7f0580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 332, \n",
      "Train: 265 [OK=265, NOK=0, UK=0], Test: 33 [OK=33, NOK=0, UK=0], Val: 33 [OK=33, NOK=0, UK=0], \n",
      "Remainder: 1 [OK=1, NOK=0, UK=0]\n"
     ]
    }
   ],
   "source": [
    "from data.prep import DataPreprocessor\n",
    "from data.config import DataConfig\n",
    "\n",
    "data_config = DataConfig(run_type='train')\n",
    "data_preprocessor = DataPreprocessor(package='topology_estimation')\n",
    "\n",
    "# load datalaoders\n",
    "train_package, test_package, val_package = data_preprocessor.get_training_data_package(data_config, train_rt=0.8, test_rt=0.1, val_rt=0.1, num_workers=0)\n",
    "\n",
    "train_loader, train_data_stats = train_package\n",
    "test_loader, test_data_stats = test_package\n",
    "val_loader, val_data_stats = val_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5a9b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_mass_1', '2_mass_2', '3_mass_3', '4_mass_4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessor.data_config.node_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df95956",
   "metadata": {},
   "source": [
    "#### Set the number of timesteps and dimensions of the node data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8343f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4\n",
      "Number of timesteps: 600\n",
      "Number of dimensions: 3\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "\n",
    "n_nodes = data[0].shape[1]\n",
    "n_timesteps = data[0].shape[2]\n",
    "n_dims = data[0].shape[3]\n",
    "\n",
    "print(f\"Number of nodes: {n_nodes}\")\n",
    "print(f\"Number of timesteps: {n_timesteps}\")  \n",
    "print(f\"Number of dimensions: {n_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b540dc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b93d1b",
   "metadata": {},
   "source": [
    "### Prepare the relation matrix for encoder input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0fcf9",
   "metadata": {},
   "source": [
    "##### Generate off-diagonal fully connected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f82490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]])\n",
      "Receiver relation matrix shape: torch.Size([50, 12, 4])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "Sender relation matrix shape: torch.Size([50, 12, 4])\n"
     ]
    }
   ],
   "source": [
    "from settings.manager import NRITrainManager\n",
    "from graph_structures import RelationMatrixMaker\n",
    "\n",
    "nri_config = NRITrainManager(data_config)\n",
    "\n",
    "rm = RelationMatrixMaker(nri_config.spf_config)\n",
    "rel_loader = rm.get_relation_matrix_loader(train_loader)\n",
    "\n",
    "rel = next(iter(rel_loader))\n",
    "\n",
    "print(rel[0][0])\n",
    "print(f\"Receiver relation matrix shape: {rel[0].shape}\")\n",
    "\n",
    "print(rel[1][0])\n",
    "print(f\"Sender relation matrix shape: {rel[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f6f7e",
   "metadata": {},
   "source": [
    "## 2. Load and prepare the topology estimator model blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc088ce8",
   "metadata": {},
   "source": [
    "### Prepare params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd5cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder model parameters:\n",
      "----------\n",
      "n_edge_types: 2\n",
      "is_residual_connection: True\n",
      "do_prob: {'mlp': 0.0, 'cnn': 0.0}\n",
      "is_batch_norm: {'mlp': True, 'cnn': False}\n",
      "attention_output_size: 5\n",
      "pipeline: [['1/node_emd.1', 'mlp'], ['1/node_emd.2', 'mlp'], ['1/pairwise_op', 'mean'], ['1/edge_emd.1.@', 'mlp'], ['2/aggregate', 'mean'], ['2/node_emd.1', 'mlp'], ['2/node_emd.2', 'mlp'], ['2/pairwise_op', 'concat'], ['2/edge_emd.1', 'mlp'], ['2/edge_emd.2', 'mlp']]\n",
      "edge_emb_configs: {'mlp': [[64, 'relu'], [32, 'relu'], [16, 'relu'], [8, None]], 'cnn': [[5, 2, 64], [8]]}\n",
      "node_emb_configs: {'mlp': [[64, 'relu'], [32, 'relu'], [16, 'relu'], [8, None]], 'cnn': [[5, 2, 64], [8]]}\n",
      "n_comps: 600\n",
      "n_dims: 3\n",
      "\n",
      "Encoder run parameters:\n",
      "----------\n",
      "domain_config: {'type': 'time', 'fs': [1000], 'cutoff_freq': 0}\n",
      "raw_data_norm: None\n",
      "feat_configs: []\n",
      "reduc_config: None\n",
      "feat_norm: None\n",
      "data_stats: {'mean': tensor([[[-0.0007,  0.0034, -0.0027]],\n",
      "\n",
      "        [[-0.0009,  0.0053, -0.0037]],\n",
      "\n",
      "        [[ 0.0015,  0.0056, -0.0045]],\n",
      "\n",
      "        [[-0.0021,  0.0088,  0.0009]]]), 'std': tensor([[[0.0484, 0.0927, 0.0554]],\n",
      "\n",
      "        [[0.0386, 0.1414, 0.0538]],\n",
      "\n",
      "        [[0.0387, 0.1766, 0.0522]],\n",
      "\n",
      "        [[0.7177, 0.2075, 0.1311]]]), 'min': tensor([[[-0.1066, -0.1838, -0.1298]],\n",
      "\n",
      "        [[-0.0903, -0.2605, -0.1246]],\n",
      "\n",
      "        [[-0.0900, -0.2870, -0.0809]],\n",
      "\n",
      "        [[-1.0972, -0.3842, -0.2921]]]), 'max': tensor([[[0.1106, 0.2104, 0.1070]],\n",
      "\n",
      "        [[0.0876, 0.2699, 0.1065]],\n",
      "\n",
      "        [[0.0890, 0.2806, 0.1246]],\n",
      "\n",
      "        [[1.0901, 0.4024, 0.3126]]])}\n",
      "\n",
      "Decoder model parameters:\n",
      "----------\n",
      "n_edge_types: 2\n",
      "msg_out_size: 64\n",
      "do_prob: 0\n",
      "is_batch_norm: True\n",
      "recur_emb_type: gru\n",
      "edge_mlp_config: [[64, 'tanh'], [32, 'tanh'], [16, 'tanh'], [64, None]]\n",
      "out_mlp_config: [[64, 'tanh'], [32, 'tanh'], [16, 'tanh'], [64, None]]\n",
      "n_dims: 3\n",
      "\n",
      "Decoder run parameters:\n",
      "----------\n",
      "temp: 1.0\n",
      "is_hard: True\n",
      "domain_config: {'type': 'time', 'fs': [1000], 'cutoff_freq': 0}\n",
      "raw_data_norm: None\n",
      "feat_configs: []\n",
      "feat_norm: None\n",
      "reduc_config: None\n",
      "skip_first_edge_type: True\n",
      "pred_steps: 1\n",
      "is_burn_in: False\n",
      "burn_in_steps: 1\n",
      "is_dynamic_graph: False\n",
      "data_stats: {'mean': tensor([[[-0.0007,  0.0034, -0.0027]],\n",
      "\n",
      "        [[-0.0009,  0.0053, -0.0037]],\n",
      "\n",
      "        [[ 0.0015,  0.0056, -0.0045]],\n",
      "\n",
      "        [[-0.0021,  0.0088,  0.0009]]]), 'std': tensor([[[0.0484, 0.0927, 0.0554]],\n",
      "\n",
      "        [[0.0386, 0.1414, 0.0538]],\n",
      "\n",
      "        [[0.0387, 0.1766, 0.0522]],\n",
      "\n",
      "        [[0.7177, 0.2075, 0.1311]]]), 'min': tensor([[[-0.1066, -0.1838, -0.1298]],\n",
      "\n",
      "        [[-0.0903, -0.2605, -0.1246]],\n",
      "\n",
      "        [[-0.0900, -0.2870, -0.0809]],\n",
      "\n",
      "        [[-1.0972, -0.3842, -0.2921]]]), 'max': tensor([[[0.1106, 0.2104, 0.1070]],\n",
      "\n",
      "        [[0.0876, 0.2699, 0.1065]],\n",
      "\n",
      "        [[0.0890, 0.2806, 0.1246]],\n",
      "\n",
      "        [[1.0901, 0.4024, 0.3126]]])}\n"
     ]
    }
   ],
   "source": [
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from torchinfo import summary\n",
    "import inspect\n",
    "\n",
    "# encoder params\n",
    "req_enc_model_params = inspect.signature(Encoder.__init__).parameters.keys()\n",
    "req_enc_run_params = inspect.signature(Encoder.set_run_params).parameters.keys()\n",
    "\n",
    "enc_model_params = {\n",
    "    key.removesuffix('_enc'): value for key, value in nri_config.__dict__.items() if key.removesuffix('_enc') in req_enc_model_params\n",
    "}\n",
    "enc_run_params = {\n",
    "    key.removeprefix('enc_'): value for key, value in nri_config.__dict__.items() if key.removeprefix('enc_') in req_enc_run_params\n",
    "}\n",
    "enc_run_params['data_stats'] = train_data_stats\n",
    "\n",
    "# decoder params\n",
    "req_dec_model_params = inspect.signature(Decoder.__init__).parameters.keys()\n",
    "req_dec_run_params = inspect.signature(Decoder.set_run_params).parameters.keys()\n",
    "\n",
    "dec_model_params = {\n",
    "    key.removesuffix('_dec'): value for key, value in nri_config.__dict__.items() if key.removesuffix('_dec') in req_dec_model_params\n",
    "}\n",
    "dec_run_params = {\n",
    "    key.removeprefix('dec_'): value for key, value in nri_config.__dict__.items() if key.removeprefix('dec_') in req_dec_run_params\n",
    "}\n",
    "dec_run_params['data_stats'] = train_data_stats\n",
    "\n",
    "# get n_comps and n_dims for encoder and decoder\n",
    "none_dict = {param: None for param in inspect.signature(Encoder).parameters.keys()}\n",
    "pre_enc = Encoder(**none_dict)\n",
    "pre_enc.set_run_params(**enc_run_params)\n",
    "n_comps, n_dims = pre_enc.process_input_data(data[0], get_data_shape=True)\n",
    "\n",
    "enc_model_params['n_comps'] = n_comps\n",
    "enc_model_params['n_dims'] = n_dims\n",
    "\n",
    "dec_model_params['n_dims'] = n_dims\n",
    "\n",
    "print(\"Encoder model parameters:\")\n",
    "print(10 * \"-\")\n",
    "for key, value in enc_model_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nEncoder run parameters:\")\n",
    "print(10 * \"-\")\n",
    "for key, value in enc_run_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nDecoder model parameters:\")\n",
    "print(10 * \"-\")\n",
    "for key, value in dec_model_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nDecoder run parameters:\")\n",
    "print(10 * \"-\")\n",
    "for key, value in dec_run_params.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c45280",
   "metadata": {},
   "source": [
    "### Make NRI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4dd464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRI Model Summary:\n",
      "NRI(\n",
      "  (encoder): Encoder(\n",
      "    (emb_fn_dict): ModuleDict(\n",
      "      (1/node_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=1800, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1/node_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1/edge_emd1@): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2/node_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2/node_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2/edge_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2/edge_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU()\n",
      "          (11): Dropout(p=0.0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=8, bias=True)\n",
      "          (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attention_layer_dict): ModuleDict()\n",
      "    (output_layer): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (edge_mlp_fn): ModuleList(\n",
      "      (0-1): 2 x MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Tanh()\n",
      "          (3): Dropout(p=0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): Tanh()\n",
      "          (7): Dropout(p=0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): Tanh()\n",
      "          (11): Dropout(p=0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (recurrent_emb_fn): GRU(\n",
      "      (input_u): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (hidden_u): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (input_r): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (hidden_r): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (input_h): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (hidden_h): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (mean_mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (var_mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (mean_output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      "    (var_output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nri import NRI\n",
    "\n",
    "nri_model = NRI(enc_model_params, dec_model_params)\n",
    "nri_model.set_run_params(enc_run_params, dec_run_params, nri_config.temp, nri_config.is_hard)\n",
    "\n",
    "\n",
    "print(\"\\nNRI Model Summary:\")\n",
    "# print(summary(nri_model, (train_loader.batch_size, n_nodes, n_timesteps, n_dims)))\n",
    "print(nri_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef3fa60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.custom_loader import CombinedDataLoader\n",
    "\n",
    "train_loader_full = CombinedDataLoader(train_loader, rel_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38adb53",
   "metadata": {},
   "source": [
    "## 3. Training NRI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c38b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'edge_estimator_2.1' already exists in the log path 'c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_thesis\\topology_estimation\\logs\\mass_sp_dm\\M004\\scene_1\\nri\\train\\etypes=2\\edge_estimator_2.1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Anaconda3\\envs\\afd_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrote 'edge_estimator_2.1' from the log path c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_thesis\\topology_estimation\\logs\\mass_sp_dm\\M004\\scene_1\\nri\\train\\etypes=2\\edge_estimator_2.1.\n",
      "Model parameters saved to c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_thesis\\topology_estimation\\logs\\mass_sp_dm\\M004\\scene_1\\nri\\train\\etypes=2\\edge_estimator_2.1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 140 K  | train\n",
      "1 | decoder | Decoder | 54.7 K | train\n",
      "--------------------------------------------\n",
      "195 K     Trainable params\n",
      "0         Non-trainable params\n",
      "195 K     Total params\n",
      "0.781     Total estimated model params size (MB)\n",
      "169       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s] train start time: 1754979395.272113\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  0.23it/s, v_num=_2.1, train_loss=929.0, train_loss_encoder=-2.02, train_loss_decoder=931.0, train_edge_accuracy=0.228]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:21<00:00,  0.23it/s, v_num=_2.1, train_loss=929.0, train_loss_encoder=-2.02, train_loss_decoder=931.0, train_edge_accuracy=0.228]\n",
      "\n",
      "Training completed in 105.38 seconds or 1.76 minutes or 0.029272621141539678 hours.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from utils.custom_loader import CombinedDataLoader\n",
    "\n",
    "nri_model.set_training_params()\n",
    "\n",
    "# get log path\n",
    "train_log_path = nri_config.get_train_log_path(n_comps=enc_model_params['n_comps'], n_dim=dec_model_params['n_dims'])\n",
    "\n",
    "if nri_config.is_log:\n",
    "    nri_config.save_params()\n",
    "    logger = TensorBoardLogger(os.path.dirname(train_log_path), name=\"\", version=os.path.basename(train_log_path))\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=nri_config.max_epochs,\n",
    "    logger=logger,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=1,)\n",
    "\n",
    "trainer.fit(model=nri_model, train_dataloaders=CombinedDataLoader(train_loader, rel_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa86d6",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e785c7",
   "metadata": {},
   "source": [
    "### Prep params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36b12cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder model parameters:\n",
      "----------\n",
      "n_edge_types: 1\n",
      "msg_out_size: 64\n",
      "do_prob: 0\n",
      "is_batch_norm: True\n",
      "recur_emb_type: gru\n",
      "edge_mlp_config: [[64, 'tanh'], [32, 'tanh'], [16, 'tanh'], [64, None]]\n",
      "out_mlp_config: [[64, 'tanh'], [32, 'tanh'], [16, 'tanh'], [64, None]]\n",
      "n_dims: 3\n",
      "\n",
      "Decoder run parameters:\n",
      "----------\n",
      "domain_config: {'type': 'time', 'fs': [1000], 'cutoff_freq': 0}\n",
      "raw_data_norm: None\n",
      "feat_configs: []\n",
      "reduc_config: None\n",
      "feat_norm: None\n",
      "skip_first_edge_type: False\n",
      "pred_steps: 1\n",
      "is_burn_in: False\n",
      "burn_in_steps: 1\n",
      "is_dynamic_graph: False\n",
      "temp: 1.0\n",
      "is_hard: True\n",
      "data_stats: {'mean': tensor([[[-0.0004,  0.0020, -0.0032]],\n",
      "\n",
      "        [[-0.0014,  0.0032, -0.0026]],\n",
      "\n",
      "        [[ 0.0012,  0.0016, -0.0034]],\n",
      "\n",
      "        [[-0.0033,  0.0023, -0.0021]]]), 'std': tensor([[[0.0489, 0.0939, 0.0552]],\n",
      "\n",
      "        [[0.0390, 0.1421, 0.0515]],\n",
      "\n",
      "        [[0.0389, 0.1787, 0.0517]],\n",
      "\n",
      "        [[0.7172, 0.2102, 0.1331]]]), 'min': tensor([[[-0.1066, -0.1838, -0.1298]],\n",
      "\n",
      "        [[-0.0903, -0.2605, -0.1246]],\n",
      "\n",
      "        [[-0.0900, -0.2870, -0.0807]],\n",
      "\n",
      "        [[-1.0972, -0.3842, -0.2921]]]), 'max': tensor([[[0.1106, 0.2104, 0.1070]],\n",
      "\n",
      "        [[0.0876, 0.2699, 0.1065]],\n",
      "\n",
      "        [[0.0890, 0.2806, 0.1246]],\n",
      "\n",
      "        [[1.0901, 0.4024, 0.3126]]])}\n",
      "\n",
      "Edge matrix\n",
      "----------\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "\n",
      "Edge matrix shape: torch.Size([50, 12, 1])\n"
     ]
    }
   ],
   "source": [
    "from settings.manager import DecoderTrainManager\n",
    "from decoder import Decoder\n",
    "from torchinfo import summary\n",
    "import inspect\n",
    "\n",
    "dec_config = DecoderTrainManager(data_config)\n",
    "\n",
    "# decoder params\n",
    "req_dec_model_params = inspect.signature(Decoder.__init__).parameters.keys()\n",
    "req_dec_run_params = inspect.signature(Decoder.set_run_params).parameters.keys()\n",
    "\n",
    "dec_model_params = {\n",
    "    key.removesuffix('_dec'): value for key, value in dec_config.__dict__.items() if key.removesuffix('_dec') in req_dec_model_params\n",
    "}\n",
    "dec_model_params['n_dims'] = n_dims  \n",
    "\n",
    "dec_run_params = {\n",
    "    key.removeprefix('dec_'): value for key, value in dec_config.__dict__.items() if key.removeprefix('dec_') in req_dec_run_params\n",
    "}\n",
    "dec_run_params['data_stats'] = train_data_stats\n",
    "\n",
    "edge_matrix = 0.5*(rel[0] + rel[1]).sum(dim=2, keepdim=True) \n",
    "\n",
    "print(\"Decoder model parameters:\")\n",
    "print(10 * \"-\")\n",
    "for key, value in dec_model_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nDecoder run parameters:\")\n",
    "print(10 * \"-\")\n",
    "for key, value in dec_run_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nEdge matrix\")\n",
    "print(10 * \"-\")\n",
    "print(edge_matrix[0])\n",
    "print(f\"\\nEdge matrix shape: {edge_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5a665",
   "metadata": {},
   "source": [
    "### Make Deocder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d24440ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Model Summary:\n",
      "Decoder(\n",
      "  (edge_mlp_fn): ModuleList(\n",
      "    (0): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (recurrent_emb_fn): GRU(\n",
      "    (input_u): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (hidden_u): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (input_r): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (hidden_r): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (input_h): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (hidden_h): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (mean_mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Tanh()\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Tanh()\n",
      "      (7): Dropout(p=0, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Tanh()\n",
      "      (11): Dropout(p=0, inplace=False)\n",
      "      (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (var_mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Tanh()\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Tanh()\n",
      "      (7): Dropout(p=0, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Tanh()\n",
      "      (11): Dropout(p=0, inplace=False)\n",
      "      (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (mean_output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (var_output_layer): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Decoder(**dec_model_params)\n",
    "decoder_model.set_run_params(**dec_run_params)\n",
    "\n",
    "print(\"\\nDecoder Model Summary:\")\n",
    "#print(summary(decoder_model, (train_loader.batch_size, n_nodes, n_timesteps, n_dims)))\n",
    "print(decoder_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ce75a",
   "metadata": {},
   "source": [
    "## Train Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a59cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'decoder_1.1' already exists in the log path 'c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_thesis\\topology_estimation\\logs\\mass_sp_dm\\M004\\scene_1\\decoder\\train\\etypes=1\\decoder_1.1'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type       | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | edge_mlp_fn       | ModuleList | 12.3 K | train\n",
      "1 | recurrent_emb_fn  | GRU        | 13.2 K | train\n",
      "2 | mean_mlp          | MLP        | 8.2 K  | train\n",
      "3 | var_mlp           | MLP        | 8.2 K  | train\n",
      "4 | mean_output_layer | Linear     | 195    | train\n",
      "5 | var_output_layer  | Linear     | 195    | train\n",
      "---------------------------------------------------------\n",
      "42.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.4 K    Total params\n",
      "0.169     Total estimated model params size (MB)\n",
      "52        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwrote 'decoder_1.1' from the log path c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_thesis\\topology_estimation\\logs\\mass_sp_dm\\M004\\scene_1\\decoder\\train\\etypes=1\\decoder_1.1.\n",
      "Model parameters saved to c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_thesis\\topology_estimation\\logs\\mass_sp_dm\\M004\\scene_1\\decoder\\train\\etypes=1\\decoder_1.1.\n",
      "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s] train start time: 1754865962.40914\n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  0.22it/s, v_num=_1.1, train_loss=992.0]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:22<00:00,  0.22it/s, v_num=_1.1, train_loss=992.0]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from utils.custom_loader import CombinedDataLoader\n",
    "\n",
    "decoder_model.set_training_params()\n",
    "\n",
    "# get log path\n",
    "train_log_path = dec_config.get_train_log_path(n_dim=dec_model_params['n_dims'])\n",
    "\n",
    "if dec_config.is_log:\n",
    "    dec_config.save_params()\n",
    "    logger = TensorBoardLogger(os.path.dirname(train_log_path), name=\"\", version=os.path.basename(train_log_path))\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=dec_config.max_epochs,\n",
    "    logger=logger,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=1,)\n",
    "\n",
    "trainer.fit(model=decoder_model, train_dataloaders=CombinedDataLoader(train_loader, rel_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dac9c2",
   "metadata": {},
   "source": [
    "#### Plot and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os\n",
    "\n",
    "event_dir = os.path.join('model_logs', 'trials', 'nri_model_trial3', 'version_0')\n",
    "print(event_dir)\n",
    "\n",
    "ea = event_accumulator.EventAccumulator(event_dir)\n",
    "ea.Reload()\n",
    "\n",
    "# List all tags\n",
    "# print(ea.Tags())\n",
    "\n",
    "loss_events = ea.Scalars('train_loss')\n",
    "losses = [event.value for event in loss_events]\n",
    "steps = [event.step for event in loss_events]\n",
    "\n",
    "print(\"Steps:\", steps)\n",
    "print(\"Losses:\", losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import io\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, losses, label='Train Loss')\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "# Convert matplotlib fig to image\n",
    "buf = io.BytesIO()\n",
    "fig.savefig(buf, format='png', dpi=1000)\n",
    "buf.seek(0)\n",
    "image = Image.open(buf)\n",
    "image_np = np.array(image)\n",
    "\n",
    "writer = SummaryWriter(\"model_logs\\\\trials\\\\nri_model_trial3\")\n",
    "\n",
    "writer.add_image(\"test_plot\", image_np.transpose(2, 0, 1), global_step=0)\n",
    "buf.close()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeab4bd",
   "metadata": {},
   "source": [
    "### Trying the config file stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198706c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7affc556",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'augment'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtopology_estimation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainNRIConfig, SelectTopologyEstimatorModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConfig\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprep\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_spring_particle_data\n\u001b[32m      5\u001b[39m run_type = \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# or 'predict'\u001b[39;00m\n\u001b[32m      6\u001b[39m tp_config = TrainNRIConfig()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AFD\\data\\prep.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConfig\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mh5py\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maugment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_gaussian_noise\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConfig\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'augment'"
     ]
    }
   ],
   "source": [
    "from topology_estimation.config import TrainNRIConfig, SelectTopologyEstimatorModel\n",
    "from data.config import DataConfig\n",
    "from data.prep import load_spring_particle_data\n",
    "\n",
    "run_type = 'train'  # or 'predict'\n",
    "tp_config = TrainNRIConfig()\n",
    "data_config = DataConfig()\n",
    "\n",
    "tp_config.set_encoder_params()\n",
    "tp_config.set_decoder_params()\n",
    "\n",
    "# if tp_config.is_sparsifier:\n",
    "#     tp_config.get_sparsif_config()\n",
    "    \n",
    "# load data\n",
    "data_config = DataConfig()\n",
    "data_config.set_train_dataset()\n",
    "\n",
    "# get node and edge dataset path from which data will be loaded\n",
    "node_ds_paths, edge_ds_paths = data_config.get_dataset_paths()\n",
    "\n",
    "# load datalaoders\n",
    "train_loader, valid_loader, test_loader, data_stats = load_spring_particle_data(node_ds_paths, edge_ds_paths)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "\n",
    "n_nodes = data[0].shape[1]\n",
    "n_timesteps = data[0].shape[2]\n",
    "n_dims = data[0].shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4dbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'edge_estimator_2.1' already exists in the log path 'c:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\train\\etypes=2\\edge_estimator_2.1'.\n",
      "Overwrote 'edge_estimator_2.1' from the log path c:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\train\\etypes=2\\edge_estimator_2.1.\n",
      "c:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\train\\etypes=2\\edge_estimator_2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.config import DataConfig\n",
    "from topology_estimation.config import TrainNRIConfig\n",
    "\n",
    "data_config = DataConfig()\n",
    "data_config.set_train_dataset()\n",
    "\n",
    "tp_config = TrainNRIConfig()\n",
    "tp_config.set_encoder_params()\n",
    "tp_config.set_decoder_params()\n",
    "\n",
    "log_path_nri = tp_config.get_train_log_path(500, 1)\n",
    "print(log_path_nri)\n",
    "\n",
    "if log_path_nri is not None:\n",
    "    os.makedirs(log_path_nri, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703eb838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to c:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\train\\etypes=2\\edge_estimator_2.1.\n"
     ]
    }
   ],
   "source": [
    "tp_config.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0269e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1 already exists in the log path 'logs\\spring_particles\\P005\\scenario_1\\directed_graph\\enc=mlp_1-dec=gru\\healthy\\H1_[OG]\\dp=49-dim=4-etype=2\\sparsif=[knn+time]\\(sparsif)=_no_fex\\[enc]=freq-[dec]=time\\(enc)=PCA+first_n_modes-(dec)=PCA\\v1'.\n",
      "Removed version 1 from the log path logs\\spring_particles\\P005\\scenario_1\\directed_graph\\enc=mlp_1-dec=gru\\healthy\\H1_[OG]\\dp=49-dim=4-etype=2\\sparsif=[knn+time]\\(sparsif)=_no_fex\\[enc]=freq-[dec]=time\\(enc)=PCA+first_n_modes-(dec)=PCA\\v1.\n"
     ]
    }
   ],
   "source": [
    "tp_config.check_if_version_exists(log_path_nri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b3ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\spring_particles\\P005\\scenario_1\\directed_graph\\enc=mlp_1_dec=gru\\dp=49\\healthy\\H1_[OG]\\sparsif_knn\\(sparsif)_no_fex\\(nri)_no_fex\\v2\n"
     ]
    }
   ],
   "source": [
    "print(tp_config.log_path)\n",
    "os.makedirs(tp_config.log_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f988d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'first_n_modes', 'n_modes': 5}, {'type': 'lucas', 'weight': 0.5, 'height': 9, 'age': 20}]\n",
      "[{'type': 'first_n_modes', 'n_modes': 69}]\n"
     ]
    }
   ],
   "source": [
    "print(tp_config.fex_configs_sparsif)\n",
    "print(tp_config.fex_configs_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46950b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">bearing</span>\n",
       "â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000\">cwru</span>\n",
       "    â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000\">scene_1</span>\n",
       "        â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000\">directed_graph</span>\n",
       "            â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;n_edge_types&gt;</span>\n",
       "            â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">etypes=2</span>\n",
       "                â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_type&gt;</span>\n",
       "                â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">OK_NOK</span>\n",
       "                    â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_subtype&gt;</span>\n",
       "                    â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0_N[OG--gau_m=0.1s=0.2--gau_m=0.2s=0.3]_+_0_B-007[gau_m=0.0s=0.1--gau_m=0.1s=0.2]_+_0_B-021</span>\n",
       "                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">[OG]</span>\n",
       "                        â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;model&gt;</span>\n",
       "                        â””â”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">E=mlp_1-D=gru</span>\n",
       "                            â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_stats&gt;</span>\n",
       "                            â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">T500_m=[acc]</span>\n",
       "                                â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;sparsif_type&gt;</span>\n",
       "                                â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">spf=_no_spf</span>\n",
       "                                    â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;domain&gt;</span>\n",
       "                                    â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">[E]=freq-[D]=time</span>\n",
       "                                        â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;nri_fex_type&gt;</span>\n",
       "                                        â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">(E)=_no_fex-(D)=[first_n_modes]</span>\n",
       "                                            â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;shape_compatibility&gt;</span>\n",
       "                                            â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">E(comps)=500-D(dims)=1</span>\n",
       "                                                â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;versions&gt;</span>\n",
       "                                                â””â”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold; font-style: italic\">v1</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">[0]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mbearing\u001b[0m\n",
       "â””â”€â”€ \u001b[32mcwru\u001b[0m\n",
       "    â””â”€â”€ \u001b[32mscene_1\u001b[0m\n",
       "        â””â”€â”€ \u001b[32mdirected_graph\u001b[0m\n",
       "            â”œâ”€â”€ \u001b[34m<n_edge_types>\u001b[0m\n",
       "            â””â”€â”€ \u001b[37metypes=2\u001b[0m\n",
       "                â”œâ”€â”€ \u001b[34m<ds_type>\u001b[0m\n",
       "                â””â”€â”€ \u001b[37mOK_NOK\u001b[0m\n",
       "                    â”œâ”€â”€ \u001b[34m<ds_subtype>\u001b[0m\n",
       "                    â””â”€â”€ \u001b[37m0_N[OG--gau_m=0.1s=0.2--gau_m=0.2s=0.3]_+_0_B-007[gau_m=0.0s=0.1--gau_m=0.1s=0.2]_+_0_B-021\u001b[0m\n",
       "                        \u001b[37m[OG]\u001b[0m\n",
       "                        â”œâ”€â”€ \u001b[34m<model>\u001b[0m\n",
       "                        â””â”€â”€ \u001b[93mE=mlp_1-D=gru\u001b[0m\n",
       "                            â”œâ”€â”€ \u001b[34m<ds_stats>\u001b[0m\n",
       "                            â””â”€â”€ \u001b[37mT500_m=[acc]\u001b[0m\n",
       "                                â”œâ”€â”€ \u001b[34m<sparsif_type>\u001b[0m\n",
       "                                â””â”€â”€ \u001b[37mspf=_no_spf\u001b[0m\n",
       "                                    â”œâ”€â”€ \u001b[34m<domain>\u001b[0m\n",
       "                                    â””â”€â”€ \u001b[37m[E]=freq-[D]=time\u001b[0m\n",
       "                                        â”œâ”€â”€ \u001b[34m<nri_fex_type>\u001b[0m\n",
       "                                        â””â”€â”€ \u001b[37m(E)=_no_fex-(D)=[first_n_modes]\u001b[0m\n",
       "                                            â”œâ”€â”€ \u001b[34m<shape_compatibility>\u001b[0m\n",
       "                                            â””â”€â”€ \u001b[37mE(comps)=500-D(dims)=1\u001b[0m\n",
       "                                                â”œâ”€â”€ \u001b[34m<versions>\u001b[0m\n",
       "                                                â””â”€â”€ \u001b[1;3;93mv1\u001b[0m \u001b[96m[0]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available version paths:\n",
      "0: logs/bearing\\cwru\\scene_1\\directed_graph\\etypes=2\\OK_NOK\\0_N[OG--gau_m=0.1s=0.2--gau_m=0.2s=0.3]_+_0_B-007[gau_m=0.0s=0.1--gau_m=0.1s=0.2]_+_0_B-021[OG]\\E=mlp_1-D=gru\\T500_m=[acc]\\spf=_no_spf\\[E]=freq-[D]=time\\(E)=_no_fex-(D)=[first_n_modes]\\E(comps)=500-D(dims)=1\\v1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtopology_estimation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SelectTopologyEstimatorModel\n\u001b[32m      3\u001b[39m model_selector = SelectTopologyEstimatorModel(\n\u001b[32m      4\u001b[39m                                               framework=\u001b[33m'\u001b[39m\u001b[33mdirected_graph\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m ckpt = \u001b[43mmodel_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_ckpt_and_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSelected checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\AFD\\topology_estimation\\config.py:707\u001b[39m, in \u001b[36mSelectTopologyEstimatorModel.select_ckpt_and_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo version paths found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m idx = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mEnter the index number of the version path to select: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m idx >= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.version_paths):\n\u001b[32m    709\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInvalid index.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "from topology_estimation.config import SelectTopologyEstimatorModel\n",
    "\n",
    "model_selector = SelectTopologyEstimatorModel(\n",
    "                                              framework='directed_graph')\n",
    "\n",
    "ckpt = model_selector.select_ckpt_and_params()\n",
    "print(f\"Selected checkpoint: {ckpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f32bc",
   "metadata": {},
   "source": [
    "predict and custom test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15d0c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e230c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict number 2 for already exists for model_2.2 in the log path 'C:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\predict\\etypes=2\\model_2.2\\predict_2.2'.\n",
      "C:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\predict\\etypes=2\\model_2.2\\predict_2.6\n",
      "Predict parameters saved to C:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\predict\\etypes=2\\model_2.2\\predict_2.6.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.config import DataConfig\n",
    "from topology_estimation.config import PredictNRIConfig\n",
    "\n",
    "data_config = DataConfig()\n",
    "data_config.set_predict_dataset()\n",
    "\n",
    "tp_config = PredictNRIConfig()\n",
    "\n",
    "log_path_nri = tp_config.get_predict_log_path()\n",
    "print(log_path_nri)\n",
    "\n",
    "if log_path_nri is not None:\n",
    "    os.makedirs(log_path_nri, exist_ok=True)\n",
    "\n",
    "tp_config.save_predict_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ec6e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "custom_test number 2 for already exists for model_2.2 in the log path 'C:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\custom_test\\etypes=2\\model_2.2\\custom_test_2.2'.\n",
      "C:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\custom_test\\etypes=2\\model_2.2\\custom_test_2.5\n",
      "Custom test parameters saved to C:\\AFD\\topology_estimation\\logs\\bearing\\cwru\\scene_1\\directed_graph\\custom_test\\etypes=2\\model_2.2\\custom_test_2.5.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data.config import DataConfig\n",
    "from topology_estimation.config import PredictNRIConfig\n",
    "\n",
    "data_config = DataConfig()\n",
    "data_config.set_custom_test_dataset()\n",
    "\n",
    "tp_config = PredictNRIConfig()\n",
    "\n",
    "log_path_nri = tp_config.get_custom_test_log_path()\n",
    "print(log_path_nri)\n",
    "\n",
    "if log_path_nri is not None:\n",
    "    os.makedirs(log_path_nri, exist_ok=True)\n",
    "\n",
    "tp_config.save_custom_test_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
