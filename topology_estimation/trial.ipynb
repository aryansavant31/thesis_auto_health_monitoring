{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9906d9cd",
   "metadata": {},
   "source": [
    "# Topology Estimation Model\n",
    "\n",
    "This notebook contains all the steps of topology model developement. \n",
    "\n",
    "In this notebook, the model can be:\n",
    "- trained and tested\n",
    "- loaded and run for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45a89842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097a33d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run from main script...\n"
     ]
    }
   ],
   "source": [
    "# This will resolve log_dir relative to main.py\n",
    "version = 19\n",
    "# StdoutToTensorBoard(log_dir=f\"logs/trials/nri/version_{version}\")\n",
    "\n",
    "print(\"Starting run from main script...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbe905",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.config import DataConfig\n",
    "from data.load import load_spring_particle_data\n",
    "\n",
    "data_config = DataConfig()\n",
    "data_config.set_train_valid_dataset()\n",
    "\n",
    "# get node and edge dataset path from which data will be loaded\n",
    "node_ds_paths, edge_ds_paths = data_config.get_dataset_paths()\n",
    "\n",
    "# load datalaoders\n",
    "train_loader, valid_loader, test_loader = load_spring_particle_data(node_ds_paths, edge_ds_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df95956",
   "metadata": {},
   "source": [
    "#### Set the number of timesteps and dimensions of the node data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8343f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5\n",
      "Number of timesteps: 49\n",
      "Number of dimensions: 4\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "\n",
    "n_nodes = data[0].shape[1]\n",
    "n_timesteps = data[0].shape[2]\n",
    "n_dims = data[0].shape[3]\n",
    "\n",
    "print(f\"Number of nodes: {n_nodes}\")\n",
    "print(f\"Number of timesteps: {n_timesteps}\")  \n",
    "print(f\"Number of dimensions: {n_dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b93d1b",
   "metadata": {},
   "source": [
    "### Prepare the relation matrix for encoder input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859af1d2",
   "metadata": {},
   "source": [
    "##### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dfc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0fcf9",
   "metadata": {},
   "source": [
    "##### Generate off-diagonal fully connected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f82490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate off-diagonal fully connected graph\n",
    "off_diag = np.ones([5, 5]) - np.eye(5)\n",
    "\n",
    "rec_rel = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "send_rel = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rec_rel = torch.FloatTensor(rec_rel)\n",
    "send_rel = torch.FloatTensor(send_rel)\n",
    "\n",
    "rec_rel = rec_rel.to(device)\n",
    "send_rel = send_rel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870f6f7e",
   "metadata": {},
   "source": [
    "## 2. Load and prepare the topology estimator model blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc088ce8",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd5cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (emb_fn_dict): ModuleDict(\n",
      "    (1/node_emd1): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=196, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1/node_emd2): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1/edge_emd1@): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2/node_emd1): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2/node_emd2): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2/edge_emd1): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2/edge_emd2): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (4): ReLU()\n",
      "        (5): Dropout(p=0.0, inplace=False)\n",
      "        (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (7): ReLU()\n",
      "        (8): Dropout(p=0.0, inplace=False)\n",
      "        (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attention_layer_dict): ModuleDict()\n",
      "  (output_layer): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from topology_estimation.config import TopologyEstimatorConfig\n",
    "from topology_estimation.encoder_blocks import Encoder\n",
    "from torchinfo import summary\n",
    "\n",
    "tp_config = TopologyEstimatorConfig()\n",
    "tp_config.set_encoder_params()\n",
    "\n",
    "encoder = Encoder(n_timesteps=n_timesteps, \n",
    "                  n_dims=n_dims,\n",
    "                  pipeline=tp_config.encoder_pipeline, \n",
    "                  n_edge_types=tp_config.n_edge_types, \n",
    "                  is_residual_connection=tp_config.is_residual_connection,\n",
    "                  edge_emd_configs=tp_config.edge_emb_configs_enc, \n",
    "                  node_emd_configs=tp_config.node_emb_configs_enc, \n",
    "                  drop_out_prob=tp_config.dropout_prob_enc,\n",
    "                  batch_norm=tp_config.batch_norm_enc, \n",
    "                  attention_output_size=tp_config.attention_output_size)\n",
    "\n",
    "encoder.set_input_graph(rec_rel, send_rel)\n",
    "enocder = encoder.to(device)\n",
    "\n",
    "# print(summary(encoder, (64, 5, n_timesteps, n_dims)))\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1e23d",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f30195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (edge_mlp_fn): ModuleList(\n",
      "    (0-1): 2 x MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (recurrent_emb_fn): GRU(\n",
      "    (input_u): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (hidden_u): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (input_r): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (hidden_r): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (input_h): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (hidden_h): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (mean_mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Tanh()\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Tanh()\n",
      "      (7): Dropout(p=0, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Tanh()\n",
      "      (11): Dropout(p=0, inplace=False)\n",
      "      (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (var_mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Tanh()\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Tanh()\n",
      "      (7): Dropout(p=0, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Tanh()\n",
      "      (11): Dropout(p=0, inplace=False)\n",
      "      (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (mean_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (var_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from topology_estimation.decoder_blocks import Decoder\n",
    "\n",
    "tp_config.set_decoder_params()\n",
    "\n",
    "decoder = Decoder(n_dim=n_dims,\n",
    "                  msg_out_size=tp_config.msg_out_size,\n",
    "                  n_edge_types=tp_config.n_edge_types,\n",
    "                  skip_first=tp_config.skip_first_edge_type,\n",
    "                  edge_mlp_config=tp_config.edge_mlp_config_dec,\n",
    "                  recurrent_emd_type=tp_config.recurrent_emd_type,\n",
    "                  out_mlp_config=tp_config.out_mlp_config_dec,\n",
    "                  do_prob=tp_config.dropout_prob_dec,\n",
    "                  is_batch_norm=tp_config.is_batch_norm_dec)\n",
    "\n",
    "\n",
    "# generate random edge matrix\n",
    "edge_matrix = torch.rand((64, 20, 2))\n",
    "edge_matrix = edge_matrix.to(device)\n",
    "\n",
    "decoder.set_input_graph(rec_rel, send_rel)\n",
    "decoder.set_edge_matrix(edge_matrix)\n",
    "decoder.set_run_params()\n",
    "\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "# print(summary(decoder, (64, 5, n_timesteps, n_dims)))\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27262fd9",
   "metadata": {},
   "source": [
    "### NRI model (Combine Encoder and Decoder blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9008a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRI(\n",
      "  (encoder): Encoder(\n",
      "    (emb_fn_dict): ModuleDict(\n",
      "      (1/node_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=196, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (1/node_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (1/edge_emd1@): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/node_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/node_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/edge_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/edge_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attention_layer_dict): ModuleDict()\n",
      "    (output_layer): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (edge_mlp_fn): ModuleList(\n",
      "      (0-1): 2 x MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Tanh()\n",
      "          (3): Dropout(p=0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): Tanh()\n",
      "          (7): Dropout(p=0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): Tanh()\n",
      "          (11): Dropout(p=0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (recurrent_emb_fn): GRU(\n",
      "      (input_u): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (hidden_u): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (input_r): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (hidden_r): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (input_h): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (hidden_h): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (mean_mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (var_mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (mean_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "    (var_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from topology_estimation.nri import NRI\n",
    "\n",
    "\n",
    "nri_model = NRI(encoder, decoder)\n",
    "nri_model.set_run_params()\n",
    "nri_model.set_input_graph(rec_rel, send_rel)\n",
    "\n",
    "print(nri_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38adb53",
   "metadata": {},
   "source": [
    "## 3. Training topology estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c38b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Anaconda3\\envs\\afd_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | encoder | Encoder | 36.3 K | train\n",
      "1 | decoder | Decoder | 55.0 K | train\n",
      "--------------------------------------------\n",
      "91.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.3 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n",
      "141       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Anaconda3\\envs\\afd_env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.97it/s, v_num=19, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.73, train_loss_decoder=112.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.80it/s, v_num=19, train_edge_accuracy=0.510, train_loss=109.0, train_loss_encoder=-2.73, train_loss_decoder=112.0]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "tp_config.set_training_params()\n",
    "nri_model.set_training_params()\n",
    "\n",
    "logger = TensorBoardLogger('logs/trials', name='nri', version=version)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=tp_config.max_epochs,\n",
    "    logger=logger,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=1,)\n",
    "\n",
    "trainer.fit(model=nri_model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dac9c2",
   "metadata": {},
   "source": [
    "#### Plot and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os\n",
    "\n",
    "event_dir = os.path.join('model_logs', 'trials', 'nri_model_trial3', 'version_0')\n",
    "print(event_dir)\n",
    "\n",
    "ea = event_accumulator.EventAccumulator(event_dir)\n",
    "ea.Reload()\n",
    "\n",
    "# List all tags\n",
    "# print(ea.Tags())\n",
    "\n",
    "loss_events = ea.Scalars('train_loss')\n",
    "losses = [event.value for event in loss_events]\n",
    "steps = [event.step for event in loss_events]\n",
    "\n",
    "print(\"Steps:\", steps)\n",
    "print(\"Losses:\", losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import io\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, losses, label='Train Loss')\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "# Convert matplotlib fig to image\n",
    "buf = io.BytesIO()\n",
    "fig.savefig(buf, format='png', dpi=1000)\n",
    "buf.seek(0)\n",
    "image = Image.open(buf)\n",
    "image_np = np.array(image)\n",
    "\n",
    "writer = SummaryWriter(\"model_logs\\\\trials\\\\nri_model_trial3\")\n",
    "\n",
    "writer.add_image(\"test_plot\", image_np.transpose(2, 0, 1), global_step=0)\n",
    "buf.close()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeab4bd",
   "metadata": {},
   "source": [
    "### Trying the config file stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7affc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from topology_estimation.config import TopologyEstimatorConfig, SelectTopologyEstimatorModel\n",
    "from data.config import DataConfig\n",
    "from data.load import load_spring_particle_data\n",
    "tp_config = TopologyEstimatorConfig()\n",
    "data_config = DataConfig()\n",
    "\n",
    "if tp_config.is_nri:\n",
    "    tp_config.set_encoder_params()\n",
    "    tp_config.set_decoder_params()\n",
    "    \n",
    "# load data\n",
    "data_config = DataConfig()\n",
    "data_config.set_train_valid_dataset()\n",
    "\n",
    "# get node and edge dataset path from which data will be loaded\n",
    "node_ds_paths, edge_ds_paths = data_config.get_dataset_paths()\n",
    "\n",
    "# load datalaoders\n",
    "train_loader, valid_loader, test_loader = load_spring_particle_data(node_ds_paths, edge_ds_paths)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "\n",
    "n_nodes = data[0].shape[1]\n",
    "n_timesteps = data[0].shape[2]\n",
    "n_dims = data[0].shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4dbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp_1_dec=gru\\dp-49\\healthy\\H1_[OG]\\_no_fex\\v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "tp_config.set_log_path(data_config, n_timesteps)\n",
    "print(tp_config.log_path)\n",
    "\n",
    "os.makedirs(tp_config.log_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0269e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1 already exists in the log path 'logs\\spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp_1_dec=gru\\dp-49\\healthy\\H1_[OG]\\_no_fex\\v2'.\n",
      "Removed version 1 from the log path logs\\spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp_1_dec=gru\\dp-49\\healthy\\H1_[OG]\\_no_fex\\v2.\n"
     ]
    }
   ],
   "source": [
    "tp_config.check_if_version_exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b3ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp_1_dec=gru\\dp-49\\healthy\\H1_[OG]\\_no_fex\\v2\n"
     ]
    }
   ],
   "source": [
    "print(tp_config.log_path)\n",
    "os.makedirs(tp_config.log_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46950b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">spring_particles</span>\n",
       "â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000\">P005</span>\n",
       "    â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000\">scenario_1</span>\n",
       "        â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;framework&gt;</span>\n",
       "        â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">novel_nri</span>\n",
       "        â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">skeleton_graph</span>\n",
       "        â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">std_nri</span>\n",
       "            â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;model&gt;</span>\n",
       "            â”œâ”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">enc=mlp1_dec=gru</span>\n",
       "            â”‚   â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;n_datapoints&gt;</span>\n",
       "            â”‚   â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dp-50</span>\n",
       "            â”‚   â”‚   â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_type&gt;</span>\n",
       "            â”‚   â”‚   â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">healthy</span>\n",
       "            â”‚   â”‚   â”‚   â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_subtype&gt;</span>\n",
       "            â”‚   â”‚   â”‚   â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">H1_[A1+A2+G]_+_H2_[G+A1]</span>\n",
       "            â”‚   â”‚   â”‚       â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;fex_type&gt;</span>\n",
       "            â”‚   â”‚   â”‚       â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">_no_fex</span>\n",
       "            â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;versions&gt;</span>\n",
       "            â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">v1</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">[0]</span>\n",
       "            â”‚   â”‚   â”‚       â”‚   â””â”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">v28</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">[1]</span>\n",
       "            â”‚   â”‚   â”‚       â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">fex_1</span>\n",
       "            â”‚   â”‚   â”‚           â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;versions&gt;</span>\n",
       "            â”‚   â”‚   â”‚           â””â”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">v1</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">[2]</span>\n",
       "            â”‚   â”‚   â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">healthy_unhealthy</span>\n",
       "            â”‚   â”‚       â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_subtype&gt;</span>\n",
       "            â”‚   â”‚       â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">H1_[A1+A2+G]_+_H2_[G+A1]_+_UH1_[A1_A2]}</span>\n",
       "            â”‚   â”‚           â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;fex_type&gt;</span>\n",
       "            â”‚   â”‚           â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">_no_fex</span>\n",
       "            â”‚   â”‚           â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">fex_1</span>\n",
       "            â”‚   â”œâ”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dp-60</span>\n",
       "            â”‚   â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dp-80</span>\n",
       "            â””â”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">enc=mlp_1_dec=gru</span>\n",
       "                â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;n_datapoints&gt;</span>\n",
       "                â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">dp-49</span>\n",
       "                    â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_type&gt;</span>\n",
       "                    â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">healthy</span>\n",
       "                        â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;ds_subtype&gt;</span>\n",
       "                        â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">H1_[OG]</span>\n",
       "                            â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;fex_type&gt;</span>\n",
       "                            â””â”€â”€ <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">_no_fex</span>\n",
       "                                â”œâ”€â”€ <span style=\"color: #000080; text-decoration-color: #000080\">&lt;versions&gt;</span>\n",
       "                                â””â”€â”€ <span style=\"color: #ffff00; text-decoration-color: #ffff00\">v1</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">[3]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mspring_particles\u001b[0m\n",
       "â””â”€â”€ \u001b[32mP005\u001b[0m\n",
       "    â””â”€â”€ \u001b[32mscenario_1\u001b[0m\n",
       "        â”œâ”€â”€ \u001b[34m<framework>\u001b[0m\n",
       "        â”œâ”€â”€ \u001b[37mnovel_nri\u001b[0m\n",
       "        â”œâ”€â”€ \u001b[37mskeleton_graph\u001b[0m\n",
       "        â””â”€â”€ \u001b[37mstd_nri\u001b[0m\n",
       "            â”œâ”€â”€ \u001b[34m<model>\u001b[0m\n",
       "            â”œâ”€â”€ \u001b[93menc=mlp1_dec=gru\u001b[0m\n",
       "            â”‚   â”œâ”€â”€ \u001b[34m<n_datapoints>\u001b[0m\n",
       "            â”‚   â”œâ”€â”€ \u001b[37mdp-50\u001b[0m\n",
       "            â”‚   â”‚   â”œâ”€â”€ \u001b[34m<ds_type>\u001b[0m\n",
       "            â”‚   â”‚   â”œâ”€â”€ \u001b[37mhealthy\u001b[0m\n",
       "            â”‚   â”‚   â”‚   â”œâ”€â”€ \u001b[34m<ds_subtype>\u001b[0m\n",
       "            â”‚   â”‚   â”‚   â””â”€â”€ \u001b[37mH1_[A1+A2+G]_+_H2_[G+A1]\u001b[0m\n",
       "            â”‚   â”‚   â”‚       â”œâ”€â”€ \u001b[34m<fex_type>\u001b[0m\n",
       "            â”‚   â”‚   â”‚       â”œâ”€â”€ \u001b[37m_no_fex\u001b[0m\n",
       "            â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ \u001b[34m<versions>\u001b[0m\n",
       "            â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ \u001b[93mv1\u001b[0m \u001b[96m[0]\u001b[0m\n",
       "            â”‚   â”‚   â”‚       â”‚   â””â”€â”€ \u001b[93mv28\u001b[0m \u001b[96m[1]\u001b[0m\n",
       "            â”‚   â”‚   â”‚       â””â”€â”€ \u001b[37mfex_1\u001b[0m\n",
       "            â”‚   â”‚   â”‚           â”œâ”€â”€ \u001b[34m<versions>\u001b[0m\n",
       "            â”‚   â”‚   â”‚           â””â”€â”€ \u001b[93mv1\u001b[0m \u001b[96m[2]\u001b[0m\n",
       "            â”‚   â”‚   â””â”€â”€ \u001b[37mhealthy_unhealthy\u001b[0m\n",
       "            â”‚   â”‚       â”œâ”€â”€ \u001b[34m<ds_subtype>\u001b[0m\n",
       "            â”‚   â”‚       â””â”€â”€ \u001b[37mH1_[A1+A2+G]_+_H2_[G+A1]_+_UH1_[A1_A2]}\u001b[0m\n",
       "            â”‚   â”‚           â”œâ”€â”€ \u001b[34m<fex_type>\u001b[0m\n",
       "            â”‚   â”‚           â”œâ”€â”€ \u001b[37m_no_fex\u001b[0m\n",
       "            â”‚   â”‚           â””â”€â”€ \u001b[37mfex_1\u001b[0m\n",
       "            â”‚   â”œâ”€â”€ \u001b[37mdp-60\u001b[0m\n",
       "            â”‚   â””â”€â”€ \u001b[37mdp-80\u001b[0m\n",
       "            â””â”€â”€ \u001b[93menc=mlp_1_dec=gru\u001b[0m\n",
       "                â”œâ”€â”€ \u001b[34m<n_datapoints>\u001b[0m\n",
       "                â””â”€â”€ \u001b[37mdp-49\u001b[0m\n",
       "                    â”œâ”€â”€ \u001b[34m<ds_type>\u001b[0m\n",
       "                    â””â”€â”€ \u001b[37mhealthy\u001b[0m\n",
       "                        â”œâ”€â”€ \u001b[34m<ds_subtype>\u001b[0m\n",
       "                        â””â”€â”€ \u001b[37mH1_[OG]\u001b[0m\n",
       "                            â”œâ”€â”€ \u001b[34m<fex_type>\u001b[0m\n",
       "                            â””â”€â”€ \u001b[37m_no_fex\u001b[0m\n",
       "                                â”œâ”€â”€ \u001b[34m<versions>\u001b[0m\n",
       "                                â””â”€â”€ \u001b[93mv1\u001b[0m \u001b[96m[3]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available version paths:\n",
      "0: logs/spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp1_dec=gru\\dp-50\\healthy\\H1_[A1+A2+G]_+_H2_[G+A1]\\_no_fex\\v1\n",
      "1: logs/spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp1_dec=gru\\dp-50\\healthy\\H1_[A1+A2+G]_+_H2_[G+A1]\\_no_fex\\v28\n",
      "2: logs/spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp1_dec=gru\\dp-50\\healthy\\H1_[A1+A2+G]_+_H2_[G+A1]\\fex_1\\v1\n",
      "3: logs/spring_particles\\P005\\scenario_1\\std_nri\\enc=mlp_1_dec=gru\\dp-49\\healthy\\H1_[OG]\\_no_fex\\v1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtopology_estimation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SelectTopologyEstimatorModel\n\u001b[32m      3\u001b[39m model_selector = SelectTopologyEstimatorModel(application=\u001b[33m'\u001b[39m\u001b[33mspring_particles\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m                                               machine=\u001b[33m'\u001b[39m\u001b[33mP005\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m                                               scenario=\u001b[33m'\u001b[39m\u001b[33mscenario_1\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m ckpt = \u001b[43mmodel_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_and_get_ckpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSelected checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_implement_thesis\\topology_estimation\\config.py:445\u001b[39m, in \u001b[36mSelectTopologyEstimatorModel.select_and_get_ckpt\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo version paths found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m idx = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mEnter the index number of the version path to select: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m idx >= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.version_paths):\n\u001b[32m    447\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInvalid index.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "from topology_estimation.config import SelectTopologyEstimatorModel\n",
    "\n",
    "model_selector = SelectTopologyEstimatorModel(application='spring_particles',\n",
    "                                              machine='P005',\n",
    "                                              scenario='scenario_1')\n",
    "\n",
    "ckpt = model_selector.select_and_get_ckpt()\n",
    "print(f\"Selected checkpoint: {ckpt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
