{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd0e89b",
   "metadata": {},
   "source": [
    "# Data block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5307eb",
   "metadata": {},
   "source": [
    "### View module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0173e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.config import DataConfig\n",
    "\n",
    "data_config = DataConfig()\n",
    "data_config.set_train_valid_dataset()\n",
    "\n",
    "data_config.get_dataset_paths()\n",
    "\n",
    "data_config.set_test_dataset()\n",
    "data_config.get_dataset_paths()\n",
    "\n",
    "data_config.set_train_valid_dataset()\n",
    "node_ds_paths, edge_ds_paths = data_config.get_dataset_paths()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f1f526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vel\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for paths in node_ds_paths['H']:\n",
    "   last_element = os.path.basename(paths)\n",
    "   print(last_element) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eadec3",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f3a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.load import load_spring_particle_data\n",
    "\n",
    "train_loader, valid_loader, test_loader = load_spring_particle_data(node_ds_paths, edge_ds_paths)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "\n",
    "n_timesteps = data[0].shape[2]\n",
    "n_dims = data[0].shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd3fb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8ce2a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Off-diagonal interaction graph:\n",
      "[[0. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "# Generate off-diagonal interaction graph\n",
    "off_diag = np.ones([5, 5]) - np.eye(5)\n",
    "print(\"Off-diagonal interaction graph:\")\n",
    "print(off_diag)\n",
    "\n",
    "rec_rel = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "send_rel = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rec_rel = torch.FloatTensor(rec_rel)\n",
    "send_rel = torch.FloatTensor(send_rel)\n",
    "\n",
    "rec_rel = rec_rel.to(device)\n",
    "send_rel = send_rel.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816339f1",
   "metadata": {},
   "source": [
    "### Enocder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e572ad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Encoder                                  [64, 20, 2]               --\n",
      "â”œâ”€ModuleDict: 1-1                        --                        --\n",
      "â”‚    â””â”€MLP: 2-1                          [64, 5, 8]                --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-1              --                        15,352\n",
      "â”‚    â””â”€MLP: 2-2                          [64, 5, 8]                --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-2              --                        3,320\n",
      "â”‚    â””â”€MLP: 2-3                          [64, 20, 8]               --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-3              --                        3,320\n",
      "â”‚    â””â”€MLP: 2-4                          [64, 5, 8]                --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-4              --                        3,320\n",
      "â”‚    â””â”€MLP: 2-5                          [64, 5, 8]                --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-5              --                        3,320\n",
      "â”‚    â””â”€MLP: 2-6                          [64, 20, 8]               --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-6              --                        3,832\n",
      "â”‚    â””â”€MLP: 2-7                          [64, 20, 8]               --\n",
      "â”‚    â”‚    â””â”€ModuleList: 3-7              --                        3,832\n",
      "â”œâ”€Linear: 1-2                            [64, 20, 2]               18\n",
      "==========================================================================================\n",
      "Total params: 36,314\n",
      "Trainable params: 36,314\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 2.32\n",
      "==========================================================================================\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 4.94\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 5.33\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from topology_estimation.config import TopologyEstimatorConfig\n",
    "from topology_estimation.encoder_blocks import Encoder\n",
    "from torchinfo import summary\n",
    "\n",
    "par = TopologyEstimatorConfig()\n",
    "par.set_encoder_params()\n",
    "\n",
    "encoder = Encoder(n_timesteps=n_timesteps, \n",
    "                  n_dims=n_dims,\n",
    "                  pipeline=par.encoder_pipeline, \n",
    "                  n_edge_types=par.n_edge_types, \n",
    "                  is_residual_connection=par.is_residual_connection,\n",
    "                  edge_emd_configs=par.edge_emb_configs_enc, \n",
    "                  node_emd_configs=par.node_emb_configs_enc, \n",
    "                  drop_out_prob=par.dropout_prob_enc,\n",
    "                  batch_norm=par.batch_norm_enc, \n",
    "                  attention_output_size=par.attention_output_size)\n",
    "\n",
    "encoder.set_input_graph(rec_rel, send_rel)\n",
    "enocder = encoder.to(device)\n",
    "print(summary(encoder, (64, 5, n_timesteps, n_dims)))\n",
    "# print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2cb2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (edge_mlp_fn): ModuleList(\n",
      "    (0-1): 2 x MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (recurrent_emb_fn): GRU(\n",
      "    (input_u): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (hidden_u): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (input_r): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (hidden_r): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (input_h): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (hidden_h): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (mean_mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Tanh()\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Tanh()\n",
      "      (7): Dropout(p=0, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Tanh()\n",
      "      (11): Dropout(p=0, inplace=False)\n",
      "      (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (var_mlp): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Tanh()\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Tanh()\n",
      "      (7): Dropout(p=0, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): Tanh()\n",
      "      (11): Dropout(p=0, inplace=False)\n",
      "      (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (mean_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "  (var_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "from topology_estimation.decoder_blocks import Decoder\n",
    "par.set_decoder_params()\n",
    "\n",
    "decoder = Decoder(n_dim=n_dims,\n",
    "                  msg_out_size=par.msg_out_size,\n",
    "                  n_edge_types=par.n_edge_types,\n",
    "                  skip_first=par.skip_first_edge_type,\n",
    "                  edge_mlp_config=par.edge_mlp_config_dec,\n",
    "                  recurrent_emd_type=par.recurrent_emd_type,\n",
    "                  out_mlp_config=par.out_mlp_config_dec,\n",
    "                  do_prob=par.dropout_prob_dec,\n",
    "                  is_batch_norm=par.is_batch_norm_dec)\n",
    "\n",
    "\n",
    "# generate random edge matrix\n",
    "edge_matrix = torch.rand((64, 20, 2))\n",
    "edge_matrix = edge_matrix.to(device)\n",
    "\n",
    "decoder.set_input_graph(rec_rel, send_rel)\n",
    "decoder.set_edge_matrix(edge_matrix)\n",
    "decoder.set_run_params()\n",
    "\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "# print(summary(decoder, (64, 5, n_timesteps, n_dims)))\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18aad7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRI(\n",
      "  (encoder): Encoder(\n",
      "    (emb_fn_dict): ModuleDict(\n",
      "      (1/node_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=196, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (1/node_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (1/edge_emd1@): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/node_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/node_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/edge_emd1): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2/edge_emd2): MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (4): ReLU()\n",
      "          (5): Dropout(p=0.0, inplace=False)\n",
      "          (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (7): ReLU()\n",
      "          (8): Dropout(p=0.0, inplace=False)\n",
      "          (9): Linear(in_features=16, out_features=8, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attention_layer_dict): ModuleDict()\n",
      "    (output_layer): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (edge_mlp_fn): ModuleList(\n",
      "      (0-1): 2 x MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Tanh()\n",
      "          (3): Dropout(p=0, inplace=False)\n",
      "          (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "          (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): Tanh()\n",
      "          (7): Dropout(p=0, inplace=False)\n",
      "          (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "          (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): Tanh()\n",
      "          (11): Dropout(p=0, inplace=False)\n",
      "          (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "          (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (recurrent_emb_fn): GRU(\n",
      "      (input_u): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (hidden_u): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (input_r): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (hidden_r): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (input_h): Linear(in_features=4, out_features=64, bias=True)\n",
      "      (hidden_h): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (mean_mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (var_mlp): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Tanh()\n",
      "        (3): Dropout(p=0, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "        (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): Tanh()\n",
      "        (7): Dropout(p=0, inplace=False)\n",
      "        (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): Tanh()\n",
      "        (11): Dropout(p=0, inplace=False)\n",
      "        (12): Linear(in_features=16, out_features=64, bias=True)\n",
      "        (13): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (mean_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "    (var_output_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from topology_estimation.nri import NRI\n",
    "nri = NRI(encoder, decoder, 5)\n",
    "nri.set_run_params()\n",
    "nri.set_input_graph(rec_rel, send_rel)\n",
    "\n",
    "# print(summary(nri, (64, 5, n_timesteps, n_dims)))\n",
    "print(nri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290107e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ef9497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e2d5ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes      | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 36.3 K | train | [1, 5, 49, 4] | [1, 20, 2]                    \n",
      "1 | decoder | Decoder | 55.0 K | train | [1, 5, 49, 4] | [[1, 5, 48, 4], [1, 5, 48, 4]]\n",
      "---------------------------------------------------------------------------------------------\n",
      "91.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.3 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n",
      "141       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Aryan_Savant\\Thesis_Projects\\my_work\\AFD_implement_thesis\\topology_estimation\\decoder_blocks.py:222: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (self.pred_steps <= n_timesteps) # if pred_Step is 100 and timesteps is 50, this will return error\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\jit\\_trace.py:1307: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%863 : Float(1, 20, 2, strides=[40, 2, 1], requires_grad=0, device=cuda:0) = aten::exponential_(%860, %861, %862) # c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\nn\\functional.py:2201:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\jit\\_trace.py:1307: TracerWarning: Output nr 2. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 909 / 960 (94.7%)\n",
      "Greatest absolute difference: 0.0006345510482788086 at index (0, 0, 11, 1) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 3.8380389840519786 at index (0, 4, 15, 0) (up to 1e-05 allowed)\n",
      "  _check_trace(\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\torch\\jit\\_trace.py:1307: TracerWarning: Output nr 3. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 869 / 960 (90.5%)\n",
      "Greatest absolute difference: 0.00029164552688598633 at index (0, 0, 16, 1) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 0.00040533414096416344 at index (0, 0, 16, 1) (up to 1e-05 allowed)\n",
      "  _check_trace(\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.90it/s, v_num=7, train_loss=37.50, train_loss_encoder=-2.71, train_loss_decoder=40.20, train_edge_accuracy=0.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.83it/s, v_num=7, train_loss=37.50, train_loss_encoder=-2.71, train_loss_decoder=40.20, train_edge_accuracy=0.490]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "nri.set_training_params()\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"nri_model_trial2\", log_graph=True)\n",
    "\n",
    "trainer = Trainer(max_epochs=10, logger=logger)\n",
    "trainer.fit(model=nri, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f40235a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at tb_logs\\nri_model_trial2\\version_3\\checkpoints\\epoch=19-step=100.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes      | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 36.3 K | train | [1, 5, 49, 4] | [1, 20, 2]                    \n",
      "1 | decoder | Decoder | 55.0 K | train | [1, 5, 49, 4] | [[1, 5, 48, 4], [1, 5, 48, 4]]\n",
      "---------------------------------------------------------------------------------------------\n",
      "91.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.3 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n",
      "141       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Restored all states from the checkpoint at tb_logs\\nri_model_trial2\\version_3\\checkpoints\\epoch=19-step=100.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.22it/s, v_num=3, train_loss=-23.0, train_loss_encoder=-2.70, train_loss_decoder=-20.3, train_edge_accuracy=0.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.17it/s, v_num=3, train_loss=-23.0, train_loss_encoder=-2.70, train_loss_decoder=-20.3, train_edge_accuracy=0.490]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_to_best_checkpoint = \"tb_logs\\\\nri_model_trial2\\\\version_3\\\\checkpoints\\\\epoch=19-step=100.ckpt\"\n",
    "trainer = Trainer(max_epochs=30, logger=logger)\n",
    "\n",
    "trainer.fit(model=nri, train_dataloaders=train_loader, ckpt_path=path_to_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56317770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes      | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 36.3 K | train | [1, 5, 49, 4] | [1, 20, 2]                    \n",
      "1 | decoder | Decoder | 55.0 K | train | [1, 5, 49, 4] | [[1, 5, 48, 4], [1, 5, 48, 4]]\n",
      "---------------------------------------------------------------------------------------------\n",
      "91.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.3 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n",
      "141       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.92it/s, v_num=8, train_loss=-45.3, train_loss_encoder=-2.60, train_loss_decoder=-42.6, train_edge_accuracy=0.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.85it/s, v_num=8, train_loss=-45.3, train_loss_encoder=-2.60, train_loss_decoder=-42.6, train_edge_accuracy=0.490]\n"
     ]
    }
   ],
   "source": [
    "hyper_params_tp =  par.__dict__\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"nri_model_trial2\")\n",
    "logger.log_hyperparams(hyper_params_tp)\n",
    "\n",
    "trainer = Trainer(max_epochs=10, logger=logger)\n",
    "trainer.fit(model=nri, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea17ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params | Mode  | In sizes      | Out sizes                     \n",
      "---------------------------------------------------------------------------------------------\n",
      "0 | encoder | Encoder | 36.3 K | train | [1, 5, 49, 4] | [1, 20, 2]                    \n",
      "1 | decoder | Decoder | 55.0 K | train | [1, 5, 49, 4] | [[1, 5, 48, 4], [1, 5, 48, 4]]\n",
      "---------------------------------------------------------------------------------------------\n",
      "91.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.3 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n",
      "141       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "c:\\Anaconda3\\envs\\thesis\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.31it/s, v_num=1, train_loss=-112., train_loss_encoder=-1.82, train_loss_decoder=-110., train_edge_accuracy=0.490]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.25it/s, v_num=1, train_loss=-112., train_loss_encoder=-1.82, train_loss_decoder=-110., train_edge_accuracy=0.490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"AFD\",  # change to your project name\n",
    "    name=\"NRI2\",  # optional: custom run name\n",
    "    version='1'\n",
    ")\n",
    "wandb_logger.log_hyperparams(par.__dict__)\n",
    "\n",
    "trainer = Trainer(max_epochs=10, logger=wandb_logger)\n",
    "trainer.fit(model=nri, train_dataloaders=train_loader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
